\documentclass[]{article}

\usepackage{framed}


\begin{document}
\section*{Bayesian BA - Philip J Schluter}
Bayesian Bland Altman Approaches
%================================%
A multivariate hierarchical Bayesian approach to measuring agreement in repeated
measurement method comparison studies

*http://www.biomedcentral.com/1471-2288/9/6*



\subsection*{Background}
Assessing agreement in method comparison studies depends on two fundamentally important components; validity (the between method agreement) and reproducibility (the within method agreement). 

The Bland-Altman limits of agreement technique is one of the favoured approaches in medical literature for assessing between method validity. However, few researchers have adopted this approach for the assessment of both validity and reproducibility. 

This may be partly due to a lack of a flexible, easily implemented and readily available statistical machinery to analyse repeated measurement method comparison data.

\textbf{Methods}\\
Adopting the Bland-Altman framework, but using Bayesian methods, we present this statistical machinery. Two multivariate hierarchical Bayesian models are advocated, one which assumes that the underlying values for subjects remain static (exchangeable replicates) and one which assumes that the underlying values can change between repeated measurements (non-exchangeable replicates).

\textbf{Results}\\
We illustrate the salient advantages of these models using two separate datasets that have been previously analysed and presented; 
(i) assuming static underlying values analysed using both multivariate hierarchical Bayesian models,  
(ii) assuming each subject's underlying value is continually changing quantity and analysed using the non-exchangeable replicate multivariate hierarchical Bayesian model.  

\textbf{Conclusion}
These easily implemented models allow for full parameter uncertainty, simultaneous method comparison, handle unbalanced or missing data, and provide estimates and credible regions for all the parameters of interest. Computer code for the analyses in also presented, provided in the freely available and currently cost free software package WinBUGS.
<hr>

\section*{Bayesian Approach}
A multivariate hierarchical Bayesian approach to measuring agreement in repeated measurement method comparison studies
PJ Schluter - BMC medical research methodology, 2009 - biomedcentral.com

\begin{itemize}
	\item Assessing agreement in method comparison studies depends on two fundamentally important 
	components; validity (the between method agreement) and reproducibility (the within method 
	agreement). 
	\item The Bland-Altman limits of agreement technique is one of the f
\end{itemize}

%========================%
\section{Escaramis}
% Escaramis et al 2010
% http://www.biomedcentral.com/1471-2288/10/31/
%-----------------------------------------------------%
\subsection{Background}
In an agreement assay, it is of interest to evaluate the degree of agreement between the different methods (devices, instruments or observers) used to measure the same characteristic. We propose in this study a technical simplification for inference about the total deviation index (TDI) estimate to assess agreement between two devices of normally-distributed measurements and describe its utility to evaluate inter- and intra-rater agreement if more than one reading per subject is available for each device.

\subsection{Methods}
We propose to estimate the TDI by constructing a probability interval of the difference in paired measurements between devices, and thereafter, we derive a tolerance interval (TI) procedure as a natural way to make inferences about probability limit estimates. We also describe how the proposed method can be used to compute bounds of the coverage probability.

\subsection{Results}
The approach is illustrated in a real case example where the agreement between two instruments, a handle mercury sphygmomanometer device and an OMRON 711 automatic device, is assessed in a sample of 384 subjects where measures of systolic blood pressure were taken twice by each device. A simulation study procedure is implemented to evaluate and compare the accuracy of the approach to two already established methods, showing that the TI approximation produces accurate empirical confidence levels which are reasonably close to the nominal confidence level.

\subsection{Conclusions}
The method proposed is straightforward since the TDI estimate is derived directly from a probability interval of a normally-distributed variable in its original scale, without further transformations. Thereafter, a natural way of making inferences about this estimate is to derive the appropriate TI. Constructions of TI based on normal populations are implemented in most standard statistical packages, thus making it simpler for any practitioner to implement our proposal to assess agreement.

%-----------------------------------------------------%
%PAGE 3 of 12 COLUMN 1
Lin defined the TDI as the boundary, $\kappa_P$ which capyures a large proportion $p$ of paired based differences from 
two devices or observers within the boundary.

The value of $\kappa_P$ that yeilds $P(|D| <\kappa_p) = p$ where D is the paired-difference variate.

%-----------------------------------------------------%
%PAGE 3 of 12 COLUMN 2

\[ \kappa_P = F^{-1}(p) = \sigma_D \sqrt{\chi^2(p,1,\mu^2_D/\sigma^2_d) }  \]

\[ \kappa_P = Z_{\frac{1+p}{2}} \| \varepsilon\| \]

%-----------------------------------------------------%

%PAGE 5 of 12 COLUMN 1

Tolerance Interval around the TDI estimate

\[ \hat{\kappa_p} = \hat{\mu}_D = Z_{p_i}\sigma_d \]

%-----------------------------------------------------%

%PAGE 5 of 12 COLUMN 2
Coverage Probability is another user friendly measure of agrre,ment which is related to the computation of the TDI.


	\newpage
	\section{Influence analysis} %1.7
	
	Likelihood based estimation methods, such as ML and REML, are sensitive to unusual observations. Influence diagnostics are formal techniques that assess the influence of observations on parameter estimates for $\beta$ and $\theta$. A common technique is to refit the model with an observation or group of observations omitted.
	
	\emph{west} examines a group of methods that examine various aspects of influence diagnostics for LME models.
	For overall influence, the most common approaches are the `likelihood distance' and the `restricted likelihood distance'.
	
	\subsection{Cook's 1986 paper on Local Influence}%1.7.1
	Cook 1986 introduced methods for local influence assessment. These methods provide a powerful tool for examining perturbations in the assumption of a model, particularly the effects of local perturbations of parameters of observations.
	
	The local-influence approach to influence assessment is quitedifferent from the case deletion approach, comparisons are of
	interest.
	
	
	
	\subsection{Overall Influence}
	An overall influence statistic measures the change in the objective function being minimized. For example, in
	OLS regression, the residual sums of squares serves that purpose. In linear mixed models fit by
	\index{maximum likelihood} maximum likelihood (ML) or \index{restricted maximum likelihood} restricted maximum likelihood (REML), an overall influence measure is the \index{likelihood distance} likelihood distance [Cook and Weisberg ].
	
	
	\subsection{Influence}
	
	\emph{schab} examines the use and implementation of
	influence measures in LME models.
	
	Influence is understood to be the ability of a single or multiple
	data points, through their presences or absence in the data, to
	alter important aspects of the analysis, yield qualitatively
	different inferences, or violate assumptions of the statistical
	model (\textit{schabenberger}).
	
	Outliers are the most noteworthy data points in an analysis, and
	an objective of influence analysis is how influential they are,
	and the manner in which they are influential.
	
	\emph{schab} describes a simple procedure for quantifying
	influence. Firstly a model should be fitted to the data, and
	estimates of the parameters should be obtained. The second step is
	that either single of multiple data points, specifically outliers,
	should be omitted from the analysis, with the original parameter
	estimates being updated. 
	
	This is known as `\textit{leave one out \ leave k
		out}' analysis. The final step of the procedure is comparing the
	sets of estimates computed from the entire and reduced data sets
	to determine whether the absence of observations changed the
	analysis.
	
	\textit{schabenberger} notes that it is not always possible to
	derive influence statistics necessary for comparing full- and
	reduced-data parameter estimates. 
	
	%
	%\begin{abstract}
	%	\noindent This paper reviews the use of diagnostic measures for LME models in SAS. This text has been widely cited by texts that don't deal with SAS implementations.
	%\end{abstract}
	%
	
	%==================================================================================================== %
	\subsection{Influence}
	Broadly
	defined, ``\textit{influence}” is understood as the ability of a single or multiple data points, through their presence
	or absence in the data, to alter important aspects of the analysis, yield qualitatively different inferences, or
	violate assumptions of the statistical model. 
	
	
	The goal of influence analysis is not primarily to mark data
	points for deletion so that a better model fit can be achieved for the reduced data, although this might be a
	result of influence analysis. The goal is rather to determine which cases are influential and the manner in
	which they are important to the analysis. Outliers, for example, may be the most noteworthy data points in
	an analysis. They can point to a model breakdown and lead to development of a better model.
	
	
	%==================================================================================================== %
	
	In recent years, mixed models have become invaluable tools in the analysis of experimental and observational
	data. In these models, more than one term can be subject to random variation. Mixed model
	technology enables you to analyze complex experimental data with hierarchical random processes, temporal,
	longitudinal, and spatial data, to name just a few important applications. 
	%
	%\subsection{Stating the LME Model}
	%The general linear mixed
	%model is
	%\[
	%Y = X\beta + Zu + \varepsilon\]
	%where Y is a $(n\times1)$ vector of observed data, X is an $(n\times p)$ fixed-effects design or regressor matrix of rank
	%k, Z is a $(n \times g)$ random-effects design or regressor matrix, $u$ is a $(g \times 1)$ vector of random effects, and $\varepsilon$ is
	%an $(n\times1)$ vector of model errors (also random effects). The distributional assumptions made by the MIXED
	%procedure are as follows: γ is normal with mean 0 and variance G; $\varepsilon$ is normal with mean 0 and variance
	%R; the random components $u$ and $\varepsilon$ are independent. Parameters of this model are the fixed-effects β and
	%all unknowns in the variance matrices G and R. The unknown variance elements are referred to as the
	%covariance parameters and collected in the vector $theta$.
	%===========================================================================%
	
	\emph{schab} remarks that the concept of critiquing the model-data agreement applies in mixed models in the same way as in linear
	fixed-effects models. In fact, because of the more complex model structure, you can argue that model and
	data diagnostics are even more important. For example, you are not only concerned with capturing the
	important variables in the model. You are also concerned with ``distributing” them correctly between the
	fixed and random components of the model. The mixed model structure presents unique and interesting
	challenges that prompt us to reexamine the traditional ideas of influence and residual analysis.
	%==========================================================================%
	%This paper presents the extension of traditional tools and statistical measures for influence and residual
	%analysis to the linear mixed model and demonstrates their implementation in the MIXED procedure (experimental
	%features in SAS 9.1). The remainder of this paper is organized as follows. The “Background” section
	%briefly discusses some mixed model estimation theory and the challenges to model diagnosis that result
	%from it.
	
	%	 The diagnostics implemented in the MIXED procedure are discussed in the “Residual Diagnostics
	%	in the MIXED Procedure” section (page 3) and the “Influence Diagnostics in the MIXED Procedure” section
	%	(page 5). The syntax options and suboptions you use to request the various diagnostics are briefly sketched
	%	in the “Syntax” section (page 9). The presentation concludes with an example.
	%	
	%	
	%====================================================================================================================%
	
	
	
\section{Hawkins : Diagnostics for conformity of paired quantitative measurements}

\begin{itemize}
	\item Matched pairs data arise in many contexts – in case-control clinical trials, for example, and from cross-over designs. They also arise in experiments to verify the equivalence of quantitative assays. This latter use (which is the main focus of this paper) raises difficulties not always seen in other matched pairs applications. 
	
	\item Since the designs deliberately vary the analyte levels over a wide range, issues of variance dependent on mean, calibrations of differing slopes, and curvature all need to be added to the usual model assumptions such as normality. 
	
	\item Violations in any of these assumptions invalidate the conventional matched pairs analysis. 
	
	\item A graphical method, due to Bland and Altman, of looking at the relationship between the average and the difference of the members of the pairs is shown to correspond to a formal testable regression model. 
	
	\item Using standard regression diagnostics, one may detect and diagnose departures from the model assumptions and remedy them – for example using variable transformations. Examples of different common scenarios and possible approaches to handling them are shown.
\end{itemize}
%====================================%

% 1. Problem Description
% 2. A Statistical Formulation
%    2.1 Regression Methods for Testing Equivalence
%    2.2 Matched Pair Analysis
% 3. Regression of Differences on Sums
%    3.1 Use of Formal regression Diagnostics
% 4. Examples
%    4.1 Example 1
%    4.2 Detection and Cure of Heteroscedascity
%    4.3 Example 2
%    4.4 Example 3
%    4.5 Example 4
%    4.6 Example 5
% 5. Precepts for Design
% 6. Conclusion


%====================================%
### A multi-Rate nonparametric test of agreement and corresponding agreement plot

- Published in: Computational Statistics and Data Analysis 54(2010)109-119
- Author: Alan D. Hutson, University of Buffalo



This approach takes advantage of readily avilable tests of uniformity found in most statistical software packages.
Such tests include the KS d statistic, the Anderson Darling Statistic and the Cramer-Von Mises statistical test for univariate data.

An important aspect of this approach is the "Agreement Region".



\section*{Roy Test}

Roy’s Tests (Roy 2009)
%=============================%
Roy 2009 devised an LME based Testing approach to the MCS problem, based on earlier work by Hamlett et al. 
Roy 2009 presents a series of three formal hypothesis tests for assessing agreement between two methods of measurement.
Roy also alludes to some of the current shortcomings of the approach.

%%%% Components of Test

Comparing different model specifications with LRT tests

%%%% Papers:
- Roy 2007
- Roy 2009
- Hamlett et al.
- Roy Leiva 2011



Conventionally LME models can be tested using Likelihood Ratio Tests, wherein a reference model is compared to a nested model.
\begin{verbatim}
> Ref.Fit = lme(y ~ meth-1, data = dat,   #Symm , Symm#
+     random = list(item=pdSymm(~ meth-1)), 
+     weights=varIdent(form=~1|meth),
+     correlation = corSymm(form=~1 | item/repl), 
+     method="ML")
\end{verbatim}
Roy(2009) presents two nested models that specify the condition of equality as required, with a third nested model for an additional test. There three formulations share the same structure, and can be specified by making slight alterations of the code for the Reference Model.
\begin{verbatim}
Nested Model (Between-Item Variability)
> NMB.fit  = lme(y ~ meth-1, data = dat,   #CS , Symm#
+     random = list(item=pdCompSymm(~ meth-1)),
+     correlation = corSymm(form=~1 | item/repl), 
+     method="ML")
\end{verbatim}



\begin{verbatim}
Nested Model (Within –item Variability)
> NMW.fit = lme(y ~ meth-1, data = dat,   #Symm , CS# 
+     random = list(item=pdSymm(~ meth-1)),
+     weights=varIdent(form=~1|meth), 
+     correlation = corCompSymm(form=~1 | item/repl), 
+     method="ML")
\end{verbatim}


Nested Model (Overall Variability)
Additionally there is a third nested model, that can be used to test overall variability, substantively a a joint test for between-item and within-item variability. The motivation for including such a test in the suite is not clear, although it does circumvent the need for multiple comparison procedures in certain circumstances, hence providing a simplified procedure for non-statisticians.
\begin{verbatim}
   > NMO.fit = lme(y ~ meth-1, data = dat,   #CS , CS# 
+     random = list(item=pdCompSymm(~ meth-1)), 
+     correlation = corCompSymm(form=~1 | item/repl), 
+     method="ML")
\end{verbatim}

ANOVAs  for  Original Fits
The likelihood Ratio test is very simple to implement in R. All that is required it to specify the reference model and the relevant nested mode as arguments to the command anova().
The figure below displays the three tests described by Roy (2009).
\begin{verbatim}
> testB    = anova(Ref.Fit,NMB.fit)                          # Between-Subject Variabilities
> testW   = anova(Ref.Fit,NMW.fit)                        # Within-Subject Variabilities
> testO     = anova(Ref.Fit,NMO.fit)                        # Overall Variabilities
\end{verbatim}
\newpage
\section{Profile Function with "lmer"}

The profile() function for lmer models is now available in the latest version of lme4, to be installed by typing:

install.packages("lme4",repos="http://r-forge.r-project.org")

also

The mle function from the stats4 package is a wrapper of optim, which makes it quite easy to produce 
profile likelihood computations. 

See help("profile,mle-method", package = "stats4") for more information.

%----------------%

http://people.upei.ca/hstryhn/stryhn208.pdf

The profile likelihood (or likelihood or likelihood ratio) methid is applicable to 
all likelihood based statstical analysis and is generally less sensitive to the difficulties
encountered by walkd-Tyoe CIs.
  
\section{Quiroz Burdick}
%-------------------------------------------------------------------------%
Assessmet of individual agreements with repeated measurements based on Generalized Confidence intervals.

%KEYWORDS

Bootstrap confidence intervals.
Coverage probability (CP)
Equivalence Studies
Individual agreements
Generalized Confidence intervals (GCI)
Total deviation index (TDI)
Variance components

%--------------------------------------------------------------------------%
%SUMMARY
Proposing an equivalence test for assessing individual agreement based on TDI and CP.
The bounds used in the tests are constucted using a bootstrap approach and generalized confidence intervals (GCI).

%--------------------------------------------------------------------------%
%PAGE 345
%Exchangability

Equivalence testing is an approach commonly used to determine the acceptability of a new method 
against a reference method.

%--------------------------------------------------------------------------%
%PAGE 346 TDI and CP

Both the TDI and CP are attractive criteria as they are easy to interpret.

Bootstrap approach was later applied to mixed models with repeated measurements by Choudhary (2007)

%--------------------------------------------------------------------------%
%PAGE 346 - EXPERIMENTAL DESIGN
$T$ for test measurement, $R$ for reference measurement

%--------------------------------------------------------------------------%
%PAGE 347

$\otimes$ is the Kroneckor Product operator.

\[  \Sigma_{MS} =  \left[     \begin{array}{cc} \sigma^2_{TS} & 0 \\ 0 & \sigma^2_{RS} \end{array}\right] \]

%--------------------------------------------------------------------------%
% PAPERS

%Paper on GCIs - http://www.jstor.org/discover/10.2307/2290779?uid=3738232&uid=2&uid=4&sid=21103546837943


\section{Turkan's LMEs}
% Influence Analysis in the LME Models
% Turkan and Toktamus
% Pakistan Journal of Statistics;2012, Vol. 28 Issue 3, p341

% - http://www.tandfonline.com/doi/abs/10.1080/03610920903564727?journalCode=lsta20#.VHj9vfmsXE4

The linear mixed model is considerably sensitive to outliers and influential observations. 
It is known that outliers and influential observations affect substantially the results of analysis. 
So it is very important to be aware of these observations. 

Some diagnostics which are analogue of diagnostics in multiple linear regression were developed to detect 
outliers and influential observations in the linear mixed model. 
\emph{
	In this paper, the new diagnostic measure which is analogue of the Pena's influence statistic is developed for 
	the linear mixed model.
}
\newpage
%-----------------------------------------------------------------------------------------%

%page 341

%-----------------------------------------------------------------------------------------%
%page 342
Estimation and Building blacks in LME models

%-----------------------------------------------------------------------------------------%
%page 343

\[ \hat{u} = DZ^{T}H^{-1}(y-X\hat{\beta}) \]

\[ \hat{y} = (I_n -  H^{-1})y + H^{-1}X\hat{\beta}\]

%-----------------------------------------------------------------------------------------%
%page 345

The proposed diagnostic Measure.

%-----------------------------------------------------------------------------------------%
% http://halweb.uc3m.es/esp/Personal/personas/dpena/articles/TECHanews2005.pdf
\bibliography{DB-txfrbib}
\end{document}