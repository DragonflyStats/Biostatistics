\documentclass[12pt, a4paper]{report}

\usepackage{epsfig}
\usepackage{subfigure}
%\usepackage{amscd}
\usepackage{amssymb}
\usepackage{graphicx}
%\usepackage{amscd}
\usepackage{amssymb}
\usepackage{subfiles}
\usepackage{framed}
\usepackage{subfiles}
\usepackage{amsthm, amsmath}
\usepackage{amsbsy}
\usepackage{framed}
\usepackage[usenames]{color}
\usepackage{listings}
\lstset{% general command to set parameter(s)
	basicstyle=\small, % print whole listing small
	keywordstyle=\color{red}\itshape,
	% underlined bold black keywords
	commentstyle=\color{blue}, % white comments
	stringstyle=\ttfamily, % typewriter type for strings
	showstringspaces=false,
	numbers=left, numberstyle=\tiny, stepnumber=1, numbersep=5pt, %
	frame=shadowbox,
	rulesepcolor=\color{black},
	,columns=fullflexible
} %
%\usepackage[dvips]{graphicx}
\usepackage{natbib}
\bibliographystyle{chicago}
\usepackage{vmargin}
% left top textwidth textheight headheight
% headsep footheight footskip
\setmargins{1.0cm}{0.75cm}{18.5 cm}{22cm}{0.5cm}{0cm}{1cm}{1cm}
%\voffset=-2.5cm
%\oddsidemargin=1cm
%\textwidth = 520pt

\renewcommand{\baselinestretch}{1.5}
\pagenumbering{arabic}
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{ill}[theorem]{Example}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{axiom}{Axiom}
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\newtheorem{notation}{Notation}
\theoremstyle{remark}
\newtheorem{remark}{Remark}[section]
\newtheorem{example}{Example}[section]
\renewcommand{\thenotation}{}
\renewcommand{\thetable}{\thesection.\arabic{table}}
\renewcommand{\thefigure}{\thesection.\arabic{figure}}
\title{Research notes: linear mixed effects models}
\author{ } \date{ }


\begin{document}
	\author{Kevin O'Brien}
	\title{Mixed Models for Method Comparison Studies}
	\tableofcontents


	\chapter{Introduction to Method Comparison Studies}



	\section{Agreement}
	\begin{itemize}
		\item The FDA define precision as the \textit{closeness of agreement} (degree of
		scatter) between a series of measurements obtained from multiple
		sampling of the same homogeneous sample under prescribed
		conditions. 
		\item \textbf{Barnhart} describes precision as being further
		subdivided as either within-run, intra-batch precision or
		repeatability (which assesses precision during a single analytical
		run), or between-run, inter-batch precision or repeatability
		(which measures precision over time).
	\end{itemize}
	


	\section{Purposes of MCS}
	
	The  question being answered is not always clear, but is usually epxressed as an attempt to quantify the agreement
	between two methods (Bland and Altman 1995)
	
	Some lack of agreement between different methods of measurement is inevitable. What matters is the amount by which they
	disagree. we want to know by how much the new method is likely to differ from the old, so that it is not enough to cause
	problems in the mathematical interpretation we can preplace the old method by the new, or even use the two interchangably.
	
	
	It often happens that the same physical and chemical property can be measured in different ways. For example, one can determine
	For example, one can determine sodium in serum by flame atomic emission spectroscopy or by isotops dilution mass spectroscopy. The question arises as to whcih methd is better (Mandel 1991)
	
	In areas of inter-laboratory quality control, method comparisons, assay validations and individual bio-equivalence, etc, the agree between observations and target (reference) value is
	of interest (lin 2002)
	
	The purpose of comparing two methods of measurement of a continuous biological variable is to uncover systematic differences, not to point to
	similarities. (ludbrook 1997)
	
	In the pharmaceutical industry, measurement methods that measure the quantity of prdocuts are regulated. The FDA (U.S. Food and
	Drug Administration) requires that the manufacturer show equivalency prior to approving the new or alternatice method in quality control (Tan \& Inglewicz ,1999)
	

	\section{Indications on how to deal with outliers in Bland Altman plots}

	We wish to determine how outliers should be treated in a Bland
	Altman Plot
	
	In their 1983 paper they merely state that the plot can be used to
	'spot outliers'.

	In  their 1986 paper, Bland and Altman give an example of an
	outlier. They state that it could be omitted in practice, but make
	no further comments on the matter.
	\\
	In Bland and Altmans 1999 paper, we get the clearest indication of
	what Bland and Altman suggest on how to react to the presence of
	outliers. Their recommendation is to recalculate the limits
	without them, in order to test the difference with the calculation
	where outliers are retained.\\
	
	The span has reduced from 77 to 59 mmHg, a noticeable but not
	particularly large reduction.
	\\
	However, they do not recommend removing outliers. Furthermore,
	they say:
	\\
	We usually find that this method of analysis is not too sensitive
	to one or two large outlying differences.
	\\
	We ask if this would be so in all cases. Given that the limits of
	agreement may or may not be disregarded, depending on their
	perceived suitability, we examine whether it would possible that
	the deletion of an outlier may lead to a calculation of limits of
	agreement that are usable in all cases?
	\\
	Should an Outlying Observation be omitted from a data set? In
	general, this is not considered prudent.
	\\
	Also, it may be required that the outliers are worthy of
	particular attention themselves.
	\\
	Classifying outliers and recalculating We opted to examine this
	matter in more detail. The following points have to be considered
	\\how to suitably identify an outlier (in a generalized sense)
	\\Would a recalculation of the limits of agreement generally
	results in  a compacted range between the upper and lower limits
	of agreement?
	\subsection{Agreement} Bland and Altman (1986) define Perfect
	agreement as 'The case where all of the pairs of rater data lie
	along the line of equality'. The Line of Equality is defined as
	the 45 degree line passing through the origin, or X=Y on a XY
	plane.
	

	\section{Roy's Approach}
	
	For the purposes of comparing two methods of measurement, \citet{ARoy2009} presents a methodology utilizing linear mixed effects model. This methodology provides for the formal testing of inter-method bias, between-subject variability and within-subject variability of two methods. 
	
	\citet{ARoy2009} uses an approach based on linear mixed effects (LME) models for the purpose of comparing the agreement between two methods of measurement, where replicate measurements on items (often individuals) by both methods are available. Three tests of hypothesis appropriate are provided for evaluating the agreement between the two methods of measurement under this sampling scheme. 
	
	Importantly \citet{ARoy2009} further proposes a series of three tests on the variance components of an LME model, which allow decisions on the second and third of Roy's criteria. For these tests, four candidate LME models are constructed. 
	
	\citet{ARoy2009} proposes the use of LME models to perform a test on two methods of agreement to comparing the agreement between two methods of measurement, where replicate measurements on items (often individuals) by both methods are available, determining whether they can be used
	interchangeably. The methodology proposed by \citet{ARoy2009} is largely based on \citet{hamlett}, which in turn follows on from \citet{lam}.
	
	\citet{ARoy2009} proposes a novel method using the LME model with Kronecker product covariance structure in a doubly multivariate set-up to assess the agreement between a new method and an established method with unbalanced data and with unequal replications for different subjects. By doubly multivariate set up, Roy means that the information on each patient or item is multivariate at two levels, the number of methods and number of replicated measurements. Further to \citet{lam}, it is assumed that the replicates are linked over time. However it is easy to modify to the unlinked case.
	
	
	The well-known ``Limits of Agreement", as developed by \citet{BA86} are not referred to directly, but are easily computable using the framework proposed by \citet{ARoy2009}. Further discussion will be provided in due course.	
	
	
	
	
	
	%Two methods of measurement can be said to be in agreement if there is no significant difference between in three key respects. 
	%
	%Firstly, there is no inter-method bias between the two methods, i.e. there is no persistent tendency for one method to give higher values than the other.
	%
	%Secondly, both methods of measurement have the same  within-subject variability. In such a case the variance of the replicate measurements would consistent for both methods.
	%Lastly, the methods have equal between-subject variability.  Put simply, for the mean measurements for each case, the variances of the mean measurements from both methods are equal.
	
	Further to this, \citet{ARoy2009} demonstrates an suite of tests that can be used to determine how well two methods of measurement, in the presence of repeated measures, agree with each other.
	
	\begin{itemize}\itemsep0.5cm
		\item No Significant inter-method bias
		\item No difference in the between-subject variabilities of the two methods
		\item No difference in the within-subject variabilities of the two methods
	\end{itemize}
	
	The formulation presented above usefully facilitates a series of
	significance tests that advise as to how well the two methods
	agree. These tests are as follows:
	\begin{itemize}
		\item A formal test for the equality of between-item variances,
		\item A formal test for the equality of within-item variances,
		\item A formal test for the equality of overall variances.
	\end{itemize}
	These tests are complemented by the ability to consider the inter-method bias and the overall correlation coefficient. Two methods can be considered to be in agreement if criteria based upon these methodologies are met. Additionally Roy makes reference to the overall correlation coefficient of the two methods, which is determinable from variance estimates. Other important aspects of the method comparison study are consequent. The limits of agreement are computed using the results of the reference model.
	
	Differences in between-subject variabilities of the two methods arise when one method is yielding average response levels for individuals than are more variable than the average response levels for the same sample of individuals taken by the other method.  Differences in within-subject variabilities of the two methods arise when one method is yielding responses for an individual than are more variable than the responses for this same individual taken by the other method. The two methods of measurement can be considered to agree, and subsequently can be used interchangeably, if all three null hypotheses are true.	
	
	
	\subsection{LME Model Specification}
	
	Let $y_{mir} $ denote the $r$th replicate measurement on the $i$th item by the $m$th method, where $m=1,2,$ $i=1,\ldots,N,$ and $r = 1,\ldots,n_i.$ When the design is balanced and there is no ambiguity we can set $n_i=n.$ The LME model underpinning Roy's approach can be written
	\begin{equation}\label{Roy-model}
	y_{mir} = \beta_{0} + \beta_{m} + b_{mi} + \epsilon_{mir}.
	\end{equation}
	
	Here $\beta_0$ and $\beta_m$ are fixed-effect terms representing, respectively, a model intercept and an overall effect for method $m.$ 
	
	The $b_{1i}$ and $b_{2i}$ terms represent random effect parameters corresponding to the two methods, having $\mathrm{E}(b_{mi})=0$ with $\mathrm{Var}(b_{mi})=g^2_m$ and $\mathrm{Cov}(b_{mi}, b_{m^\prime i})=d_{12}.$ The random error term for each response is denoted $\epsilon_{mir}$ having $\mathrm{E}(\epsilon_{mir})=0$, $\mathrm{Var}(\epsilon_{mir})=\sigma^2_m$, $\mathrm{Cov}(b_{mir}, b_{m^\prime ir})=\sigma_{12}$, $\mathrm{Cov}(\epsilon_{mir}, \epsilon_{mir^\prime})= 0$ and $\mathrm{Cov}(\epsilon_{mir}, \epsilon_{m^\prime ir^\prime})= 0.$
	
	
	When two methods of measurement are in agreement, there is no significant differences between $\beta_1$ and $\beta_2,$ $g^2_1 $ and$ g^2_2$, and $\sigma^2_1 $ and$ \sigma^2_2$.
	Here $\beta_0$ and $\beta_m$ are fixed-effect terms representing, respectively, a model intercept and an overall effect for method $m.$ 
	
	The model can be reparameterized by gathering the $\beta$ terms together into (fixed effect) intercept terms $\alpha_m=\beta_0+\beta_m.$ The $b_{1i}$ and $b_{2i}$ terms are correlated random effect parameters having $\mathrm{E}(b_{mi})=0$ with $\mathrm{Var}(b_{mi})=g^2_m$ and $\mathrm{Cov}(b_{1i}, b_{2 i})=d_{12}.$ 
	
	The random error term for each response is denoted $\epsilon_{mir}$ having $\mathrm{E}(\epsilon_{mir})=0$, $\mathrm{Var}(\epsilon_{mir})=\sigma^2_m$, $\mathrm{Cov}(\epsilon_{1ir}, \epsilon_{2 ir})=\sigma_{12}$, $\mathrm{Cov}(\epsilon_{mir}, \epsilon_{mir^\prime})= 0$ and $\mathrm{Cov}(\epsilon_{1ir}, \epsilon_{2 ir^\prime})= 0.$ Two methods of measurement are in complete agreement if the null hypotheses $\mathrm{H}_1\colon \alpha_1 = \alpha_2$ and $\mathrm{H}_2\colon \sigma^2_1 = \sigma^2_2 $ and $\mathrm{H}_3\colon g^2_1= g^2_2$ hold simultaneously. \citet{ARoy2009} uses a Bonferroni correction to control the familywise error rate for tests of $\{\mathrm{H}_1, \mathrm{H}_2, \mathrm{H}_3\}$ and account for difficulties arising due to multiple testing. 
		\subsection{Variance Covariance Matrices }
		
		Under Roy's model, random effects are defined using a bivariate normal distribution. Consequently, the variance-covariance structures can be described using $2 \times 2$  matrices. A discussion of the various structures a variance-covariance matrix can be specified under is required before progressing. The following structures are relevant: the identity structure, the compound symmetric structure and the symmetric structure.
		
		The differences in the models are specifically in how the the $D$ and $\Lambda$ matrices are constructed, using either an unstructured form or a compound symmetry form. To illustrate these differences, consider a generic matrix $A$,
		
		\[
		\boldsymbol{A} = \left( \begin{array}{cc}
		a_{11} & a_{12}  \\
		a_{21} & a_{22}  \\
		\end{array}\right).
		\]
		
		A symmetric matrix allows the diagonal terms $a_{11}$ and $a_{22}$ to differ. The compound symmetry structure requires that both of these terms be equal, i.e $a_{11} = a_{22}$.
		
		
		The identity structure is simply an abstraction of the identity matrix. The compound symmetric structure and symmetric structure can be described with reference to the following matrix (here in the context of the overall covariance Block-$\boldsymbol{\Omega}_i$, but equally applicable to the component variabilities $\boldsymbol{D}$ and $\boldsymbol{\Sigma}$);
		
		\[\left( \begin{array}{cc}
		\omega^2_1  & \omega_{12} \\
		\omega_{12} & \omega^2_2 \\
		\end{array}\right) \]
		
		Symmetric structure requires the equality of all the diagonal terms, hence $\omega^2_1 = \omega^2_2$. Conversely compound symmetry make no such constraint on the diagonal elements. Under the identity structure, $\omega_{12} = 0$.
		A comparison of a model fitted using symmetric structure with that of a model fitted using the compound symmetric structure is equivalent to a test of the equality of variance.
		
		
		%In the presented example, it is shown that Roy's LOAs are lower than those of (\ref{BXC-model}), when covariance between methods is present.
		
		
		
		\subsubsection{Independence}
		
		As though analyzed using between subjects analysis.
		\[
		\left(
		\begin{array}{c c c}
		\psi^2 & 0 & 0   \\
		0 & \psi^2 & 0   \\
		0 & 0 & \psi^2   \\
		\end{array}%
		\right)
		\]
		
		
		
		\subsubsection{Compound Symmetry}
		
		Assumes that the variance-covariance structure has a single variance (represented by $\psi^2$)
		for all 3 of the time points and a single covariance (represented by $\psi_{ij}$) for each of the pairs of trials.
		
		\[
		\left(%
		\begin{array}{c c c}
		\psi^2 &  \psi_{12} & \psi_{13}   \\
		\psi_{21} & \psi^2 & \psi_{23}   \\
		\psi_{31} & \psi_{32} & \psi^2   \\
		\end{array}%
		\right)
		\]
		
		
		%\subsubsection{Unstructured}
		%
		%Assumes that each variance and covariance is unique.
		%Each trial has its own variance (e.g. s12 is the variance of trial 1)
		%and each pair of trials has its own covariance (e.g. s21 is the covariance of trial 1 and trial2).
		%This structure is illustrated by the half matrix below.
		%
		%
		%
		%\subsubsection{Autoregressive}
		%
		%Another common covariance structure which is frequently observed
		%in repeated measures data is an autoregressive structure,
		%which recognizes that observations which are more proximate
		%are more correlated than measures that are more distant.
		%
		%
		
		
		
		
		
		
		%-----------------------------------------------------------------------------------------------------%
		
		
		


	\subsection{Model Terms (Roy 2009)}
	\begin{itemize}
		\item Let $y_{mir}$ be the response of method $m$ on the $i$th subject
		at the $r-$th replicate.
		\item Let $\boldsymbol{y}_{ir}$ be the $2 \times 1$ vector of measurements
		corresponding to the $i-$th subject at the $r-$th replicate.
		\item Let $\boldsymbol{y}_{i}$ be the $R_i \times 1$ vector of
		measurements corresponding to the $i-$th subject, where $R_i$ is number of replicate measurements taken on item $i$.
		\item Let $\alpha_mi$ be the fixed effect parameter for method for subject $i$.
		\item Formally ARoy2009 uses a separate fixed effect parameter to describe the true value $\mu_i$, but later combines it with the other fixed effects when implementing the model.
		\item Let $u_{1i}$ and $u_{2i}$ be the random effects corresponding to methods for item $i$.
		
		\item $\boldsymbol{\epsilon}_{i}$ is a $n_{i}$-dimensional vector
		comprised of residual components. For the blood pressure data $n_{i} = 85$.
		
		\item $\boldsymbol{\beta}$ is the solutions of the means of the two methods. In the LME output, the bias ad corresponding
		t-value and p-values are presented. This is relevant to ARoy2009's first test.\end{itemize}
	
	

\subsection{Model Terms (Roy 2009)}
It is important to note the following characteristics of this model.

Let the number of replicate measurements on each item $i$ for both methods be $n_i$, hence $2 \times n_i$ responses. However, it is assumed that there may be a different number of replicates made for different items. Let the maximum number of replicates be $p$. An item will have up to $2p$ measurements, i.e. $\max(n_{i}) = 2p$.

% \item $\boldsymbol{y}_i$ is the $2n_i \times 1$ response vector for measurements on the $i-$th item.
% \item $\boldsymbol{X}_i$ is the $2n_i \times  3$ model matrix for the fixed effects for observations on item $i$.
% \item $\boldsymbol{\beta}$ is the $3 \times  1$ vector of fixed-effect coefficients, one for the true value for item $i$, and one effect each for both methods.

Later on $\boldsymbol{X}_i$ will be reduced to a $2 \times 1$ matrix, to allow estimation of terms. This is due to a shortage of rank. The fixed effects vector can be modified accordingly.

$\boldsymbol{Z}_i$ is the $2n_i \times  2$ model matrix for the random effects for measurement methods on item $i$.\\
\bigskip

$\boldsymbol{b}_i$ is the $2 \times  1$ vector of random-effect coefficients on item $i$, one for each method.

$\boldsymbol{\epsilon}$  is the $2n_i \times  1$ vector of residuals for measurements on item $i$.\\
\bigskip

$\boldsymbol{G}$ is the $2 \times  2$ covariance matrix for the random effects.

$\boldsymbol{R}_i$ is the $2n_i \times  2n_i$ covariance matrix for the residuals on item $i$.

The expected value is given as $\mbox{E}(\boldsymbol{y}_i) = \boldsymbol{X}_i\boldsymbol{\beta}.$ \citep{hamlett}\\
\bigskip

The variance of the response vector is given by $\mbox{Var}(\boldsymbol{y}_i)  = \boldsymbol{Z}_i \boldsymbol{G} \boldsymbol{Z}_i^{\prime} + \boldsymbol{R}_i$ \citep{hamlett}.



$\boldsymbol{b}_{i}$ is a $m-$dimensional vector comprised of
the random effects.
\begin{equation}
\boldsymbol{b}_{i} = \left( \begin{array}{c}
b_{1i} \\
b_{21}  \\
\end{array}\right)
\end{equation}


$\boldsymbol{V}$ represents the correlation matrix of the replicated measurements on a given method.
$\boldsymbol{\Sigma}$ is the within-subject VC matrix.\\
\bigskip


$\boldsymbol{V}$ and $\boldsymbol{\Sigma}$ are positive
definite matrices. The dimensions of $\boldsymbol{V}$ and
$\boldsymbol{\Sigma}$ are $3 \times 3 ( = p \times p )$ and $ 2 \times
2 (= k \times k)$.\\
\bigskip


It is assumed that $\boldsymbol{V}$ is the same for both methods and $\boldsymbol{\Sigma}$ is
the same for all replications.\\
\bigskip

$\boldsymbol{V} \bigotimes \boldsymbol{\Sigma}$ creates a $ 6 \times 6 ( = kp \times
kp)$ matrix.
$\boldsymbol{R}_{i}$ is a sub-matrix of this.\\
\bigskip

% Complete paragraph by specifying variances and covariances for epsilons.
% I thing that these are your sigmas?
% Also, state equality of the parameters in this model when each of the three hypotheses above are true.


	\chapter{Linear Mixed effects Models}
		
		\section{Case Deletion Diagnostics for LME models}
		
		
		
		\citet{Christensen} describes three propositions that are required
		for efficient case-deletion in LME models. The first proposition
		decribes how to efficiently update $V$ when the $i$th element is
		deleted.
		\begin{equation}
		V_{[i]}^{-1} = \Lambda_{[i]} - \frac{\lambda
			\lambda\prime}{\nu^{}ii}
		\end{equation}
		
		The second of christensen's propostions is the following set of
		equations, which are variants of the Sherman Wood bury updating
		formula.
		\begin{eqnarray}
		X'_{[i]}V_{[i]}^{-1}X_{[i]} &=& X' V^{-1}X -
		\frac{\hat{x}_{i}\hat{x}'_{i}}{s_{i}}\\
		(X'_{[i]}V_{[i]}^{-1}X_{[i]})^{-1} &=& (X' V^{-1}X)^{-1} +
		\frac{(X' V^{-1}X)^{-1}\hat{x}_{i}\hat{x}' _{i}
			(X' V^{-1}X)^{-1}}{s_{i}- \bar{h}_{i}}\\
		X'_{[i]}V_{[i]}^{-1}Y_{[i]} &=& X\prime V^{-1}Y -
		\frac{\hat{x}_{i}\hat{y}' _{i}}{s_{i}}
		\end{eqnarray}
		
		
		
		
		
		
		% In LME models, fitted by either ML or REML, an important overall
		% influence measure is the likelihood distance \citep{cook82}. The
		% procedure requires the calculation of the full data estimates
		% $\hat{\psi}$ and estimates based on the reduced data set
		% $\hat{\psi}_{(U)}$. The likelihood distance is given by
		% determining
		%
		%
		% \begin{eqnarray}
		% 	LD_{(U)} &=& 2\{l(\hat{\psi}) - l( \hat{\psi}_{(U)}) \}\\
		% 	RLD_{(U)} &=& 2\{l_{R}(\hat{\psi}) - l_{R}(\hat{\psi}_{(U)})\}
		% \end{eqnarray}
		
	\subsubsection{Influence on measure component ratios}               %-Case Deletion section 6.2.2
	The general diagnostic tools for variance component ratios are the analogues of the Cook's distance and the Information Ratio.
	
	
	\begin{eqnarray*}
		CD_{U}(\gamma) = (\hat{\gamma}_{(U)} - \hat{\gamma})^{\prime}[\mbox{var}(\hat{\gamma})]^{-1}(\hat{\gamma}_{(U)} - \hat{\gamma})\\
		&= -\boldsymbol{g^{\prime}}_{(U)} (\boldsymbol{Q}-\boldsymbol{G})^{-1}\boldsymbol{Q}(\boldsymbol{Q}-\boldsymbol{G})\boldsymbol{g}_{(U)} \\
		&= \boldsymbol{g^{\prime}}_{(U)} (\boldsymbol{I}_{r}  \mbox{var}(\hat{\gamma})\boldsymbol{G})^{-2}\mbox{var}(\hat{\gamma})\boldsymbol{g}_{(U)}
	\end{eqnarray*}
	
	Large values of $CD(\gamma)$ highlight observation groups for closer attentions
	
	
	\begin{eqnarray*}
		IR{\gamma}  = \frac{\mbox{det}(\boldsymbol{Q} - \boldsymbol{G})}{\mbox{det}(\boldsymbol{Q})}
	\end{eqnarray*}
	
	Ideally when all observations have the same influence on the information matrix $IR{\gamma}$ is approximately one.
	Deviations from one indicate the group $U$ is influential. Since $\mbox{var}(\hat{\gamma})$ and $\boldsymbol{I}_{r}$ are fixed for all observations, $IR{\gamma}$ is a function of $\boldsymbol{G}$, in turn a function of $\boldsymbol{C}_{i}$ and $c_{ii}$.
	
		
		


\section{BXC - Model Terms}

\begin{itemize}
	\item Let $y_{mir}$ be the response of method $m$ on the $i$th subject
	at the $r-$th replicate.
	\item Let $\boldsymbol{y}_{ir}$ be the $2 \times 1$ vector of measurements
	corresponding to the $i-$th subject at the $r-$th replicate.
	\item Let $\boldsymbol{y}_{i}$ be the $R_i \times 1$ vector of
	measurements corresponding to the $i-$th subject, where $R_i$ is number of replicate measurements taken on item $i$.
	\item Let $\alpha_mi$ be the fixed effect parameter for method for subject $i$.
	\item Formally Roy uses a separate fixed effect parameter to describe the true value $\mu_i$, but later combines it with the other fixed effects when implementing the model.
	\item Let $u_{1i}$ and $u_{2i}$ be the random effects corresponding to methods for item $i$.
	
	\item $\boldsymbol{\epsilon}_{i}$ is a $n_{i}$-dimensional vector
	comprised of residual components. For the blood pressure data $n_{i} = 85$.
	
	\item $\boldsymbol{\beta}$ is the solutions of the means of the two methods. In the LME output, the bias ad corresponding
	t-value and p-values are presented. This is relevant to Roy's first test.\end{itemize}
%-----------------------------------------------------------------------------------%


\section{LME}
Consistent with the conventions of mixed models, \citet{pkc}
formulates the measurement $y_{ij} $from method $i$ on individual
$j$ as follows;
\begin{equation}
y_{ij} =P_{ij}\theta + W_{ij}v_{i} + X_{ij}b_{j} + Z_{ij}u_{j} +
\epsilon_{ij},     (j=1,2, i=1,2....n)
\end{equation}
The design matrix $P_{ij}$ , with its associated column vector
$\theta$, specifies the fixed effects common to both methods. The
fixed effect specific to the $j$th method is articulated by the
design matrix $W_{ij}$ and its column vector $v_{i}$. The random
effects common to both methods is specified in the design matrix
$X_{ij}$, with vector $b_{j}$ whereas the random effects specific
to the $i$th subject by the $j$th method is expressed by $Z_{ij}$,
and vector $u_{j}$. Noticeably this notation is not consistent
with that described previously.  The design matrices are specified
so as to includes a fixed intercept for each method, and a random
intercept for each individual. Additional assumptions must also be
specified;
\begin{equation}
v_{ij} \sim N(0,\Sigma),
\end{equation}
These vectors are assumed to be independent for different $i$s,
and are also mutually independent. All Covariance matrices are
positive definite.  In the above model effects can be classed as
those common to both methods, and those that vary with method.
When considering differences, the effects common to both
effectively cancel each other out. The differences of each pair of
measurements can be specified as following;
\begin{equation}
d_{ij} = X_{ij}b_{j} + Z_{ij}u_{j} + \epsilon_{ij},     (j=1,2,
i=1,2....n)
\end{equation}
This formulation has seperate distributional assumption from the
model stated previously.

This agreement covariate $x$ is the key step in how this
methodology assesses agreement.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%5






\section{Remarks}
The relationship between precision and the within-item and between-item variability must be established. Roy establishes the equivalence of repeatability and within-item variability, and hence precision.  The method with the smaller within-item variability can be deemed to be the more precise.

A useful approach is to compute the confidence intervals for the ratio of within-item standard deviations (equivalent to the ratio of repeatability coefficients), which can be interpreted in the usual manner.  

In fact, the ratio of within-item standard deviations, with the attendant confidence interval,  can be determined using a single R command: \texttt{intervals()}.

Pinheiro and Bates (pg 93-95) give a description of how confidence intervals for the variance components are computed. Furthermore a complete set of confidence intervals can be computed to complement the variance component estimates. 

What is required is the computation of the variance ratios of within-item and between-item standard deviations.  

A naive  approach would be to compute the variance ratios by relevant F distribution quantiles. However, the question arises as to the appropriate degrees of freedom.
Limits of agreement are easily computable using the LME framework. While we will not be considering this analysis, a demonstration will be provided in the example.

%============================================================== %


	\chapter{LME Likelihood}

\section{PRESS}
	% The DFBETA for a particular observation is the difference between the regression coefficient for an included variable calculated for all of the data and the regression coefficient calculated with the observation deleted, scaled by the standard error calculated with the observation deleted.
	
	
	
	%===================================%
	
	
	% % - http://support.sas.com/documentation/cdl/en/statug/63347/HTML/default/viewer.htm#statug_mixed_sect027.htm
	An (unconditional) predicted value is $\hat{y}_i = x^{\prime}_i \boldsymbol{\hat{\beta}}$, where
	the vector $x_i$ is the $i$th row of $\boldsymbol{X}$.
	
	%	For an \texttt{lme} object, such as our fitted model \texttt{JS.roy1}, the predicted values for each subject can be determined using the \texttt{coef.lme} function.
	%	\begin{framed}
	%		\begin{verbatim}
	%		> JS.roy1 %>% coef %>% head(5)
	%		methodJ   methodS
	%		74     84.31724  91.08404
	%		36     91.54994  97.05548
	%		3      81.16581  96.48653
	%		62     92.09493  90.89073
	%		31     88.41411 103.38802
	%		\end{verbatim}
	%	\end{framed}
	
 %http://support.sas.com/documentation/cdl/en/statug/63347/HTML/default/viewer.htm#statug_mixed_sect027.htm

	An (unconditional) predicted value is $\hat{y}_i = x^{\prime}_i \boldsymbol{\hat{\beta}}$, where
	the vector $x_i$ is the $i$th row of $\boldsymbol{X}$.
	The (raw) residual is given as $\varepsilon_i = y_i - \hat{y}_i$. The PRESS residual is
	similarly constructed, using the predicted value for observation $i$ with a model fitted from reduced data.
	\[ \varepsilon_{i(U)} = y_i - x^{\prime}_i \boldsymbol{\hat{\beta}}_{(U)} \]
	
	
	%---------------------------------------------------------------------------%
	
	


	\section{One Way ANOVA}
	\subsection{Page 448}
	Computing the variance of $\hat{\beta}$
	\begin{eqnarray}
	\mbox{var}(\hat{\beta}) = (X^{\prime}V^{-1}X)^-1
	\end{eqnarray}
	It is not necessary to compute $V^{-1}$ explicitly.
	
	\begin{eqnarray}
	V^{-1}X &= \Sigma^{1}{X-Z()Z^{\prime}\Sigma^{-1}X} \\
	&= \Sigma^{-1}(X-Zb_{x})
	\end{eqnarray}
	
	The estimate $b_{x}$ is the same term obtained from the random effects model; $X = Zb_{x} + e$, using $X$ as an outcome variable.
	This formula is convenient in applications where $b_{x}$ can be easily computed. Since $X$ is a matrix of $p$ columns, $b_{x}$ can simple be computed column by column. according to the columns of $X$.
	\subsection{Page 448- simple example}
	Consider a simple model of the form;
	\begin{equation*}
	y_{ij} = \mu + \beta_{i} + \epsilon_{ij}.
	\end{equation*}
	
	The iterative procedure is as follows Evaluate the individual group mean $\bar{y_{i}}$ and variance $\hat{Sigma^2}_{i}$. Then use the variance of the group means as an estimate of the $\sigma^2_{b}$. The average of the the variances of the groups is the initial estimate of the $\sigma^2_{e}$.
	\subsubsection{Iterative procedure}
	
	The iterative procedure comprises two steps, with $0$ as the first approximation of $b_{i}$.
	
	The first step is to compute $\lambda$, the ratio of variabilities,
	
	\begin{equation*}
	\lambda = \frac{\sigma^2_{b}}{\sigma^2_{e}}
	\end{equation*}
	
	\begin{eqnarray*}
		\mu = \frac{1}{N} \sum_{ij} (y_{ij} - b_{i}) \\
		b_{i} = \frac{n(\bar{y_{i}}-\mu)}{n+ \lambda} \\
	\end{eqnarray*}
	
	
	The second step is to updat $sigma^2_{e}$
	
	\begin{equation}
	\sigma^2_{e} = \frac{e^{\prime}e}{N-df}
	\end{equation}
	
	where $e$ is the vector of $e_{ij} = y_{ij}-\mu-b_{i}$ and $df =
	qn / n+\lambda$ and
	\begin{equation}
	\sigma^{2}_{b} = \frac{1}{q} \sum_{i=1}^{q} b_{1}^2 +
	(\frac{n}{\sigma^2_{e}}+\frac{1}{\sigma^2_{b}})^{-1}
	\end{equation}
	
	\subsubsection{Worked Example}
	
	Further to [pawitan 17.1] the initial estimates for variability
	are $\sigma^{2}_{b} = 1.7698$ and $\sigma^{2}_{e} = 0.3254$. At
	convergence the following results are obtained.
	\\
	n=16, q=5
	\begin{eqnarray*}
		\hat{\mu} = \bar{y} = 14.175 \\
		\hat{\sigma}^2 = 0.325\\
		\hat{\sigma}^2_{b} = 1.395\\
		\sigma  = 0.986 \\
	\end{eqnarray*}
	At convergene the following estimates are obtained,
	\begin{eqnarray*}
		\hat{\mu} = 14.1751 \\
		\hat{b}= (-0.6211, 0.2683,1.4389,-1.914,0.8279)\\
		\hat{\sigma}^2_{b} = 1.3955\\
		\hat{\sigma}^2_{e} = 0.3254\\
	\end{eqnarray*}
	

	
	

	\section{Sampling}
	\emph{
		One important feature of replicate observations is that they should be independent
		of each other. In essence, this is achieved by ensuring that the observer makes each
		measurement independent of knowledge of the previous value(s). This may be difficult
		to achieve in practice.} (Check who said this
	)
	
	
	
	
	
	
	
	\section{Conclusion}
	\citet{BXC2008} and \citet{ARoy2009} highlight the need for method comparison methodologies suitable for use in the presence of replicate measurements. \citet{ARoy2009} presents a comprehensive methodology for assessing the agreement of two methods, for replicate measurements. This methodology has the added benefit of overcoming the problems of unbalanced data and unequal numbers of replicates. Implementation of the methodology, and interpretation of the results, is relatively easy for practitioners who have only basic statistical training. Furthermore, it can be shown that widely used existing methodologies, such as the limits of agreement, can be incorporated into ARoy2009's methodology.
	%=========================================================================================================================================== %
	%=========================================================================================================================================== %
	
	\section*{Permutation Test, Power Tests and Missing Data }
	
	This section explores topics such as dependent variable simulation and power analysis, introduced by Galecki \& Burzykowski (2013), and implementable with their \textbf{\textit{nlmeU}} \texttt{R} package.
	
	Using the \textbf{\textit{predictmeans}} \texttt{R} package, it is possible to perform permutation t-tests for coefficients of (fixed) effects and permutation F-tests.
	
	The matter of missing data has not been commonly encountered in either Method Comparison Studies or Linear Mixed Effects Modelling. However ARoy2009 (2009) deals with the relevant assumptions regrading missing data. 
	
	Galecki \& Burzykowski (2013) approaches the subject of missing data in LME Modelling. The \textbf{\textit{nlmeU}} package includes the \texttt{patMiss} function, which ``\textit{allows to compactly present pattern of missing data in a given vector/matrix/data
		frame or combination of thereof}".
	
	
	%================================================%
	
\subsection{EBLUPS-Diagnostics for Random Effects}
%% West Page 42 Section 2.8.3
\citet{west} recommends the empirical Bayes predictor, also known as EBLUPS as a diagnostic tool for Random effects. Checking EBLUPS for normality is of limited value.


%--------------------------------------------------------------------------------------------------------%
%%EBLUP

%-http://chjs.deuv.cl/Vol3N1/ChJS-03-01-05.pdf

The EBLUP is useful to identify outlier subjects given that it represents the distance
between the population mean value and the value predicted for the ith subject. A way of
using the EBLUP to search for outliers subjects is to use the Mahalanobis distance (see
Waternaux et al., 1989), FORMULA

. It is also possible to use the EBLUP
to verify the random effects normality assumption. For more information; see Nobre and
Singer (2007). In Table 2 we summarize diagnostic techniques involving residuals discussed
in Nobre and Singer (2007).

%----------------------------------------------------%



	\chapter{General Appendices}
	$\Lambda = \frac{\mbox{max}_{H_{0}}L}{\mbox{max}_{H_{1}}L}$
	
	\subsection{Extending deletion diagnostics to LMEs}
	
	
	\citet{Christensen} notes the case deletion diagnostics techniques have not been applied to linear mixed effects models and seeks to develop methodologies in that respect. \citet{Christensen} develops these techniques in the context of REML
	
	% www.jds-online.com/file_download/70/JDS-205.pdf
	
	\begin{eqnarray*}
		X= \left[%
		\begin{array}{c}
			x^\prime_{i} \\
			X(i) \\
		\end{array}%
		\right],
		Z= \left[%
		\begin{array}{c}
			z^\prime_{ij} \\
			Z_{j(i)} \\
		\end{array}%
		\right] ,
		Z = \left[%
		\begin{array}{c}
			z^\prime_{ij} \\
			Z_{j(i)} \\
		\end{array}%
		\right], \\
		y = \left[%
		\begin{array}{c}
			y^\prime_{ij} \\
			y_{j(i)} \\
		\end{array}%
		\right]
		\mbox{ and } H = \left[%
		\begin{array}{cc}
			h_{ii}& h\\
			h_{j(i)} & h\\
		\end{array}%
		\right]
	\end{eqnarray*}
	
	For notational simplicity, $\boldsymbol{A}_{(i)}$ denotes an $n
	\times m$ matrix  $\boldsymbol{A}$ with the $i$-th row removed,
	$\boldsymbol{a}_{i}$ denotes the $i$-th row of $\boldsymbol{A}$,
	and $a_{ij}$ denotes the $(i, j)$-th element of $\boldsymbol{A}$.
	
	$\boldsymbol{a}_{(i)}$ denotes a vector $\boldsymbol{a}$ with the $i$-th element, $a_{i}$, removed.
	
	\begin{equation}
	\breve{a_{i}} =  \boldsymbol{a}_{i} -
	\boldsymbol{A}_{(i)}\boldsymbol{H}_{[i]}\boldsymbol{h}_{i}
	\end{equation}
%=======================================================%
\section{Unknown Material}


To standardize the assessment of how influential data is, several measures of influence are commonly used, such as DFBETAS 
and Cook’s Distance.





Although influential cases thus have extreme values on one or more of the variables, they can be onliers
rather than outliers. 

To account for this, the (standardized) deleted residual is defined as the difference between
the observed score of a case on the dependent variable, and the predicted score from the regression
model fitted from data when that case is omitted.


Just as influential cases are not necessarily outliers, outliers are not necessarily influential cases. 

This also holds for deleted residuals. The reason for this is that the amount of influence a case exerts on the regression slope is not only determined by how well its (observed) score is fitted by the specified
regression model, but also by its score(s) on the independent variable(s). The degree to which the scores of a case on the independent variable(s) are extreme is indicated by the leverage of this case. 


%=========================================================%





%=========================================================%


\newpage

%\subsubsection{Deviance}
%In statistics, deviance is a quality of fit statistic for a model that is often used for statistical hypothesis testing. It is a generalization of the idea of using the sum of squares of residuals in ordinary least squares to cases where model-fitting is achieved by maximum likelihood.
%
\subsection{Estimation}

\begin{eqnarray}
\hat{\beta} &=& X^{T} \\
\hat{\gamma} &=& G(\hat{\theta})Z^{T}
\end{eqnarray}

The difference between perturbation and residual analysis between the linear and LME models.
The estimates of the fixed effects $\beta$ depend on the estimates of the covariance parameters.
\subsection{Zewotir-Cook's Distance}

Diagnostic tool for variance components
\[ C_{\theta i} =(\hat(\theta)_{[i]} - \hat(\theta))^{T}\mbox{cov}( \hat(\theta))^{-1}(\hat(\theta)_{[i]} - \hat(\theta))\]

\begin{description}
	\item[linear functions]
	$CD(\psi)_i$ does not have to be calculated unless $CD(\beta)_i$ is large.
\end{description}


It is also desirable to measure the influence of the case deletions on the covariance matrix of $\hat{\beta}$.
% % - Fixed Effects Parameter		

For fixed effects parameter estimates in LME models, the \index{Cook's distance} Cook's distance can be extended to measure influence on these fixed effects.

\[
\mbox{CD}_{i}(\beta) = \frac{(c_{ii} - r_{ii}) \times t^2_{i}}{r_{ii} \times p}
\]


For random effect estimates, the \index{Cook's distance} Cook's distance is

\[
\mbox{CD}_{i}(b) = g{\prime}_{(i)} (I_{r} + \mbox{var}(\hat{b})D)^{-2}\mbox{var}(\hat{b})g_{(i)}.
\]

Large values for Cook's distance indicate observations for special attention.


For linear functions, $CD(\psi)_i$ does not have to be calculated unless $CD(\beta)_i$ is large.
%===================================================== %
\subsubsection{Mean Square Prediction Error}
\begin{equation}
MSPR = \frac{\sum (y_{i}-\hat{y}_{i})^2}{n^*}
\end{equation}

%===================================================== %
\subsection{Leverage}
Leverage can be defined through the projection matrix that results from a transformation of the model with the inverse of the Cholesky decomposition of $\boldsymbol{V}$, or an oblique projector:	$\boldsymbol{Y} = \boldsymbol{H}\boldsymbol{\hat{Y}}$.

While $H$ is idempotent, it is generally not symmetric and thus not a projection matrix in the narrow sense.
\[ h_{ii} = x^{\prime}_{i}(X^{\prime}X)^{-1}x_{i} \]
The trace of $\boldsymbol{H}$ equals the rank of $\boldsymbol{X}$.
If $V_{ij}$ denotes the element in row $i$, column $j$ of $\boldsymbol{V}^{-1}$, then for a model containing only an intercept the diagonal elements of $\boldsymbol{H}$.

\[ h_{ii} = \frac{\sum v_{ij}}{\sum \sum v_{ij}} \]

%========================================================%
\subsubsection{PRESS}
\citet{schabenberger} descibes the use of the $PRESS$ and $DFFITS$ in determining influence.

The $PRESS$ residual is the difference between the observed value and the predicted (marginal)value.
\begin{equation}
\hat{e_{i}}_{(U)} = y_{i} - x\hat{\beta}_{(U)}
\end{equation}

The prediction residual sum of squares (PRESS) is an value associated with this calculation. When fitting linear models, PRESS can be used as a criterion for model selection, with smaller values indicating better model fits.
\begin{equation}
PRESS = \sum(y-y^{(k)})^2
\end{equation}
\begin{eqnarray*}
	e_{-Q} = y_{Q} - x_{Q}\hat{\beta}^{-Q}\\
	PRESS = \sum(y-y^{-Q})^2\\
	PRESS_{(U)} = y_{i} - x\hat{\beta}_{(U)}\\
\end{eqnarray*}

\subsubsection{PRESS Residuals and PRESS Statistic}
% % - Wikipedia
The predicted residual sum of squares (PRESS) statistic is a form of cross-validation used in regression analysis to provide a summary measure of the fit of a model to a sample of observations that were not themselves used to estimate the model. It is calculated as the sums of squares of the prediction residuals for those observations.

A fitted model having been produced, each observation in turn is removed and the model is refitted using the remaining observations. The out-of-sample predicted value is calculated for the omitted observation in each case, and the PRESS statistic is calculated as the sum of the squares of all the resulting prediction errors:[4]
\[\mbox{PRESS} =\sum_{i=1}^n (y_i - \hat{y}_{i, -i})^2 \]

Given this procedure, the PRESS statistic can be calculated for a number of candidate model structures for the same dataset, with the lowest values of PRESS indicating the best structures. Models that are over-parameterised (over-fitted) would tend to give small residuals for observations included in the model-fitting but large residuals for observations that are excluded.





%============================================== %
\subsection{Local Influence}

\citet{Christensen} developed their global influences for the deletion of single observations in two steps: a one-step estimate for the REML (or ML) estimate of the variance components, and an ordinary case-deletion diagnostic for a weighted regression problem (conditional on the estimated covariance matrix) for fixed effects.

%============================================== %
%- F:
\bibliographystyle{chicago}
\bibliography{DB-txfrbib}	
	
	%----------------------------------------------------------------------------------------------%
	
	%http://blog.minitab.com/blog/adventures-in-statistics/why-you-need-to-check-your-residual-plots-for-regression-analysis
	In the graph above, you can predict non-zero values for the residuals based on the fitted value. For example, a fitted value of 8 has an expected residual that is negative. Conversely, a fitted value of 5 or 11 has an expected residual that is positive.
	
	The non-random pattern in the residuals indicates that the deterministic portion (predictor variables) of the model is not capturing some explanatory information that is “leaking” into the residuals. The graph could represent several ways in which the model is not explaining all that is possible. 
	
	Possibilities include:
	
	\begin{itemize}
		\item A missing variable
		\item A missing higher-order term of a variable in the model to explain the curvature
		\item A missing interction between terms already in the model
	\end{itemize}
	
	
	Identifying and fixing the problem so that the predictors now explain the information that they missed before should produce a good-looking set of residuals.
	
	In addition to the above, here are two more specific ways that predictive information can sneak into the residuals:
	
	The residuals should not be correlated with another variable. If you can predict the residuals with another variable, that variable should be included in the model. In Minitab’s regression, you can plot the residuals by other variables to look for this problem.
	
	\noindent \textbf{Autocorrelation} \\
	Adjacent residuals should not be correlated with each other (\textbf{autocorrelation}). If you can use one residual to predict the next residual, there is some predictive information present that is not captured by the predictors. Typically, this situation involves time-ordered observations. For example, if a residual is more likely to be followed by another residual that has the same sign, adjacent residuals are positively correlated. You can include a variable that captures the relevant time-related information, or use a time series analysis. 
	
	In Minitab’s regression, you can perform the \textbf{\textit{Durbin-Watson} }test to test for autocorrelation.
	

	\section{ICC, Reproducibility Index and Passing-Bablok }
	
	
	\subsection{Intraclass Correlation Coefficient} This measure of agreement is estimated using variance components from appropriate analysis of variance models. Measures of agreement are variance dependent, and so the ICC can be misleading. The ICC takes a value between $0$ and $1$, and is based on Analysis of Variance
	methodologies.
	\\
	The ICC is a measure of reliability. \citet{bartko} considers the ICC as just another measure of agreement.
	
	%-------------------------------------------------------------------------------%
	
	\subsection*{Intra-class correlation coefficient}
	
	The ICC, which takes on values between 0 and 1, is based on analysis of variance techniques. It is close to 1 when the differences between paired measurements is very small compared to the differences between subjects. Of these three procedures--t test, correlation coefficient, intra-class correlation coefficient--the ICC is best because it can be large only if there is no bias and the paired measurements are in good agreement, but it suffers from the same faults ii and iii as ordinary correlation coefficients. The magnitude of the ICC can be manipulated by the choice of samples to split and says nothing about the magnitude of the paired differences.
	
	
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	
	
	
	
	\subsection{Passing and Bablok (1983) }
	Passing \& Bablok have described a linear regression model that
	are without the usual assumptions regarding the distribution of
	the samples and the measurement errors. The result does not depend
	on the assignment of the methods (or instruments) to X and Y. The
	slope and intercept  are calculated with their 95\% confidence
	interval.Hypothesis tests on the slope and intercept maybe then
	carried out.
	\\
	If the hypothesis of the intercept is rejected, then it is
	concluded that it is significant different from $0$ and both
	raters differ at least by a constant amount.
	\\
	If the hypothesis of the slope is rejected, then it is concluded
	that the slope is significant different from $1$ and there is at
	least a proportional difference between the two raters.
	
	\subsection{Lin's Reproducibility Index} Lin proposes the use of a
	reproducibility index, called the Concordance Correlation
	Coefficent (CCC). While it is not strictly a measure of agreement
	as such, it can form part of an overall method comparision
	methodology.

	%-------------------------------------------------------------------------------%

	\section{Repeated Measurements}
	
	In cases where there are repeated measurements by each of the two
	methods on the same subjects , Bland Altman suggest calculating
	the mean for each method on each subject and use these pairs of
	means to compare the two methods.
	The estimate of bias will be unaffected using this approach, but
	the estimate of the standard deviation of the differences will be
	too small, because of the reduction of the effect of repeated
	measurement error. Bland Altman propose a correction for this.
	Carstensen attends to this issue also, adding that another
	approach would be to treat each repeated measurement separately.
	
	
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	
	In this model , the variances of the random effects must depend on
	$m$, since the different methods do not necessarily measure on the
	same scale, and different methods naturally must be assumed to
	have different variances. \citet{BXC2004} attends to the issue of
	comparative variances.
	%----------------------------------------------------------------------------%




	\section{RSquared for LME models}
	
	As a complement to this, one can also consider how to properly employ the $R^2$ measure, in the context of Methoc Comparison Studies, further to the work by Edwards et al, namely ``An $R^2$ statistic for fixed effects in the linear mixed model".
	
	\begin{framed}
		
		\begin{quote}
			\textbf{Abstract for ``An $R^2$ statistic for fixed effects in the linear mixed model"}
			Statisticians most often use the linear mixed model to analyze Gaussian longitudinal data. 
			
			The value and familiarity of the R2 statistic in the linear univariate model naturally creates great interest in extending it to the linear mixed model. We define and describe how to compute a model R2 statistic for the linear mixed model by using only a single model. 
			
			The proposed R2 statistic measures multivariate association between the repeated outcomes and the fixed effects in the linear mixed model. The R2 statistic arises as a 1–1 function of an appropriate F statistic for testing all fixed effects (except typically the intercept) in a full model. 
			
			The statistic compares the full model with a null model with all fixed effects deleted (except typically the intercept) while retaining exactly the same covariance structure. 
			
			Furthermore, the R2 statistic leads immediately to a natural definition of a partial R2 statistic. A mixed model in which ethnicity gives a very small p-value as a longitudinal predictor of blood pressure (BP) compellingly illustrates the value of the statistic. 
			
			In sharp contrast to the extreme p-value, a very small $R^2$ , a measure of statistical and scientific importance, indicates that ethnicity has an almost negligible association with the repeated BP outcomes for the study.
		\end{quote}
	\end{framed}
	
	\section{Remarks on the Multivariate Normal Distribution}
	
	Diligence is required when considering the models. Carstensen specifies his models in terms of the univariate normal distribution. ARoy2009's model is specified using the bivariate normal distribution.
	This gives rises to a key difference between the two model, in that a bivariate model accounts for covariance between the variables of interest.
	The multivariate normal distribution of a $k$-dimensional random vector $X = [X_1, X_2, \ldots, X_k]$
	can be written in the following notation:
	\[
	X\ \sim\ \mathcal{N}(\mu,\, \Sigma),
	\]
	or to make it explicitly known that $X$ is $k$-dimensional,
	\[
	X\ \sim\ \mathcal{N}_k(\mu,\, \Sigma).
	\]
	with $k$-dimensional mean vector
	\[ \mu = [ \operatorname{E}[X_1], \operatorname{E}[X_2], \ldots, \operatorname{E}[X_k]] \]
	and $k \times k$ covariance matrix
	\[ \Sigma = [\operatorname{Cov}[X_i, X_j]], \; i=1,2,\ldots,k; \; j=1,2,\ldots,k \]
	
	\bigskip
	
	\begin{enumerate}
		\item Univariate Normal Distribution
		
		\[
		X\ \sim\ \mathcal{N}(\mu,\, \sigma^2),
		\]
		
		\item Bivariate Normal Distribution
		
		\begin{itemize}
			\item[(a)] \[  X\ \sim\ \mathcal{N}_2(\mu,\, \Sigma), \vspace{1cm}\]
			\item[(b)] \[    \mu = \begin{pmatrix} \mu_x \\ \mu_y \end{pmatrix}, \quad
			\Sigma = \begin{pmatrix} \sigma_x^2 & \rho \sigma_x \sigma_y \\
			\rho \sigma_x \sigma_y  & \sigma_y^2 \end{pmatrix}.\]
		\end{itemize}
	\end{enumerate}
	
	
	
	\subsection{Lin's Reproducibility Index} Lin proposes the use of a
	reproducibility index, called the Concordance Correlation
	Coefficent (CCC).While it is not strictly a measure of agreement
	as such, it can form part of an overall method comparision
	methodology.
\section{Measurement Error Models}

\citet{DunnSEME} proposes a measurement error model for use in
method comparison studies. Consider n pairs of measurements
$X_{i}$ and $Y_{i}$ for $i=1,2,...n$.
\begin{equation}
X_{i} = \tau_{i}+\delta_{i}\\
\end{equation}
\begin{equation}
Y_{i} = \alpha +\beta\tau_{i}+\epsilon_{i} \nonumber
\end{equation}

In the above formulation is in the form of a linear structural
relationship, with $\tau_{i}$ and $\beta\tau_{i}$ as the true
values , and $\delta_{i}$ and $\epsilon_{i}$ as the corresponding
measurement errors. In the case where the units of measurement are
the same, then $\beta =1$.

\begin{equation}
E(X_{i}) = \tau_{i}\\
\end{equation}
\begin{equation}
E(Y_{i}) = \alpha +\beta\tau_{i} \nonumber
\end{equation}
\begin{equation}
E(\delta_{i}) = E(\epsilon_{i}) = 0 \nonumber
\end{equation}

The value $\alpha$ is the inter-method bias between the two
methods.


\begin{eqnarray}
z_0 &=& d = 0 \\
z_{n+1} &=& z_n^2+c
\end{eqnarray}


	
\subsection{The Problem of Identifiability}
\citet{DunnSEME} highlights an important issue regarding using
models such as these, the identifiability problem. This comes as a
result of there being too many parameters to be estimated.
Therefore assumptions about some parameters, or estimators used,
must be made so that others can be estimated. 

For example $\alpha$
may take the value of the inter-method bias estimate from Bland -
Altman methodology. 


For example in literature the variance
ratio $\lambda=\frac{\sigma^{2}_{1}}{\sigma^{2}_{2}}$
must often be assumed to be equal to $1$ \citep{linnet98}.\citet{DunnSEME} considers methodologies based on two methods with single measurements on each subject as inadequate for a serious
study on the measurement characteristics of the methods. This is
because there would not be enough data to allow for a meaningful
analysis. There is, however, a contrary argument that in many
practical settings it is very difficult to get replicate
observations when the measurement method requires invasive medical
procedure.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Bartko's BB

\subsection{Identifiability}
In many models,  naïve assumptions are required to overcome issues of identifiabilty.
Precision is defined by the reciprocal of the variance of the random errors. 
Also it is assumed that the error variance is independent of the amount of material being measured. However, in practice, this is often not the case. Variability increases over the scale of measurements over many cases.
Estimators of scale parameters are estimable only if the analyst is prepared to make naïve, if not unacceptable, assumptions.

Equation 4 
$\psi$  and $\varepsilon$ are statistically independent of each other.
Contamination effect that arises from non-specificity /  specimen specific bias.
Random error is measured by ε. Homogenity of variances is assumed.
If there are no replicate measures,  both variances are completely confounded, and there is no way of telling them apart.
Scaling of new measurements is measured by β.


\section{Carstensen Model (mir model)}

A measurement $y_{mi}$ by method $m$ on individual $i$ is formulated as follows;
\begin{equation}
y_{mi}  = \alpha_{m} + \mu_{i} + e_{mi} \qquad  e_{mi} \sim
\mathcal{N}(0,\sigma^{2}_{m})
\end{equation}

The differences are expressed as $d_{i} = y_{1i} - y_{2i}$. For the replicate case, an interaction term $c$ is added to the model, with an associated variance component. All the random effects are assumed independent, and that all replicate measurements are assumed to be exchangeable within each method.

%----

The following model (in the authors own notation) is
formulated as follows, where $y_{mir}$ is the $r$th replicate measurement on subject $i$ with method $m$.


Using Carstensen's notation, a measurement $y_{mi}$ by method $m$ on individual $i$ the measurement $y_{mir} $ is the $r$th replicate measurement on the $i$th item by the $m$th method, where $m=1,2,$ $i=1,\ldots,N,$ and $r = 1,\ldots,n_i$ is formulated as follows;

\begin{equation}
y_{mir}  = \alpha_{m} + \mu_{i} + c_{mi} + \epsilon_{mir}, \qquad  e_{mi}
\sim \mathcal{N}(0,\sigma^{2}_{m}), \quad c_{mi} \sim \mathcal{N}(0,\tau^{2}_{m}).
\end{equation}

Let $y_{mir} $ be the $r$th replicate measurement on the $i$th item by the $m$th method, where $m=1,2,$ $i=1,\ldots,N,$ and $r = 1,\ldots,n_i.$ When the design is balanced and there is no ambiguity we can set $n_i=n.$ The LME model can be written
\begin{equation}
y_{mir} = \beta_{0} + \beta_{m} + b_{mi} + \epsilon_{mir}.
\end{equation}
Here $\beta_0$ and $\beta_m$ are fixed-effect terms representing, respectively, a model intercept and an overall effect for method $m.$ The model can be reparameterized by gathering the $\beta$ terms together into (fixed effect) intercept terms $\alpha_m=\beta_0+\beta_m.$ The $b_{1i}$ and $b_{2i}$ terms are correlated random effect parameters having $\mathrm{E}(b_{mi})=0$ with $\mathrm{Var}(b_{mi})=d^2_m$ and $\mathrm{Cov}(b_{1i}, b_{2 i})=d_{12}.$ 

%Here $\beta_0$ and $\beta_m$ are fixed-effect terms representing, respectively, a model intercept and an overall effect for method $m.$ The $b_{1i}$ and $b_{2i}$ terms represent random effect parameters corresponding to the two methods, having $\mathrm{E}(b_{mi})=0$ with $\mathrm{Var}(b_{mi})=d^2_m$ and $\mathrm{Cov}(b_{mi}, b_{m^\prime i})=g_{12}.$ 

%The random error term for each response is denoted $\epsilon_{mir}$ having $\mathrm{E}(\epsilon_{mir})=0$, $\mathrm{Var}(\epsilon_{mir})=\sigma^2_m$, $\mathrm{Cov}(\epsilon_{1ir}, \epsilon_{2 ir})=\sigma_{12}$, $\mathrm{Cov}(\epsilon_{mir}, \epsilon_{mir^\prime})= 0$ and $\mathrm{Cov}(\epsilon_{1ir}, \epsilon_{2 ir^\prime})= 0.$ 
The random error term for each response is denoted $\epsilon_{mir}$ having $\mathrm{E}(\epsilon_{mir})=0$, $\mathrm{Var}(\epsilon_{mir})=\sigma^2_m$, $\mathrm{Cov}(b_{mir}, b_{m^\prime ir})=\sigma_{12}$, $\mathrm{Cov}(\epsilon_{mir}, \epsilon_{mir^\prime})= 0$ and $\mathrm{Cov}(\epsilon_{mir}, \epsilon_{m^\prime ir^\prime})= 0.$
When two methods of measurement are in agreement, there is no significant differences between $\beta_1$ and $\beta_2,$ $d^2_1 $ and$ d^2_2$, and $\sigma^2_1 $ and$ \sigma^2_2$.
\bigskip

% Complete paragraph by specifying variances and covariances for epsilons.
% I thing that these are your sigmas?
% Also, state equality of the parameters in this model when each of the three hypotheses above are true.


Additionally these parameter are assumed to have Gaussian distribution. Two methods of measurement are in complete agreement if the null hypotheses $\mathrm{H}_1\colon \alpha_1 = \alpha_2$ and $\mathrm{H}_2\colon \sigma^2_1 = \sigma^2_2 $ and $\mathrm{H}_3\colon d^2_1= d^2_2$ hold simultaneously. \citet{ARoy2009} uses a Bonferroni correction to control the familywise error rate for tests of $\{\mathrm{H}_1, \mathrm{H}_2, \mathrm{H}_3\}$ and account for difficulties arising due to multiple testing. Additionally, Roy combines $\mathrm{H}_2$ and $\mathrm{H}_3$ into a single testable hypothesis $\mathrm{H}_4\colon \omega^2_1=\omega^2_2,$ where $\omega^2_m = \sigma^2_m + d^2_m$ represent the overall variability of method $m.$
%Disagreement in overall variability may be caused by different between-item variabilities, by different within-item variabilities, or by both.



Here the terms $\alpha_{m}$ and $\mu_{i}$ represent the fixed effect for method $m$ and a true value for item $i$ respectively. The random effect terms comprise an interaction term $c_{mi}$ and the residuals $\varepsilon_{mir}$.
The $c_{mi}$ term represent random effect parameters corresponding to the two methods, having $\mathrm{E}(c_{mi})= 0$ with $\mathrm{Var}(c_{mi})=\tau^2_m$.  

Carstensen specifies the variance of the interaction terms as being univariate normally distributed. As such, $\mathrm{Cov}(c_{mi}, c_{m^\prime i})= 0.$ All the random effects are assumed independent, and that all replicate measurements are assumed to be exchangeable within each method.




%---Key difference 1---The True Value
%---Colollary -- Difference in model types
The presence of the true value term $\mu_i$ gives rise to an important difference between Carstensen's and Roy's models. Of particular importance is terms of the model, a true value for item $i$ ($\mu_{i}$).  The fixed effect of Roy's model comprise of an intercept term and fixed effect terms for both methods, with no reference to the true value of any individual item. In other words, Roy considers the group of items being measured as a sample taken from a population. Therefore a distinction can be made between the two models: Roy's model is a standard LME model, whereas Carstensen's model is a more complex additive model.


%======================================================================================= %







%\emph{The formulation of this model is general and refers to comparison
%	of any number of methods  however, if only two methods are
%	compared, separate values of $\tau^2_1$ and $\tau^2_2$ cannot be
%	estimated, only their average value $\tau$, so in the case of only
%	two methods we are forced to assume that $\tau_1 = \tau_2 = \tau$} \citep{BXC2008}.





	\chapter{Bradley Blackwood}
	%----------------------------------------------------------------------------------------------------------------------%
	\section{Bartko's Bradley-Blackwood Test}
	This is a regression based
	approach that performs a simultaneous test for the equivalence of
	means and variances of the respective methods.We have identified
	this approach  to be examined to see if it can be used as a
	foundation for a test perform a test on
	means and variances individually.
	\begin{equation}
	D = (X_{1}-X_{2})
	\end{equation}
	\begin{equation}
	M = (X_{1} + X_{2}) /2
	\end{equation}
	The Bradley Blackwood Procedure fits D on M as follows:\\
	\begin{equation}
	D = \beta_{0} + \beta_{1}M
	\end{equation}
	\begin{itemize}
		\item The Bradley Blackwood test is a simultaneous test for bias and
		precision. They propose a regression approach which fits D on M,
		where D is the difference and average of a pair of results.
		\item Both beta values, the intercept and slope, are derived from the respective means and
		standard deviations of their respective data sets.
		\item We determine if the respective means and variances are equal if
		both beta values are simultaneously equal to zero. The Test is
		conducted using an F test, calculated from the results of a
		regression of D on M.
		\item We have identified this approach  to be examined to see if it can
		be used as a foundation for a test perform a test on means and
		variances individually.
		\item Russell et al have suggested this method be used in conjunction
		with a paired t-test , with estimates of slope and intercept.
	\end{itemize}
	%subsection{t-test}
	
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	%%%%%%%  Blackwood Bradley Model         %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	


	\section{Bradley-Blackwood Test (Kevin Hayes Talk)}
	%--------------------------------------------------------------------%
	% KH - UW
	
	This work considers the problem of testing $\mu_1$ = $\mu_2$ and $\sigma^2_1 = \sigma^2_2$ using a random sample from a bivariate normal distribution with parameters $(\mu_1, \mu_2, \sigma^2_1, \sigma^2_2, \rho)$. 
	
	The new contribution is a decomposition of the Bradley-Blackwood test statistic (\textit{Bradley and Blackwood, 1989})for the simultaneous test of {$\mu_1$ = $\mu_2$; $\sigma^2_1 = \sigma^2_2$}  as a sum of two statistics. 
	
	One is equivalent to the Pitman-Morgan (\textit{Pitman, 1939; Morgan, 1939}) test statistic 
	for $\sigma^2_1 = \sigma^2_2$ and the other one is a new alternative to the standard paired-t test of $\mu_D = \mu_1 = \mu_2 = 0$. 
	
	Surprisingly, the classic Student paired-t test makes no assumptions about the equality (or otherwise) of the 
	variance parameters. 
	
	The power functions for these tests are quite easy to derive, and show that when $\sigma^2_1 = \sigma^2_2$, 
	the paired t-test has a slight advantage over the new alternative in terms of power, but when $\sigma^2_1 \neq \sigma^2_2$, the 
	new test has substantially higher power than the paired-t test.
	
	While Bradley and Blackwood provide a test on the joint hypothesis of equal means and equal variances their regression based approach does not separate these two issues.
	
	The rejection of the joint hypothesis may be 
	due to two groups with unequal means and unequal variances; unequal means and equal variances, or equal means and unequal variances. We propose an approach for resolving this (model selection) problem in a manner controlling the magnitudes of the relevant type I error probabilities.
	
	
	
	
	\section*{Deming Regression}
	
	\begin{itemize}
		\item Informative analysis for the purposes of method comparison, Deming Regression is a regression technique taking into account uncertainty in both the independent and dependent variables.
		
		\item Deming’s method always results in one regression fit, regardless of which variable takes the place of the predictor variables.
		
		%Significant error in the least-squares slope estimation occurs when the ratio of the standard deviation of measurement of a single x value to the standard deviation of the indepedent variable data set exceeds 0.2.
		
		%Errors in the least-squares coefficients attributable to outliers can be avoided by eliminating data points whose vertical distance from the regression line exceed four times the standard error the estimate.
		
		\item The measurement error (lambda or $\lambda$) is specified with measurement error variance related as 
		\[\lambda = \sigma^2_y/\sigma^2_x\]
		
		(where $\sigma^2_x$ and $\sigma^2_y$ is the measurement error variance of the $x$ and $y$ variables, respectively).
		
		\item In the case where $\lambda$ is equal to one, (i.e. equal error variances), the methodology is equivalent to \textit{\textbf{orthogonal regression}}.
		
		\item Deming approaches the matter by simultaneously minimizing the sum of the square of the residuals of both variables. This derivation results in the best fit to minimize the sum of the squares of the perpendicular distances from the data points.
		
		\item To compute the slope by Deming’s formula,  normally distributed error of both variables  is assumed, as well as a constant level of imprecision throughout the range of measurements.
		
	\end{itemize}


\section{Simple Linear Regression}

% 1.A. Use of SLR, description of SLR as Model I
% 1.B. Inappropriate for MCS
% 1.C  Calibration and Conversion problems

Simple linear regression is defined as such with the name `Model I regression' by Cornbleet Gochman (1979), in contrast to 'Model II regression'.

On account of the fact that one set of measurements are linearly related to another, one could surmise that Linear Regression is the most suitable approach to analyzing comparisons. This approach is unsuitable on two counts. Firstly one of the assumptions of Regression analysis is that the independent variable values are without error. In method comparison studies one must assume the opposite; that there is error present in the measurements. Secondly a regression of X on Y would yield and entirely different result from Y on X.


Simple linear regression calculates a line of best fit for two
sets of data, n which the independent variable, X, is measured without error, with y as the dependent variable.  

SLR (Model I) regression is considered by many \citet{BA83,CornCoch,ludbrook97} to be wholly unsuitable for
method comparison studies, although recommended for use in calibration studies [Corncoch]. Even in the case where one
method is a gold standard , it is disputed as to whether it is a valid approach. Model II regression is more suitable for method comparison studies, but it is more difficult to execute. Both Model I and II regression models are unduly influenced by outliers. Regression Models can not be used to analyze repeated measurements

\subsubsection{Regression Analysis}
Another inappropriate approach is the regressing one set of measurements against the other. According to this methodology the measurement methods could considered equivalent if the confidence interval for
the regression coefficient included $1$. Analysts sometimes use least squares (referred to by Ludbrook as Model I) regression analysis to calibrate one method of measurement against another. In this technique, the sum of the squares of the vertical deviations of y values from the line is minimized. This approach is invalid, because both y and x values are attended by random error.


\subsubsection{The Identity Plot} This is a simple graphical approach, advocated by \citet{BA86}, that yields a cursory examination of how well the measurement methods agree. In the case of good agreement, the co-variates of the plot accord closely with the $X=Y$ line.

\subsubsection{Advantages of Regression Approaches for MCS}
\begin{itemize}
	\item These methods can be employed in conversion problems.
	\item Bland and Altman have stated that regression analysis offers insights into MCS problems.
\end{itemize}
\subsubsection{Disadvantages}
\begin{itemize}
	\item Regression methods are uninformative about the variability of the differences.
\end{itemize}

\begin{itemize}\item
	Regression methods can determine the presence of bias, and the levels of constant bias and proportional bias thereof \cite{ludbrook97,ludbrook02}.
\end{itemize}

%------------------------------------------------------------------------%

\section{Constant and Proportional Bias}

Linear Regression is a commonly used technique for comparing paired assays. The Intercept and Slope can provide estimates for the constant bias and proportional bias occurring between both methods. If the basic assumptions underlying linear regression are not met, the regression equation, and consequently the estimations
of bias are undermined. Outliers are a source of error in regression estimates.

Constant or proportional bias in method comparison studies using linear regression can be detected by an individual test on the intercept or the slope of the line regressed from the results of the two methods to be compared.





\section*{Bartko's Discussion of BB}

Let $y = X_1 - X_2$ and $x= (X_1 - X_2)/2$.
The Bradley-Blackwood procedure fits $y$ on $x$, such that
\[ y = \beta_0 + \beta_1x \]

The slope and intercepte are given bu

\[beta_1 =  \frac{(\sigma^2_1 = \sigma^2_2)}{2\sigma^2_x}\]
%------------------------------------------------%


\section*{Pitman's Test on Correlated variances}
%Bartko Page 741
\begin{description}
	\item[$H_0$] : $\sigma^2_1 = \sigma^2_2$
	\item[$H_0$] : $\sigma^2_1 = \sigma^2_2$
\end{description}


Pitman's test is identical to the slope equal to zero in the regression of $y$ on $x$.

%------------------------------------------------%



\section{Conclusions about Existing Methodologies}

The Bland Altman methodology is well noted for its ease of use,
and can be easily implemented with most software packages. Also it
doesn't require the practitioner to have more than basic
statistical training. The plot is quite informative about the
variability of the differences over the range of measurements. For
example, an inspection of the plot will indicate the 'fan effect'.
They also can be used to detect the presence of an outlier.

\citet{ludbrook97,ludbrook02} criticizes these plots on the
basis that they presents no information on effect of constant bias
or proportional bias. These plots are only practicable when both
methods measure in the same units. Hence they are totally
unsuitable for conversion problems. The limits of agreement are
somewhat arbitrarily constructed. They may or may not be suitable
for the data in question. It has been found that the limits given
are too wide to be acceptable. There is no guidance on how to deal
with outliers. Bland and Altman recognize effect they would have
on the limits of agreeement, but offer no guidance on how to
correct for those effects.

There is no formal testing procedure provided. Rather, it is upon
the practitioner opinion to judge the outcome of the methodology.





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%9 Appendix                  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%
%\section{Contention }
%Several papers have commented that this approach is undermined
%when the basic assumptions underlying linear regression are not
%met, the regression equation, and consequently the estimations of
%bias are undermined. Outliers are a source of error in regression
%estimates.In method comparison studies, the X variable is a
%precisely measured reference method. Cornbleet Gochman (1979)
%argued that criterion may be regarded as the correct value. Other
%papers dispute this.
%



%
%
%\section{A regression based approach based on Bland Altman Analysis}
%Lu et al used such a technique in their comparison of DXA
%scanners. They also used the Blackwood Bradley test. However it
%was shown that, for particular comparisons,  agreement between
%methods was indicated according to one test, but lack of agreement
%was indicated by the other.



\section*{Bartko's Ellipse}

\[ \frac{x - \bar{x}}{\sigma^2_x} - \frac{2\rho(x - \bar{x})(y - \bar{y})}{\sigma_x \sigma_y} + \frac{y - \bar{y}}{\sigma^2_y} = \chi^2(2df_(1-\rho^2) \]
%------------------------------------------------%


section*{Remarks}
\begin{itemize}
	\item Pearson's Correlation of (x,y) is the same as Pitman's correlation of sums and differences.
	
	\item Techniques for plotting an ellipse can be found in Douglas Altman's book.
\end{itemize}
%------------------------------------------------%
\newpage
%----------------------------------------------------------------------------------------------------------------------%



\section{A regression based approach based on Bland Altman Analysis}
Bland and Altman have stated that regression analysis offers insights into method comparison studies. Regression methods can determine the presence of bias, and the levels of constant bias and proportional bias thereof \cite{ludbrook97,ludbrook02}.
While they are informative about inter-method bias, Regression methods offer the analyst no insights into the relative precision of both methods. These methods can be employed in conversion problems, however errors are
attended.
\emph{\textbf{Lu et al}} used such a technique in their comparison of DXA scanners. They also used the Blackwood Bradley test. However it was shown that, for particular comparisons, agreement between methods was indicated according to one test, but lack of agreement was indicated by the other.


\section*{Remarks}
\begin{itemize}
	\item Pearson's Correlation of (x,y) is the same as Pitman's correlation of sums and differences.
	
	\item Techniques for plotting an ellipse can be found in Douglas Altman's book.
\end{itemize}
%------------------------------------------------%

\section{The MCR R pacakge - Regression Techniques for MCS}

The \textbf{\textit{mcr}} packages provides a set of regression techniques to quantify the relation between two measurement methods.

In particular, it address regression problems with errors in both variables, but without repeated measurements.
The \textbf{\textit{mcr}} package follows the CLSI EP09-A3 recommendations for analytical
method comparison and estimation of bias using patient samples.


\textit{Methods featured in the \textbf{mcr} package}

\begin{itemize}
	\item Deming Regression
	\item Weighted Deming Regression
	\item Passing-Bablock Regression
\end{itemize}

The \textit{creatinine} gives the blood and serum preoperative creatinine measurements in 110 heart surgery patients.

\begin{framed}
	\begin{verbatim}
	library("mcr")
	data("creatinine", package="mcr")
	tail(creatinine)
	
	
	fit.lr <- mcreg(as.matrix(creatinine), method.reg="LinReg", na.rm=TRUE)
	fit.wlr <- mcreg(as.matrix(creatinine), method.reg="WLinReg", na.rm=TRUE)
	compareFit( fit.lr, fit.wlr )
	\end{verbatim}
\end{framed}


\section{Implementation of Deming Regression with \texttt{R}s}
Thus far, one of the few \texttt{R} implementations of Deming regression is contained in the `MethComp' package. \citep{BXC2008}.

Unless specified otherwise, the variance ratio $\lambda$ has a default value of one. A means of computing likelihood functions would potentially allow for an algorithm for estimating the true variance ratio.




%\citet{linnet93} defines analytical standard deviation as the standard deviation of measures values around the target value.\citet{linnet93} defines analytical standard deviation as the standard deviation of measures values around the target value.



\section{KP}
Most residual covariance structures are design for one
within-subject factor. However two or more may be present. For
such cases, an approppriate approach would be the residual
covariance structure using Kronecker product of the underlying
within-subject factor specific covariances structure.



	\chapter{Residual Diagnostics}

\title{Roy's Candidate models}
The original Bland Altman Method was developed for two sets of
measurements done on one occasion (i.e. independent data), and so
this approach is not suitable for repeated measures data. However,
as a naïve analysis, it may be used to explore the data because of
the simplicity of the method. Myles states that such misuse of the
standards Bland Altman method is widespread in Anaesthetic and
critical care literature.
\\
\\
Bland and Altman have provided a modification for analysing
repeated measures under stable or chaninging conditions, where
repeated data is collected over a period of time. Myers proposes
an alternative Random effects model for this purpose.
\\
\\
with repeated measures data, we can
calculate the mean of the repeated measurements by each method on
each individuals. \emph{ The pairs of means can then be used to
	compare the two methods based on the 95\% limits of agreement for
	the difference of means. The bias between the two methods will not
	be affected by averaging the repeated measurements.}.However the
variation of the differences will be underestimated by this
practice because the measurement error is, to some extent,
removed. Some advanced statistical calculations are needed to take
into account these measurement errors. \emph{Random effects models
	can be used to estimate the within-subject variation after
	accounting for other observed and unobserved variations, in which
	each subject has a different intercept and slope over the
	observation period .On the basis of the within-subject variance
	estimated by the random effects model, we can then create an
	appropriate Bland Altman Plot.}The sequence or the time of the
measurement over the observation period can be taken as a random
effect.


\section{Haslett Dillane Hayes}
	\citet{HaslettDillane} offers an procedure to assess the influences for the variance components
	within the linear model, complementing the existing methods for the fixed components. The essential problem is that there is no useful updating procedures for $\hat{V}$, or for $\hat{V}^{-1}$.
	
	\citet{HaslettDillane} remark that linear mixed effects models
	didn't experience a corresponding growth in the use of deletion
	diagnostics, adding that \citet{McCullSearle} makes no mention of
	diagnostics whatsoever.	
	
	\citet{HaslettDillane} propose an alternative, and
	computationally inexpensive approach, making use of the
	`\texttt{delete=replace}' identity.
	
	\citet{Haslett99} considers the effect of `leave k out'
	calculations on the parameters $\beta$ and $\sigma^{2}$, using
	several key results from \citet{HaslettHayes} on partioned
	matrices.

\subsection{Case-Deletion Diagnostics}
Influence diagnostics are formal techniques that assess the influence of observations on parameter estimates for $\beta$ and $\theta$. A common technique is to refit the model with an observation or group of observations omitted.

Case-deletion diagnostics provide a useful tool for identifying influential observations and outliers. Since the pioneering work of Cook in 1977, deletion measures have been applied to many statistical models for identifying influential observations.

% Cook's Distance for OLS models

Standard statistical packages concentrate on calculating and testing parameter estimates without considering the diagnostics of the model. 

The assessment of the effects of perturbations in data, on the outcome of the analysis, is known as statistical influence analysis. Influence analysis examines the robustness of the model.

\section{Demidenk Case Deletion Diagnostics}
\citet{Demi} extends several regression diagnostic techniques commonly used in linear regression, such as leverage, infinitesimal influence, case deletion diagnostics, Cook's distance, and local influence to the linear mixed-effects model. In each case, the proposed new measure has a direct interpretation in terms of the effects on a parameter of interest, and reduces to the familiar linear regression measure when there are no random effects.

The new measures that are proposed by \citet{Demi} are explicitly defined functions and do not require re-estimation of the model, especially for cluster deletion diagnostics. The basis for both the cluster deletion diagnostics and Cook's distance is a generalization of Miller's simple update formula for case deletion for linear models. Furthermore \citet{Demi} shows how Pregibon's infinitesimal case deletion diagnostics is adapted to the linear mixed-effects model. 
%==============================%


	\section{LME diagnostic measures}
	\subsection{Andrews-Pregibon statistic} %2.4.4
	\begin{itemize}
		\item For fixed effect parameters $\beta$.
	\end{itemize}
	The Andrews-Pregibon statistic $AP_{i}$ is a measure of influence based on the volume of the confidence ellipsoid.
	The larger this statistic is for observation $i$, the stronger the influence that observation will have on the model fit.
	
	
	\subsection{Cook's Distance} %2.4.1
	\begin{itemize}
		\item For variance components $\gamma$
	\end{itemize}
	
	Diagnostic tool for variance components
	\[ C_{\theta i} =(\hat(\theta)_{[i]} - \hat(\theta))^{T}\mbox{cov}( \hat(\theta))^{-1}(\hat(\theta)_{[i]} - \hat(\theta))\]
	
	
	%---------------------------------------------------------------------------%
	\subsection{Variance Ratio} %2.4.2
	\begin{itemize}
		\item For fixed effect parameters $\beta$.
	\end{itemize}
	
	
	\subsection{Cook-Weisberg statistic} %2.4.3
	\begin{itemize}
		\item For fixed effect parameters $\beta$.
	\end{itemize}
	
	\subsection{Andrews-Pregibon statistic} %2.4.4
	\begin{itemize}
		\item For fixed effect parameters $\beta$.
	\end{itemize}
	The Andrews-Pregibon statistic $AP_{i}$ is a measure of influence based on the volume of the confidence ellipsoid.
	The larger this statistic is for observation $i$, the stronger the influence that observation will have on the model fit.
	
	%==============================================================================================================================%
	%--------------------------------------------------------------------------------------------%
	
	
	
	

	\section{Two-tailed testing} A test for equality of variances, based on the likelihood Ratio test, is very simple to implement using existing methodologies. All that is required it to specify the reference model and the relevant nested mode as arguments to the command \texttt{anova()}. The output can be interpreted in the usual way.
	
	\section{One Tailed Testing}
	The approach proposed by Roy deals with the question of agreement, and indeed interchangeability, as developed by Bland and Altman's corpus of work. In the view of Dunn, a question relevant to many practitioners is which of the two methods is more precise.
	
	The relationship between precision and the within-item and between-item variability must be established. Roy establishes the equivalence of repeatability and within-item variability, and hence precision.  The method with the smaller within-item variability can be deemed to be the more precise.
	
	\section{Enabling One Tailed Testing}
	A useful approach is to compute the confidence intervals for the ratio of within-item standard deviations (equivalent to the ratio of repeatability coefficients), which can be interpreted in the usual manner ( or alternatively, the ratio of the variances). In fact, the ratio of within-item standard deviations, with the attendant confidence interval,  can be determined using a single \texttt{R} command: \texttt{intervals()}.
	
	Pinheiro and Bates (pg 93-95) give a description of how confidence intervals for the variance components are computed. Furthermore a complete set of confidence intervals can be computed to complement the variance component estimates.
	However , to facilitate one tailed testing, What is required is the computation of the variance ratios of within-item and between-item standard deviations.
	
	A naïve approach would be to compute the variance ratios by relevant F distribution quantiles. However, the question arises as to the appropriate degrees of freedom. However, Douglas Bates has stated that an alternative approach is required (i.e. Profile Likelihoods)
	
	\begin{quote}
		"The omission of standard errors on variance components is intentional.
		The distribution of an estimator of a variance component is highly
		skewed and obtaining an estimate of the standard deviation of a skewed
		distribution is not very useful.  A much better approach is based on
		profiling the objective function." (Douglas Bates May 2012)
	\end{quote}
	
	
	\section{Profile Likelihood}
	Normal-based confidence intervals for a parameter of interest are inaccurate when the sampling distribution of the estimate is skewed. The technique known as profile likelihood can produce confidence intervals with better coverage. It may be used when the model includes only the variable of interest or several other variables in addition. Profile-likelihood confidence intervals are particularly useful in nonlinear models.
	
	Profile likelihood confidence intervals are based on the log-likelihood function.  
	%For a single parameter, likelihood theory shows that the 2 points 1.92 units down from the maximum of the log-likelihood function provide a $95\%$ confidence interval when there is no extrabinomial variation (i.e. c = 1)..  The value 1.92 is half of the chi-square value of 3.84 with 1 degree of freedom.
	
	%Thus, the same confidence interval can be computed with the deviance by adding 3.84 to the minimum of the deviance function, where the deviance is the log-likelihood multiplied by -2 minus the -2 log likelihood value of the saturated model.
	
	\section{Implementation of PL Confidence Intervals}
	
	The suitable calculation of confidence limits for this variance ratio are to be computed using the profile likelihood approach. The \texttt{R} package \texttt{profilelikelihood} will be assessed for feasibility, particularly the command \texttt{profilelikelihood.lme()}
	
	
	Normal-based condence intervals for a parameter of interest are inaccurate when the sampling 
	distribution of the estimate is skewed. The technique known as profile likelihood can produce confidence 
	intervals with better coverage. It may be used when the model includes only the variable of interest or 
	several other variables in addition.
	Profile-likelihood confidence intervals are particularly useful in nonlinear models. 
	Profile likelihood confidence intervals are based on the log-likelihood function.
	
	%http://cran.r-project.org/web/packages/ProfileLikelihood/ProfileLikelihood.pdf
	
	%http://lme4.r-forge.r-project.org/slides/2011-03-16-Amsterdam/3Profiling.pdf
	
	%http://lme4.r-forge.r-project.org/slides/2009-07-21-Seewiesen/4PrecisionD.pdf
	
	
	



	\section{Haslett Hayes}                %-Case Deletion section 3
	
	For fixed effect linear models with correlated error structure
	Haslett (1999) showed that the effects on the fixed effects
	estimate of deleting each observation in turn could be cheaply
	computed from the fixed effects model predicted residuals.
	
	
	A general theory is presented for residuals from the general
	linear model with correlated errors. It is demonstrated that there
	are two fundamental types of residual associated with this model,
	referred to here as the marginal and the conditional residual.
	These measure respectively the distance to the global aspects of
	the model as represented by the expected value and the local
	aspects as represented by the conditional expected value. These
	residuals may be multivariate.
	
	In contrast to classical linear models, diagnostics for LME are
	difficult to perform and interpret, because of the increased
	complexity of the model
	
	%---------------------------------------------------------------------%
	\section{Confounded Residuals}
	Hilden-Minton (1995, PhD thesis, UCLA): residual is pure for a specific type of error if it depends only on the fixed components and
	on the error that it is supposed to predict	Residuals that depend on other types of errors are called \textit{\textbf{confounded
			residuals}}
	This code will allow you to make QQ plots for each level of the random effects.  LME models assume that not only the within-cluster residuals are normally distributed, but that each level of the random effects are as well. Depending on the model, you can vary the level from 0, 1, 2 and so on
	\begin{framed}
		\begin{verbatim}
		qqnorm(JS.roy1, ~ranef(.))
		
		# 	qqnorm(JS.roy1, ~ranef(.,levels=1)
		\end{verbatim}
	\end{framed}
	%====================================================================%
	This code will allow you to make QQ plots for each level of the random effects.  LME models assume that not only the within-cluster residuals are normally distributed, but that each level of the random effects are as well. Depending on the model, you can vary the level from 0, 1, 2 and so on
	\begin{framed}
		\begin{verbatim}
		qqnorm(JS.roy1, ~ranef(.))
		
		# 	qqnorm(JS.roy1, ~ranef(.,levels=1)
		\end{verbatim}
	\end{framed}

	

	\chapter{Fitting LME Models}
	%\subsection{Overview of R implementations}
	Further to previous material, an appraisal of the current state of development for statistical software for fitting for LME models, particularly for \texttt{nlme} and \texttt{lme4} fitted models.
	
	%======================%
	% lme4 and influence.ME
	
	The \textbf{lme4} pacakge is used to fit linear and generalized linear mixed-effects models in the R environment.
	The \textbf{lme4} package is also under active development, under the leadership of Ben Bolker (McMaster Uni., Canada).
	
	
	Crucially, a review of internet resources indicates that almost all of the progress in this regard has been done for \texttt{lme4} fitted models, specifically the \textit{Influence.ME} \texttt{R} package. (Nieuwenhuis et al 2014)
	Conversely there is very little for \texttt{nlme} models. One would immediately look at the current development workflow for both packages.
	
	%======================%
	% Douglas Bates
	
	As an aside, Douglas Bates was arguably the most prominent \texttt{R} developer working in the LME area. 
	However Bates has now prioritised the development of LME models in another computing environment , i.e Julia. 
	% The current version of this is XXXX
	
	%======================%
	% nlme
	
	With regards to \texttt{nlme}, the package is now maintained by the \texttt{R} core development team. The most recent major text is by Galecki \& Burzykowski, who have published \textit{ Linear Mixed Effects Models using \texttt{R}. }
	Also, the accompanying \texttt{R} package, nlmeU package is under current development, with a version being released $0.70-3$.
	
	
	









%========================================================== %



\section{Relevance of Roy's Methodology}

The relevance of Roy's methodology is that estimates for the between-item variances for both methods $\hat{d}^2_m$ are computed. Also the VC matrices are constructed with covariance
terms and, so the difference variance must be formulated accordingly.


\[
\hat{\alpha}_1 - \hat{\alpha}_2 \pm \sqrt{ \hat{d}^2_1  +
	\hat{d}^2_1 + \hat{\sigma}^2_1 + \hat{\sigma}^2_2 - 2 \hat{d}_{12}
	- 2 \hat{\sigma}_12}
\]
%=================================================================== %



%
%\citet{ARoy2009} considers the problem of assessing the agreement
%between two methods with replicate observations in a doubly
%multivariate set-up using linear mixed effects models.
%
%\citet{ARoy2009} uses examples from \citet{BA86} to be able to
%compare both types of analysis.


%The maximum likelihood estimate of the between-subject variance
%covariance matrix of two methods is given as $D$. The estimate for
%the within-subject variance covariance matrix is $\hat{\Sigma}$.
%The estimated overall variance covariance matrix `Block
%$\Omega_{i}$' is the addition of $\hat{D}$ and $\hat{\Sigma}$.
%
%
%\begin{equation}
%	\mbox{Block  }\Omega_{i} = \hat{D} + \hat{\Sigma}
%\end{equation}

\section{Interaction Terms in Model}

\emph{
	One important feature of replicate observations is that they should be independent
	of each other. In essence, this is achieved by ensuring that the observer makes each
	measurement independent of knowledge of the previous value(s). This may be difficult
	to achieve in practice.}


Further to \citet{barnhart}, if the measurements by a method on an item are not necessarily true replications, e.g., repeated measures over time, then additional terms may be needed for $e_{mir}$. \citet{BXC2008} also addresses this issue by the addition of an interaction term (i.e. a random effect) $u_mi$, yielding

\[ y_{mir} =  \alpha_{mi} + u_{mi} + e_{mi}.  \]

The additional interaction term is characterized as $u_{mi}  \sim \mathcal{N}(0, \tau^2_m)$ \citep{BXC2008}. This extra interaction term provides a source of extra variability, but this variance is not relevant to computing the case-wise differences.

%
%\citet{BXC2008} advises that the formulation of the model should take the exchangeability (in other words, whether or not the measurements are `true replicates') into account. If there is a linkage between measurements (therefore not `true' replicates) , the `item by replicate' should be included in the model. If there is no linkage, and the replicates are indeed true replicates, the interaction term should be omitted.
%
%
%
%\citet{ARoy2009} also assigns a random effect $u_{mi}$ for each response $y_{mir}$. Importantly Roy's model assumes linkage.


%\citet{BXC2008} formulates an LME model, both in the absence and the presence of an interaction term. \citet{BXC2008} uses both to demonstrate the importance of using an interaction term. Failure to take the replication structure into
%account results in over-estimation of the limits of agreement. For the Carstensen estimates below, an interaction term was included when computed.
%
%






%============================================================================= %


















\section{Difference Variance further to Carstensen}


%---Key difference 1---The True Value
%---Carstensen's limits of agreement
%---The between item variances are not individually computed. An estimate for their sum is used.
%---The within item variances are indivdually specified.
%---Carstensen remarks upon this in his book (page 61), saying that it is "not often used".
%---The Carstensen model does not include covariance terms for either VC matrices.
%---Some of Carstensens estimates are presented, but not extractable, from R code, so calculations have to be done by %---hand.
%---All of Roys stimates are  extractable from R code, so automatic compuation can be implemented
%---When there is negligible covariance between the two methods, Roys LoA and Carstensen's LoA are roughly the same.
%---When there is covariance between the two methods, Roy's LoA and Carstensen's LoA differ, Roys usually narrower.

%================================================================================= %



Even though the separate variances can not be identified, their sum can be estimated by the empirical variance of the differences.

Like wise the separate $\alpha$ can not be
estimated, only their difference can be estimated as
$\bar{D}$


We assume that that the variance of the measurements is different for both methods, but it does not mean that the separate variances can be estimated with the data available.










%With regards to the specification of the variance terms, Carstensen  remarks that using their approach is common, %remarking that \emph{ The only slightly non-standard (meaning ``not often used") feature is 

%\section{Correlation indices}
%\citet{ARoy2009} remarks that PROC MIXED only gives overall correlation coefficients, but not their variances. Consequently it is not possible to carry out inferences based on all overall correlation coefficients.



%================================================================================================== %

	\section{Why use LMEs for Method Comparison?}
	The LME model approach has seen increased use as a framework for method comparison studies in recent years (Lai $\&$ Shaio, Carstensen and Choudhary as examples). In part this is due to the increased profile of LME models, and furthermore the availability of capable software. Additionally LME based approaches may utilise the diagnostic and influence analysis techniques that have been developed in recent times.
	
	
	Roy proposes an LME model with Kronecker product covariance structure in a doubly multivariate setup. Response for $i$th subject can be written as
	\[ y_i = \beta_0 + \beta_1x_{i1} + \beta_2x_{i2} + b_{1i}z_{i1}  + b_{2i}z_{i2} + \epsilon_i \]
	\begin{itemize}
		\item $\beta_1$ and $\beta_2$ are fixed effects corresponding to both methods. ($\beta_0$ is the intercept.)
		\item $b_{1i}$ and $b_{2i}$ are random effects corresponding to both methods.
	\end{itemize}
	
	Overall variability between the two methods ($\Omega$) is sum of between-subject ($D$) and within-subject variability ($\Sigma$),
	\[
	\mbox{Block } \boldsymbol{\Omega}_i = \left[ \begin{array}{cc} d^2_1 & d_{12}\\ d_{12} & d^2_2\\ \end{array} \right]
	+ \left[\begin{array}{cc} \sigma^2_1 & \sigma_{12}\\ \sigma_{12} & \sigma^2_2\\ \end{array}\right].
	\]
	
	The well-known ``Limits of Agreement", as developed by Bland and Altman (1986) are easily computable using the LME framework, proposed by Roy. While we will not be considering this analysis, a demonstration will be provided in the example.
	
	Further to this, Roy(2009) demonstrates an suite of tests that can be used to determine how well two methods of measurement, in the presence of repeated measures, agree with each other.
	
	\begin{itemize}\itemsep0.5cm
		\item No Significant inter-method bias
		\item No difference in the between-subject variabilities of the two methods
		\item No difference in the within-subject variabilities of the two methods
	\end{itemize}
	
	\section{Definition of Replicate measurements}
	Further to \citet{BA99}, a formal definition is required of what exactly replicate measurements are
	
	\emph{By replicates we mean two or more measurements on the same
		individual taken in identical conditions. In general this requirement means that the
		measurements are taken in quick succession.}
	
	\citet{BA99} also remark that an important feature of replicate observations is that they should be independent
	of each other. This issue is addressed by \citet{BXC2010}, in terms of exchangeability and linkage. Carstenen advises that repeated measurements come in two \emph{substantially different} forms, depending on the circumstances of their measurement: exchangable and linked.
	%----------------------------------------------------------------------------%
	\subsection{Exchangeable measurements}
	Repeated measurements are said to be exchangeable if no relationship exists between successive measurements across measurements. If the condition of exchangeability exists, a group of measurement of the same item determined by the same method can be re-arranged in any permutation without prejudice to proper analysis. There is no reason to believe that the true value of the underlying variable has changed over the course of the measurements.
	
	For the purposes of method comparison studies the following remarks can be made. The $r-$th measurement made by method $1$ has no special correspondence to the $r-$th measurement made by method $2$, and consequently any pairing of repeated measurements are as good as each other.
	
	Exchangeable repeated measurements can be treated as true replicates.
	%----------------------------------------------------------------------------%
	\subsection{Linked measurements}
	Repeated measurements are said to be linked if a direct correspondence exists between successive measurements across measurements, i.e. pairing. Such measurements are commonly made with a time interval between them, but simultaneously for both methods. Paired measurements are exchangeable, but individual measurements are not.
	
	If the paired measurements are taken
	in a short period of time so that no real systemic changes can take place on each item, they can be considered true replicates.
	Should enough time elapse for systemic changes, linked repeated measurements can not be treated as true replicates.
	
	\subsection{Replicate measurements in ARoy2009's paper}
	\citet{ARoy2009} takes its definition of replicate measurement: two or more measurements on the same item taken
	under identical conditions. ARoy2009 also assumes linked measurements, but it is can be used for the non-linked case.
	
	%----------------------------------------------------------------------------------------------------%
	\newpage
	\subsection{Random effects}
	
	Further to \citet{barnhart}, if the measurements by a method on an item are not necessarily true replications, e.g., repeated measures over time, then additional terms may be needed for $e_{mir}$. \citet{BXC2008} also addresses this issue by the addition of an interaction term (i.e. a random effect) $u_mi$, yielding
	
	\[ y_{mir} =  \alpha_{mi} + u_{mi} + e_{mi}.  \]
	
	The additional interaction term is characterized as $u_{mi}  \sim \mathcal{N}(0, \tau^2_m)$ \citep{BXC2008}.
	
	This extra interaction term provides a source of extra variability, but this variance is not relevant to computing the case-wise differences.
	
	\citet{BXC2008} advises that the formulation of the model should take the exchangeability (in other words, whether or not the measurements are `true replicates') into account. If there is a linkage between measurements (therefore not `true' replicates) , the `item by replicate' should be included in the model. If there is no linkage, and the replicates are indeed true replicates, the interaction term should be omitted.
	
	\citet{BXC2008} demonstrates how to compute the limits of agreement for two methods in the case of linked measurements. As a surplus source of variability is excluded from the computation, the limits of agreement are not unduly wide, which would have been the case if the measurements were treated as true replicates.
	
	\citet{ARoy2009} also assigns a random effect $u_{mi}$ for each response $y_{mir}$. Importantly ARoy2009's model assumes linkage.
	
	%----------------------------------------------------------------------------%
	\section{Model for replicate measurements}
	
	We generalize the single measurement model for the replicate measurement case, by additionally specifying replicate values. Let $y_{mir}$ be the $r-$th replicate measurement for subject ``i" made by method ``m". Further to \citet{barnhart} fixed effect can be expressed with a single term $\alpha_{mi}$, which incorporate the true value $\mu_i$.
	
	\[ y_{mir} = \mu_{i} + \alpha_{m} + e_{mir}  \]
	
	Combining fixed effects \citep{barnhart}, we write,
	
	\[ y_{mir} = \alpha_{mi} + e_{mir}.\]
	
	The following assumptions are required
	
	\begin{itemize}
		\item $e_{mir}$ is independent of the fixed effects with mean $\mbox{E}(e_{mir}) = 0$.
		\item Further to \citet{barnhart} between-item and within-item variances $\mbox{Var}(\alpha_{mi}) = \sigma^2_{Bm}$ and $\mbox{Var}(e_{mir}) = \sigma^2_{Wm}$
		\item In keeping with \citet{ARoy2009}, these variance shall be considered as part of the between-item variance covariance matrix $\boldsymbol{D}$ and the within-item variance covariance matrix  $\boldsymbol{\Sigma}$
		respectively, and will be denoted accordingly ( i.e. $d^2_{m}$ and $\sigma^2_{m}$).
		\item Additionally, the total variability of method "m", denoted $\omega^2_m$ is the sum of the within-item and between-item variabilities.
		
		\[ \omega^2_m = d^2_{m}+ \sigma^2_{m} \]
		
	\end{itemize}
	%----------------------------------------------------------------------------%
	\newpage
	
	


\chapter{BA99}

\section{Regression-based Limits of Agreement} Assuming that
there will be no curvature in the scatter-plot, the methodology
regresses the difference of methods ($d$) on the average of those
methods ($a$) with a simple intercept slope model; $\hat{d} =
b_{0}+ b_{1}a.$ Should the slope $b_{1}$ be found to be
negligible, $\hat{d}$ takes the value $\bar{d}$.

The next step to take in calculating the limits is also a
regression, this time of the residuals as a function of the scale
of the measurements, expressed by the averages $a_{i}$;
$ \hat{R} = c_{0}+ c_{1}a_{i}$

With reference to absolute values following a half-normal
distribution with mean $\sigma\sqrt{\frac{2}{\pi}}$, \citet{BA99} formulate the regression based limits of agreement as
follows
\begin{equation}
\hat{d} \pm 1.96\sqrt{\frac{\pi}{2}}\hat{R} = \hat{d} \pm 2.46\hat{R}
\end{equation}

%------------------------------------------------%
\newpage


	\section{Steps of Structural Equation modelling}
	
	\begin{itemize}
		\item[1.] \textbf{Model Specification}
		We must state the theoretical model either as a set of equations.
		
		\item[2.] \textbf{Identification }
		This step involves checking that the model can be estimated with observable data, both in theory and in practice.
		
		\item[3.] \textbf{Estimation}
		The models parameters are statistically estimated from data. (multiple regression is one such method)
		
		\item[4.] \textbf{Model Fit}
		The estimated model parameters are used to predict the correlations and covariance between measured variables 
		The predicted correlations, or covariance are compared to the observed correlations, or covariance. (Measures of model fit are calculated)
	\end{itemize}



	\chapter{Generalized linear models}
	\section{Generalized Linear model}
	In statistics, the generalized linear model (GzLM) is a flexible
	generalization of ordinary least squares regression. The GzLM
	generalizes linear regression by allowing the linear model to be
	related to the response variable via a link function and by
	allowing the magnitude of the variance of each measurement to be a
	function of its predicted value.
	
	
	Mixed Effects Models offer a flexible framework by which to model
	the sources of variation and correlation that arise from grouped
	data. This grouping can arise when data collection is undertaken
	in a hierarchical manner, when a number of observations are taken
	on the same observational unit over time, or when observational
	units are in some other way related, violating assumptions of
	independence.
	
	\section{Generalized  Model(GzLM)}
	
	Nelder and Wedderburn (1972) integrated the previously disparate
	and separate approaches to models for non-normal cases in a
	framework called "generalized linear models."  The key elements of
	their approach is to describe any given model in terms of it's
	link function and it's variance function.
	
	\subsection{What is a GzLM}
	
	\begin{equation}
	\operatorname{E}(\mathbf{Y}) = \boldsymbol{\mu} =
	g^{-1}(\mathbf{X}\boldsymbol{\beta})
	\end{equation}
	
	where $E(Y)$ is the expected value of $Y$, $X\beta$ is the linear
	predictor, a linear combination of unknown parameters,$\beta$ and
	$g$ is the link function.
	
	
	$\operatorname{Var}(\mathbf{Y}) = \operatorname{V}(
	\boldsymbol{\mu} ) =
	\operatorname{V}(g^{-1}(\mathbf{X}\boldsymbol{\beta}))$
	\\
	
	
	\subsection{GzLM Structure}
	The GzLM consists of three elements. \\1. A probability
	distribution from the exponential family. \\2. A linear predictor
	$\eta= X\beta$ . \\3. A link function $g$ such that $E(Y)$ = $\mu$
	= $g^{-1}(eta)$.
	
	\subsection{Link Function}
	Definition 1 : The link function provides the relationship between
	the linear predictor and the mean of the distribution function.
	There are many commonly used link functions, and their choice can
	be somewhat arbitrary. It can be convenient to match the domain of
	the link function to the range of the distribution function's
	mean.
	
	\noindent Definition 2 : A link function is the function that
	links the linear model specified in the design matrix, where
	columns represent the beta parameters and rows the real
	parameters.
	
	\subsection{Canonical parameter}
	$\theta$, called the dispersion parameter,
	\subsection{Dispersion parameter}
	$\tau$, called the dispersion parameter, typically is known and is
	usually related to the variance of the distribution.
	
	\subsection{Iteratively weighted least square}
	IWLS is used to find the maximum likelihood estimates of a
	generalized linear model.
	
	\noindent Definition: An iterative algorithm for fitting a linear
	model in the case where the data may contain outliers that would
	distort the parameter estimates if other estimation procedures
	were used. The procedure uses weighted least squares, the
	influence of an outlier being reduced by giving that observation a
	small weight. The weights chosen in one iteration are related to
	the magnitudes of the residuals in the previous iteration  with a
	large residual earning a small weight.
	
	\subsection{Residual Components}
	In GzLMS the deviance is the sum of the deviance components
	
	\begin{equation}
	D = \sum d_{i}
	\end{equation}
	
	In GzLMS the deviance is the sum of the deviance components
	
	
	\section{Generalized linear mixed models}
	[pawitan section 17.8]
	
	The Generalized linear mixed model (GLMM) extend classical mixed models to non-normal outcome data.
	
	In statistics, a generalized linear mixed model (GLMM) is a particular type of mixed model. It is an extension to the
	generalized linear model in which the linear predictor contains random effects in addition to the usual fixed effects. These random effects are usually assumed to have a normal distribution.
	
	Fitting such models by maximum likelihood involves integrating over these random effects.
	
	
	

	
	
	\section{Assessment of Agreements in Linear and Generalized Linear Mixed Models}
	
	% http://indigo.uic.edu/handle/10027/9520
	\begin{itemize}
		\item Study of measuring agreement is intend to evaluate whether the readings from one rater/ measurement 
		agree with those from other raters/measurements. 
		In this dissertation, we are going to present a general method to assess agreement for a large 
		variety of data with repeated measurements using linear and generalized linear mixed models. 
		\item In the first place, a set of agreement statistics, including mean square deviation, concordance 
		correlation coefficient, precision and accuracy coefficients, is presented for evaluating the 
		intra-, inter-, and total-rater agreement in the multiple-rater and multiple-replications cases. 
		\item Secondly, likelihood-based approaches are developed to estimate all the agreement statistics. 
		Asymptotic properties of these estimates are also discussed for different data structures. 
		\item Furthermore, our method has the merit of handling missing values and covariates naturally, 
		and a new set of restricted agreement statistics is proposed in order to capture the true random 
		variations and between-instrument effects adjusted for the covariate effects. 
		
		\item Simulations for both linear and generalized linear mixed models are conducted to show the accuracy and effectiveness 
		of our approaches. In the end, two industry datasets are evaluated using our approach. 
		\item One is the cardiac function measurements used to determine the agreement between impedance cardiography and radionuclide 
		ventriculography estimates, and the other one is an antihypertensive patch dataset given by FDA for assessing 
		individual bioequivalence.
	\end{itemize}

\newpage






\citet{pkcng} generalize this approach to account for situations
where the distributions are not identical, which is commonly the
case. The TDI is not consistent and may not preserve its
asymptotic nominal level, and that the coverage probability
approach of \citet{lin2002} is overly conservative for moderate
sample sizes. This methodology proposed by \citet{pkcng} is a
regression based approach that models the mean and the variance of
differences as functions of observed values of the average of the
paired measurements.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%5

Maximum likelihood estimation is used to estimate the parameters.
The REML estimation is not considered since it does not lead to a
joint distribution of the estimates of fixed effects and random
effects parameters, upon which the assessment of agreement is
based.

\section{Random Effects and MCS}
The methodology comprises two calculations. The second calculation
is for the standard deviation of means Before the modified Bland
and Altman method can be applied for repeated measurement data, a
check of the assumption that the variance of the repeated
measurements for each subject by each method is independent of the
mean of the repeated measures. This can be done by plotting the
within-subject standard deviation against the mean of each subject
by each method. Mean Square deviation measures the total deviation
of a


\subsection{Random coefficient growth curve model} (Chincilli
1996) Random coefficient growth curve model, a special type of
mixed model have been proposed a single measure of agreement for
repeated measurements.
\begin{equation}
\textbf{d}= \textbf{Xb} + \textbf{Zu} + \textbf{e}
\end{equation}
The distributional asummptions also require \textbf{d} to
\textbf{N}


\section{Random effects Model} \citet{Myles} proposes the use of
Random effects models to address the issue of repeated
measurement. 

Myles proposes a formulation of the BlandAltman
plot, using the within-subject variance estimated by the random
effects model, with the time of the measurement taken as a random
effect. He states that \emph{random effects models account for the
	dependent nature of the data, and additional explanatory
	variables, to provide reliable estimates of agreement in this
	setting.}
\\
Agreement between methods is reflected by the between-subject
variation.The Random Effects Model takes this into account before
calculating the within-subject standard deviation.

\subsection{Myers Random Effects Model} The presentation of the
95\% limits of agreement is for visual judgement of how well two
methods of measurement agree. The smaller the range between the
two, the better the agreement is The question of small is small is
a question of clinical judgement


Repeated measurements for each subjects are often used in clinical
research.



\subsection{Random Effects Modelling}
Random effects models are used to examine the within-subject
variation after adjusting for known and unknown variables, in
which each subject has a different intercept and slope over a time
period period.


\citet{Myles} remarks that the random effects model is an
extension of the analysis of variance method, accounting for more
covariates.

A random effect (in Myles's case, time of measurement) is chosen
to reflect the different intercept and slope for each subject with
respect to their change of measurements over the time period.

In Myles's methodology, the standard deviation of difference
between the means of the repeated measurements can be calculated
based on the within-subject standard deviation estimates.

A random effects model (also variance components model)is a type
of hierarchical linear model. Hierarchical linear modelling (HLM)
is a more advanced form of simple linear regression and multiple
linear regression. HLM is appropriate for use with nested
data.\\Faraway comments that the random effects approach is
\emph{more ambitious than the LME model in that it attempts to say
	something about the wider population beyond the particular
	sample}.

\section{Other Approaches : Marginal Modelling}
(Diggle 2002) proposes the use of marginal models as an
alternative to mixed models.m Marginal models are appropriate when
interences about the mean response are of specific interest.

\section{Other Approaches}


\citet{pkcng} generalize this approach to account for situations
where the distributions are not identical, which is commonly the
case. The TDI is not consistent and may not preserve its
asymptotic nominal level, and that the coverage probability
approach of \citet{lin2002} is overly conservative for moderate
sample sizes. This methodology proposed by \citet{pkcng} is a
regression based approach that models the mean and the variance of
differences as functions of observed values of the average of the
paired measurements.



%-------------------------------------------------

\begin{enumerate}
	\item Agreement and Method Comparison Studies
	\begin{enumerate}
		\item What is Agreement?
		\item Repeatability
		\item
		\item
		\item
	\end{enumerate}
	\item Bland Altman Single Observations
	\begin{enumerate}
		\item
		\item
	\end{enumerate}
	\item Alternative Methods
	\begin{enumerate}
		\item Deming Regression
		\item Mountain Plot
		\item Bartko's Ellipse
		\item Formal Tests and Procedures
	\end{enumerate}
	\item Replicate Observations
	
	\item LME models
	
	\item Estimation and Algorithms
	\begin{enumerate}
		\item ML and REML estimation
		\item MINQUE
		\item
	\end{enumerate}
	\item Residual Diagnostics
	\begin{enumerate}
		\item Marginal and Conditional Diagnostics
		\item Scaled Residuals
	\end{enumerate}
	
	\item Influence Diagnostics
	\begin{enumerate}
		\item Underlying Concepts
		\item Managing the Covariance Parameters
		\item Predicted Values, PRESS Residual and the PRESS Statistic
		\item Leverage
		\item Internally and Externally Studentized Residuals
		\item DFFITs and MDFFITs
		\item Covariance Ratio and Trace
		\item Likelihood Distance
		\item Non-iterative Update Procedures
	\end{enumerate}
\end{enumerate}
\newpage

\section{MCS Data Sets}
\begin{enumerate}
	\item Blood Data
	\item Cardiac Data
	\item Nadler Hurley 
\end{enumerate}

%%%%%%%%%%%%%
%1 Method Comparison Studies            %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{itemize}		
	%-------------------------------------------------%
	% Chapter 1
	
	\item	Introduction to Method Comparison Studies	
	\begin{itemize}	
		\item	Accuracy and Precision
		\item	Repeatability (Bland Altman 1999)
		\item	Barnharts Paper
		\item	
	\end{itemize}	
	
	%-------------------------------------------------%
	% Chapter 2
	
	\item	Bland and Altman Plot	
	\begin{itemize}	
		\item	Bland and Altman 1983 and 86
		\item	Limits of Agreement
		\item	
		\item	
	\end{itemize}
	
	
\end{itemize}		

%====================================================================%

\section{Introduction}

Outliers and detection of influent observations is an important step in the analysis of a data set. There are several ways of evaluating the influence of perturbations in the data set and in the model given the parameter estimates. 

\subsection{Overview of R implementations}
Further to previous material, an appraisal of the current state of development (or lack thereof) for current implemenations for LME models, particularly for \texttt{nlme} and \texttt{lme4} fitted models.

Crucially, a review of internet resources indicates that almost all of the progress in this regard has been done for \texttt{lme4} fitted models, specifically the \textit{Influence.ME} \texttt{R} package. (Nieuwenhuis et al 2014)
Conversely there is very little for \texttt{nlme} models. One would immediately look at the current development workflow for both packages.

%======================%
% Douglas Bates

As an aside, Douglas Bates was arguably the most prominent \texttt{R} developer working in the LME area. 
However Bates has now prioritised the development of LME models in another computing environment , i.e Julia. 
% The current version of this is XXXX

%======================%
% nlme

With regards to \texttt{nlme}, the package is now maintained by the \texttt{R} core development team. The most recent major text is by Galecki \& Burzykowski, who have published \textit{ Linear Mixed Effects Models using \texttt{R}. }
Also, the accompanying \texttt{R} package, nlmeU package is under current development, with a version being released $0.70-3$.


%======================%
% lme4 and influence.ME

The \textbf{lme4} pacakge is used to fit linear and generalized linear mixed-effects models in the R environment.
The \textbf{lme4} package is also under active development, under the leadership of Ben Bolker (McMaster Uni., Canada).


%=====================%
\subsection*{Important Consideration for MCS}

The key issue is that \texttt{nlme} allows for the particular specification of Roy's Model, speciifically direct specification of the VC matrices for within subject and between subject residuals.
The \texttt{lme4} package does not allow for Roy's Model, for reasons that will identified shortly.
To advance the ideas that eminate from Roys' paper, one is required to use the \texttt{nlme} context. However, to take advantage of the infrastructure already provided for \texttt{lme4} models, one may change the research question away from that of Roy's paper. 
To this end, an exploration of what textbf{influence.ME} can accomplished is merited.




%--------------------------------------------------------------%
\newpage
\section{Computation and Notation } %2.3
with $\boldsymbol{V}$ unknown, a standard practice for estimating $\boldsymbol{X \beta}$ is the estime the variance components $\sigma^2_j$,
compute an estimate for $\boldsymbol{V}$ and then compute the projector matrix $A$, $\boldsymbol{X \hat{\beta}}  = \boldsymbol{AY}$.


Zewotir remarks that $\boldsymbol{D}$ is a block diagonal with the $i-$th block being $u \boldsymbol{I}$

\section{Lai Shiao}
\citet{LaiShiao} use mixed models to determine the factors that
affect the difference of two methods of measurement using the
conventional formulation of linear mixed effects models.

If the parameter \textbf{b}, and the variance components are not
significantly different from zero, the conclusion that there is no
inter-method bias can be drawn. If the fixed effects component
contains only the intercept, and a simple correlation coefficient
is used, then the estimate of the intercept in the model is the
inter-method bias. Conversely the estimates for the fixed effects
factors can advise the respective influences each factor has on
the differences. The Proc Mixed package allows users to specify
different correlation structures of the variance components
\textbf{G} and \textbf{R}.


Oxygen saturation is one of the most frequently measured variables
in clinical nursing studies. `Fractional saturation' ($HbO_{2}$)
is considered to be the gold standard method of measurement, with
`functional saturation' ($SO_{2}$) being an alternative method.
The method of examining the causes of differences between these
two methods is applied to a clinical study conducted by
\citet{Shiao}. This experiment was conducted by 8 lab
practitioners on blood samples, with varying levels of
haemoglobin, from two donors. The samples have been in storage for
varying periods ( described by the variable `Bloodage') and are
categorized according to haemoglobin percentages(i.e
$0\%$,$20\%$,$40\%$,$60\%$,$80\%$,$100\%$). There are 625
observations in all.

\citet{LaiShiao} fits two models on this data, with the lab
technicians and the replicate measurements as the random effects
in both models. The first model uses haemoglobin level as a fixed
effects component. For the second model, blood age is added as a
second fixed factor.

\subsubsection{Single fixed effect} The first model fitted by \citet{LaiShiao} takes the
blood level as the sole fixed effect to be analyzed. The following
coefficient estimates are estimated by `Proc Mixed';
\begin{eqnarray}
\mbox{fixed effects :   } 2.5056 - 0.0263\mbox{Fhbperct}_{ijtl} \\
(\mbox{p-values :   } = 0.0054, <0.0001, <0.0001)\nonumber\\\nonumber\\
\mbox{random effects :   } u(\sigma^{2}=3.1826) + e_{ijtl}
(\sigma^{2}_{e}=0.1525, \rho= 0.6978) \nonumber\\
(\mbox{p-values :   } = 0.8113, <0.0001, <0.0001)\nonumber
\end{eqnarray}

With the intercept estimate being both non-zero and statistically
significant ($p=0.0054$), this models supports the presence
inter-method bias is $2.5\%$ in favour of $SO_{2}$. Also, the
negative value of the haemoglobin level coefficient indicate that
differences will decrease by $0.0263\%$ for every percentage
increase in the haemoglobin .

In the random effects estimates, the variance due to the
practitioners is $3.1826$, indicating that there is a significant
variation due to technicians ($p=0.0311$) affecting the
differences. The variance for the estimates is given as $0.1525$,
($p<0.0001$).

\subsubsection{Two fixed effects}
Blood age is added as a second fixed factor to the model,
whereupon new estimates are calculated;
\begin{eqnarray}
\mbox{fixed effects :   } -0.2866 + 0.1072 \mbox{Bloodage}_{ijtl}
- 0.0264\mbox{Fhbperct}_{ijtl}\nonumber\\
( \mbox{p-values :   } = 0.8113, <0.0001, <0.0001)\nonumber\\\nonumber\\
\mbox{random effects :   } u(\sigma^{2}=10.2346) + e_{ijtl}
(\sigma^{2}_{e}=0.0920, \rho= 0.5577) \nonumber\\
(\mbox{p-values :   } = 0.0446, <0.0001, <0.0001)
\end{eqnarray}


With this extra fixed effect added to the model, the intercept
term is no longer statistically significant. Therefore, with the
presence of the second fixed factor, the model is no longer
supporting the presence of inter-method bias. Furthermore, the
second coefficient indicates that the blood age of the observation
has a significant bearing on the size of the difference between
both methods ($p <0.0001$). Longer storage times for blood will
lead to higher levels of particular blood factors such as MetHb
and HbCO (due to the breakdown and oxidisation of the
haemoglobin). Increased levels of MetHb and HbCO are concluded to
be the cause of the differences. The coefficient for the
haemoglobin level doesn't differ greatly from the single fixed
factor model, and has a much smaller effect on the differences.
The random effects estimates also indicate significant variation
for the various technicians; $10.2346$ with $p=0.0446$.

\citet{LaiShiao} demonstrates how that linear mixed effects models
can be used to provide greater insight into the cause of the
differences. Naturally the addition of further factors to the
model provides for more insight into the behavior of the data.



\newpage
\section{ Liao Shaio}

Lai et Shiao is interesting in that it extends the usual method comparison study question. It correctly identifies LME models as a methodoloy that can used to make such questions tractable.
The Data Set used in their examples is unavailable for independent use. Therefore, for the sake of consistency, a data set will be simulated based on the Blood Data that will allow for extra variables.



%============================================================================%

% - http://journal.r-project.org/archive/2012-2/RJournal_2012-2_Nieuwenhuis~et~al.pdf

% - http://www.rensenieuwenhuis.nl/tag/lme4/

% - http://lme4.r-forge.r-project.org/lMMwR/lrgprt.pdf

%============================================================================%

A Study of the Bland-Altman Plot and its Associated Methodology

Joseph G. Voelkel Bruce E. Siskowski 

% - https://www.rit.edu/kgcoe/cqas/sites/rit.edu.kgcoe.cqas/files/docs/TR%202005-3.pdf

%============================================================================%

% - http://sprouts.aisnet.org/785/1/TAMReview.pdf
% - http://organizacija.fov.uni-mb.si/index.php/organizacija/article/viewFile/557/999
\section{Limits of agreement for Carstensen's data}


\citet{bxc2008} describes the calculation of the limits of agreement (with the inter-method bias implicit) for both data sets, based on his formulation;

\[\hat{\alpha}_1 - \hat{\alpha}_2 \pm 2\sqrt{2\hat{\tau}^2 +\hat{\sigma}_1^2 +\hat{\sigma}_2^2 }.\]

For the `Fat' data set, the inter-method bias is shown to be $0.045$. The limits of agreement are $(-0.23 , 0.32)$

Carstensen demonstrates the use of the interaction term when computing the limits of agreement for the `Oximetry' data set. When the interaction term is omitted, the limits of agreement are $(-9.97, 14.81)$. Carstensen advises the inclusion of the interaction term for linked replicates, and hence the limits of agreement are recomputed as $(-12.18,17.12)$.






%-----------------------------------------------------------------------------------------------------%
\newpage
\section{Hamlett and Lam}
The methodology proposed by \citet{Roy2009} is largely based on \citet{hamlett}, which in turn follows on from \citet{lam}.

%Lam 99
%In many cases, repeated observation are collected from each subject in sequence  and/or longitudinally.

%Hamlett
%Hamlett re-analyses the data of lam et al to generalize their model to cover other settings not covered by the Lam %method.






The desired outcome of this research is to

\begin{itemize}
	\item Formulate a methodology that represents Best practice in Method Comparison Studies. Indeed the methodology is envsiaged to advance what is considered best practice, inter alia, by making diagnostics procedures a standard part of MCS. 
	
	\item Provide for ease of use such that non-statisticians can master and implement the method, with a level of training that one would expect 
	as part of a Professional CPD programe.
	
\end{itemize}

Apropos of the matter of ease-of-use, certain assumptions must be made.


The user has a reasonable amount of computer literacy.
The user would have a reasonable understanding of statistics, consistent with an undergraduate statistics module. 
That is to say, that the user is acquainted with the idea of $p-$values.

Easy to follow set of instructions to properly implement the method.

%==============================================================================%

Linear Mixed Effects Models can be implemented by using one of the following R packages.
lme4
nlme

The first package to be introducted was nlme, developled by Jose Pinheiro and Douglas Bates ( Authors of the the companion textbook, NAME)

As this package has been under ongoing development for quite a long time, it is now allows for a lot of complex LME implementations. 
Furthermore, nlme is one of the base R packages.  That is to say, when one downloads and installs R, nlme is automatically installed also, and can be called immediately.

Having said that, the authors have pointed to several limitations of the overall methodology thrugh R.
The original developers have both left the project, but other statisticians have taken over the development, and indeed a new version of nlme was released.

LME4 is a more recent package. at a glance, the syntax is easier, but the development is less advanced. There are several functionalities that can not be implemented with lme4 yet. 
As an example - CHAP5 in PB - has no equivalent in LME4. Indeed no textbook exists to co-incide with LME4.

The main author, Douglas Bates, has turned his attention to development of LME models in the Julia programming language.

The nlmeU package is described by its authors as an extesntion of the nlme package, and indeed provides for additionally functionality. The package is also useful as it serves as a companion piece to the 
book by Galecki and Burzwhatski.

The nlme package also allows for the specification of GLS models.

%-----------------------------------------------------------------------------%
\subsection*{Objects and Classes}

The main nlme object is an \texttt{nlme} model.

The main lme4 object is called an \texttt{lmer} model

The lattice package is used for graphical methods.

%=============================================================================%

Model Diagnostics with \texttt{nlme}





\subsection{Inappropriate Techniques for MCS}


\subsection{Links and Papers}
\begin{verbatim}

Westgard Statistics  - http://www.westgard.com/lesson23.htm
\end{verbatim}





%==============================================================================%
\subsection*{Measurement Systems Analysis}The topic of measurement sensitivity anaylysis (MSA, also known as Gauge R\&R) is prevalent in industrial statistics (i.e Six Sigma).

There is extensive literature that covers the area. For the sake of brevity, we will use Cano et al.

For sake of clarity, Cano's definitions of repeatability and reproducibility are listed, with added emphasis.

Reproducibility is rarely, if ever, discussed in the domain of Method Comparison Studies. This may be due to the fact that prevalent methodologies can be used for the problem.However
the methodologies proposed by this research can easily be extended.




\chapter{Introduction}




\chapter{Appendix}


\section*{Bayesian BA - Philip J Schluter}
Bayesian Bland Altman Approaches
%================================%
A multivariate hierarchical Bayesian approach to measuring agreement in repeated
measurement method comparison studies

*http://www.biomedcentral.com/1471-2288/9/6*



\subsection*{Background}
Assessing agreement in method comparison studies depends on two fundamentally important components; validity (the between method agreement) and reproducibility (the within method agreement). 

The Bland-Altman limits of agreement technique is one of the favoured approaches in medical literature for assessing between method validity. However, few researchers have adopted this approach for the assessment of both validity and reproducibility. 

This may be partly due to a lack of a flexible, easily implemented and readily available statistical machinery to analyse repeated measurement method comparison data.

\textbf{Methods}\\
Adopting the Bland-Altman framework, but using Bayesian methods, we present this statistical machinery. Two multivariate hierarchical Bayesian models are advocated, one which assumes that the underlying values for subjects remain static (exchangeable replicates) and one which assumes that the underlying values can change between repeated measurements (non-exchangeable replicates).

\textbf{Results}\\
We illustrate the salient advantages of these models using two separate datasets that have been previously analysed and presented; 
(i) assuming static underlying values analysed using both multivariate hierarchical Bayesian models,  
(ii) assuming each subject's underlying value is continually changing quantity and analysed using the non-exchangeable replicate multivariate hierarchical Bayesian model.  

\textbf{Conclusion}
These easily implemented models allow for full parameter uncertainty, simultaneous method comparison, handle unbalanced or missing data, and provide estimates and credible regions for all the parameters of interest. Computer code for the analyses in also presented, provided in the freely available and currently cost free software package WinBUGS.
<hr>

\section*{Bayesian Approach}
A multivariate hierarchical Bayesian approach to measuring agreement in repeated measurement method comparison studies
PJ Schluter - BMC medical research methodology, 2009 - biomedcentral.com

\begin{itemize}
	\item Assessing agreement in method comparison studies depends on two fundamentally important 
	components; validity (the between method agreement) and reproducibility (the within method 
	agreement). 
	\item The Bland-Altman limits of agreement technique is one of the f
\end{itemize}

%========================%
\section{Escaramis}
% Escaramis et al 2010
% http://www.biomedcentral.com/1471-2288/10/31/
%-----------------------------------------------------%
\subsection{Background}
In an agreement assay, it is of interest to evaluate the degree of agreement between the different methods (devices, instruments or observers) used to measure the same characteristic. We propose in this study a technical simplification for inference about the total deviation index (TDI) estimate to assess agreement between two devices of normally-distributed measurements and describe its utility to evaluate inter- and intra-rater agreement if more than one reading per subject is available for each device.

\subsection{Methods}
We propose to estimate the TDI by constructing a probability interval of the difference in paired measurements between devices, and thereafter, we derive a tolerance interval (TI) procedure as a natural way to make inferences about probability limit estimates. We also describe how the proposed method can be used to compute bounds of the coverage probability.

\subsection{Results}
The approach is illustrated in a real case example where the agreement between two instruments, a handle mercury sphygmomanometer device and an OMRON 711 automatic device, is assessed in a sample of 384 subjects where measures of systolic blood pressure were taken twice by each device. A simulation study procedure is implemented to evaluate and compare the accuracy of the approach to two already established methods, showing that the TI approximation produces accurate empirical confidence levels which are reasonably close to the nominal confidence level.

\subsection{Conclusions}
The method proposed is straightforward since the TDI estimate is derived directly from a probability interval of a normally-distributed variable in its original scale, without further transformations. Thereafter, a natural way of making inferences about this estimate is to derive the appropriate TI. Constructions of TI based on normal populations are implemented in most standard statistical packages, thus making it simpler for any practitioner to implement our proposal to assess agreement.

%-----------------------------------------------------%
%PAGE 3 of 12 COLUMN 1
Lin defined the TDI as the boundary, $\kappa_P$ which capyures a large proportion $p$ of paired based differences from 
two devices or observers within the boundary.

The value of $\kappa_P$ that yeilds $P(|D| <\kappa_p) = p$ where D is the paired-difference variate.

%-----------------------------------------------------%
%PAGE 3 of 12 COLUMN 2

\[ \kappa_P = F^{-1}(p) = \sigma_D \sqrt{\chi^2(p,1,\mu^2_D/\sigma^2_d) }  \]

\[ \kappa_P = Z_{\frac{1+p}{2}} \| \varepsilon\| \]

%-----------------------------------------------------%

%PAGE 5 of 12 COLUMN 1

Tolerance Interval around the TDI estimate

\[ \hat{\kappa_p} = \hat{\mu}_D = Z_{p_i}\sigma_d \]

%-----------------------------------------------------%

%PAGE 5 of 12 COLUMN 2
Coverage Probability is another user friendly measure of agrre,ment which is related to the computation of the TDI.

\section{Schabenberger}

\emph{schab} examines the use and implementation of
influence measures in LME models.

Influence is understood to be the ability of a single or multiple
data points, through their presences or absence in the data, to
alter important aspects of the analysis, yield qualitatively
different inferences, or violate assumptions of the statistical
model (\textit{schabenberger}).

Outliers are the most noteworthy data points in an analysis, and
an objective of influence analysis is how influential they are,
and the manner in which they are influential.

\emph{schab} describes a simple procedure for quantifying
influence. Firstly a model should be fitted to the data, and
estimates of the parameters should be obtained. The second step is
that either single of multiple data points, specifically outliers,
should be omitted from the analysis, with the original parameter
estimates being updated. 

This is known as `\textit{leave one out \ leave k
	out}' analysis. The final step of the procedure is comparing the
sets of estimates computed from the entire and reduced data sets
to determine whether the absence of observations changed the
analysis.

\textit{schabenberger} notes that it is not always possible to
derive influence statistics necessary for comparing full- and
reduced-data parameter estimates. 

%
%\begin{abstract}
%	\noindent This paper reviews the use of diagnostic measures for LME models in SAS. This text has been widely cited by texts that don't deal with SAS implementations.
%\end{abstract}
%

%==================================================================================================== %

In recent years, mixed models have become invaluable tools in the analysis of experimental and observational
data. In these models, more than one term can be subject to random variation. Mixed model
technology enables you to analyze complex experimental data with hierarchical random processes, temporal,
longitudinal, and spatial data, to name just a few important applications. 
%
%\subsection{Stating the LME Model}
%The general linear mixed
%model is
%\[
%Y = X\beta + Zu + \varepsilon\]
%where Y is a $(n\times1)$ vector of observed data, X is an $(n\times p)$ fixed-effects design or regressor matrix of rank
%k, Z is a $(n \times g)$ random-effects design or regressor matrix, $u$ is a $(g \times 1)$ vector of random effects, and $\varepsilon$ is
%an $(n\times1)$ vector of model errors (also random effects). The distributional assumptions made by the MIXED
%procedure are as follows: γ is normal with mean 0 and variance G; $\varepsilon$ is normal with mean 0 and variance
%R; the random components $u$ and $\varepsilon$ are independent. Parameters of this model are the fixed-effects β and
%all unknowns in the variance matrices G and R. The unknown variance elements are referred to as the
%covariance parameters and collected in the vector $theta$.
%===========================================================================%

\emph{schab} remarks that the concept of critiquing the model-data agreement applies in mixed models in the same way as in linear
fixed-effects models. In fact, because of the more complex model structure, you can argue that model and
data diagnostics are even more important. For example, you are not only concerned with capturing the
important variables in the model. You are also concerned with ``distributing” them correctly between the
fixed and random components of the model. The mixed model structure presents unique and interesting
challenges that prompt us to reexamine the traditional ideas of influence and residual analysis.
%==========================================================================%
%This paper presents the extension of traditional tools and statistical measures for influence and residual
%analysis to the linear mixed model and demonstrates their implementation in the MIXED procedure (experimental
%features in SAS 9.1). The remainder of this paper is organized as follows. The “Background” section
%briefly discusses some mixed model estimation theory and the challenges to model diagnosis that result
%from it.

%	 The diagnostics implemented in the MIXED procedure are discussed in the “Residual Diagnostics
%	in the MIXED Procedure” section (page 3) and the “Influence Diagnostics in the MIXED Procedure” section
%	(page 5). The syntax options and suboptions you use to request the various diagnostics are briefly sketched
%	in the “Syntax” section (page 9). The presentation concludes with an example.
%	
%	
%====================================================================================================================%



\section{Hawkins : Diagnostics for conformity of paired quantitative measurements}

\begin{itemize}
	\item Matched pairs data arise in many contexts – in case-control clinical trials, for example, and from cross-over designs. They also arise in experiments to verify the equivalence of quantitative assays. This latter use (which is the main focus of this paper) raises difficulties not always seen in other matched pairs applications. 
	
	\item Since the designs deliberately vary the analyte levels over a wide range, issues of variance dependent on mean, calibrations of differing slopes, and curvature all need to be added to the usual model assumptions such as normality. 
	
	\item Violations in any of these assumptions invalidate the conventional matched pairs analysis. 
	
	\item A graphical method, due to Bland and Altman, of looking at the relationship between the average and the difference of the members of the pairs is shown to correspond to a formal testable regression model. 
	
	\item Using standard regression diagnostics, one may detect and diagnose departures from the model assumptions and remedy them – for example using variable transformations. Examples of different common scenarios and possible approaches to handling them are shown.
\end{itemize}
%====================================%

% 1. Problem Description
% 2. A Statistical Formulation
%    2.1 Regression Methods for Testing Equivalence
%    2.2 Matched Pair Analysis
% 3. Regression of Differences on Sums
%    3.1 Use of Formal regression Diagnostics
% 4. Examples
%    4.1 Example 1
%    4.2 Detection and Cure of Heteroscedascity
%    4.3 Example 2
%    4.4 Example 3
%    4.5 Example 4
%    4.6 Example 5
% 5. Precepts for Design
% 6. Conclusion


%====================================%
A multi-Rate nonparametric test of agreement and corresponding agreement plot

- Published in: Computational Statistics and Data Analysis 54(2010)109-119
- Author: Alan D. Hutson, University of Buffalo



This approach takes advantage of readily avilable tests of uniformity found in most statistical software packages.
Such tests include the KS d statistic, the Anderson Darling Statistic and the Cramer-Von Mises statistical test for univariate data.

An important aspect of this approach is the "Agreement Region".



\section*{Roy Test}

Roy’s Tests (Roy 2009)
%=============================%
Roy 2009 devised an LME based Testing approach to the MCS problem, based on earlier work by Hamlett et al. 
Roy 2009 presents a series of three formal hypothesis tests for assessing agreement between two methods of measurement.
Roy also alludes to some of the current shortcomings of the approach.

%%%% Components of Test

Comparing different model specifications with LRT tests

%%%% Papers:
- Roy 2007
- Roy 2009
- Hamlett et al.
- Roy Leiva 2011



Conventionally LME models can be tested using Likelihood Ratio Tests, wherein a reference model is compared to a nested model.
\begin{verbatim}
> Ref.Fit = lme(y ~ meth-1, data = dat,   #Symm , Symm#
+     random = list(item=pdSymm(~ meth-1)), 
+     weights=varIdent(form=~1|meth),
+     correlation = corSymm(form=~1 | item/repl), 
+     method="ML")
\end{verbatim}
Roy(2009) presents two nested models that specify the condition of equality as required, with a third nested model for an additional test. There three formulations share the same structure, and can be specified by making slight alterations of the code for the Reference Model.
\begin{verbatim}
Nested Model (Between-Item Variability)
> NMB.fit  = lme(y ~ meth-1, data = dat,   #CS , Symm#
+     random = list(item=pdCompSymm(~ meth-1)),
+     correlation = corSymm(form=~1 | item/repl), 
+     method="ML")
\end{verbatim}



\begin{verbatim}
Nested Model (Within –item Variability)
> NMW.fit = lme(y ~ meth-1, data = dat,   #Symm , CS# 
+     random = list(item=pdSymm(~ meth-1)),
+     weights=varIdent(form=~1|meth), 
+     correlation = corCompSymm(form=~1 | item/repl), 
+     method="ML")
\end{verbatim}


Nested Model (Overall Variability)
Additionally there is a third nested model, that can be used to test overall variability, substantively a a joint test for between-item and within-item variability. The motivation for including such a test in the suite is not clear, although it does circumvent the need for multiple comparison procedures in certain circumstances, hence providing a simplified procedure for non-statisticians.
\begin{verbatim}
> NMO.fit = lme(y ~ meth-1, data = dat,   #CS , CS# 
+     random = list(item=pdCompSymm(~ meth-1)), 
+     correlation = corCompSymm(form=~1 | item/repl), 
+     method="ML")
\end{verbatim}

ANOVAs  for  Original Fits
The likelihood Ratio test is very simple to implement in R. All that is required it to specify the reference model and the relevant nested mode as arguments to the command anova().
The figure below displays the three tests described by Roy (2009).
\begin{verbatim}
> testB    = anova(Ref.Fit,NMB.fit)                          # Between-Subject Variabilities
> testW   = anova(Ref.Fit,NMW.fit)                        # Within-Subject Variabilities
> testO     = anova(Ref.Fit,NMO.fit)                        # Overall Variabilities
\end{verbatim}
\newpage

\section{Turkan's LMEs}
% Influence Analysis in the LME Models
% Turkan and Toktamus
% Pakistan Journal of Statistics;2012, Vol. 28 Issue 3, p341

% - http://www.tandfonline.com/doi/abs/10.1080/03610920903564727?journalCode=lsta20#.VHj9vfmsXE4

The linear mixed model is considerably sensitive to outliers and influential observations. 
It is known that outliers and influential observations affect substantially the results of analysis. 
So it is very important to be aware of these observations. 

Some diagnostics which are analogue of diagnostics in multiple linear regression were developed to detect 
outliers and influential observations in the linear mixed model. 
\emph{
	In this paper, the new diagnostic measure which is analogue of the Pena's influence statistic is developed for 
	the linear mixed model.
}
\newpage
%-----------------------------------------------------------------------------------------%

%page 341

%-----------------------------------------------------------------------------------------%
%page 342
Estimation and Building blacks in LME models

%-----------------------------------------------------------------------------------------%
%page 343

\[ \hat{u} = DZ^{T}H^{-1}(y-X\hat{\beta}) \]

\[ \hat{y} = (I_n -  H^{-1})y + H^{-1}X\hat{\beta}\]

%-----------------------------------------------------------------------------------------%
%page 345

The proposed diagnostic Measure.

%-----------------------------------------------------------------------------------------%
% http://halweb.uc3m.es/esp/Personal/personas/dpena/articles/TECHanews2005.pdf

\subsection{Ordinary Least Product Regression}
\citet{ludbrook97} states that the grouping structure can be
straightforward, but there are more complex data sets that have a
hierarchical(nested) model.
\\
\\
Observations between groups are independent, but observations
within each groups are dependent because they belong to the same
subpopulation. Therefore there are two sources of variation:
between-group and within-group variance.
\vspace{5 mm} \noindent Mean correction is a method of reducing
bias.







\subsection{A regression based approach based on Bland Altman Analysis}
Lu et al used such a technique in their comparison of DXA
scanners. They also used the Blackwood Bradley test. However it
was shown that, for particular comparisons,  agreement between
methods was indicated according to one test, but lack of agreement
was indicated by the other.


\section{Measurement Error Models}
\citet{DunnSEME} proposes a measurement error model for use in
method comparison studies. Consider n pairs of measurements
$X_{i}$ and $Y_{i}$ for $i=1,2,...n$.
\begin{equation}
X_{i} = \tau_{i}+\delta_{i}\\
\end{equation}
\begin{equation}
Y_{i} = \alpha +\beta\tau_{i}+\epsilon_{i} \nonumber
\end{equation}

In the above formulation is in the form of a linear structural
relationship, with $\tau_{i}$ and $\beta\tau_{i}$ as the true
values , and $\delta_{i}$ and $\epsilon_{i}$ as the corresponding
measurement errors. In the case where the units of measurement are
the same, then $\beta =1$.

\begin{equation}
E(X_{i}) = \tau_{i}\\
\end{equation}
\begin{equation}
E(Y_{i}) = \alpha +\beta\tau_{i} \nonumber
\end{equation}
\begin{equation}
E(\delta_{i}) = E(\epsilon_{i}) = 0 \nonumber
\end{equation}

The value $\alpha$ is the inter-method bias between the two
methods.

\begin{eqnarray}
z_0 &=& d = 0 \\
z_{n+1} &=& z_n^2+c
\end{eqnarray}

% http://www.jstor.org/discover/10.2307/1269550?uid=3738232&uid=2&uid=4&sid=21103552726783

% Abstract for CPJ paper
% Mixed linear models arise in many areas of application. 
% Standard estimation methods for mixed models are sensitive to bizarre observations. 
% Such influential observations can completely distort an analysis and lead to inappropriate actions and conclusions. 
% We develop case-deletion diagnostics for detecting influential observations in mixed linear models. 
% Diagnostics for both fixed effects and variance components are proposed. 
% Computational formulas are given that make the procedures feasible. 
% The methods are illustrated using examples.




\section{Work List}
\begin{enumerate}
	\item ML v REML
	\item Nested Models and LRTs
	\item Generalized Lease Squares
	\item Diagnostics
	\item Simplifying GLS
	\item Paper progression
\end{enumerate}





\newpage
%--------------------------------------------------------------------Diagnostics%
\section{Diagnostics}

%http://www.artifex.org/~meiercl/R_statistics_guide.pdf
\subsection{Identifying outliers with a LME model object}

The process is slightly different than with standard LME model objects, since the \textbf{\emph{influence}}
function does not work on lme model objects. Given \textbf{\emph{mod.lme}}, we can use the plot function to
identify outliers.
%----------------------%
\subsection{Diagnostics for Random Effects}
Empirical best linear unbiased predictors EBLUPS provide the a useful way of diagnosing random effects.

EBLUPs are also known as ``shrinkage estimators" because they tend to be smaller than the estimated effects would be if they were computed by treating a random factor as if it was fixed (West etal )


%-------------------------------------------------------------------Simplifying GLS by KH -%

%---------------------------------------------------------------------------------------------------%
\newpage

\section{Two-tailed testing} A test for equality of variances, based on the likelihood Ratio test, is very simple to implement using existing methodologies. All that is required it to specify the reference model and the relevant nested mode as arguments to the command \texttt{anova()}. The output can be interpreted in the usual way.

\section{One Tailed Testing}
The approach proposed by Roy deals with the question of agreement, and indeed interchangeability, as developed by Bland and Altman's corpus of work. In the view of Dunn, a question relevant to many practitioners is which of the two methods is more precise.

The relationship between precision and the within-item and between-item variability must be established. Roy establishes the equivalence of repeatability and within-item variability, and hence precision.  The method with the smaller within-item variability can be deemed to be the more precise.

\section{Enabling One Tailed Testing}
A useful approach is to compute the confidence intervals for the ratio of within-item standard deviations (equivalent to the ratio of repeatability coefficients), which can be interpreted in the usual manner ( or alternatively, the ratio of the variances). In fact, the ratio of within-item standard deviations, with the attendant confidence interval,  can be determined using a single \texttt{R} command: \texttt{intervals()}.

Pinheiro and Bates (pg 93-95) give a description of how confidence intervals for the variance components are computed. Furthermore a complete set of confidence intervals can be computed to complement the variance component estimates.
However , to facilitate one tailed testing, What is required is the computation of the variance ratios of within-item and between-item standard deviations.

A naive approach would be to compute the variance ratios by relevant F distribution quantiles. However, the question arises as to the appropriate degrees of freedom. However, Douglas Bates has stated that an alternative approach is required (i.e. Profile Likelihoods)

\begin{quote}
	"The omission of standard errors on variance components is intentional.
	The distribution of an estimator of a variance component is highly
	skewed and obtaining an estimate of the standard deviation of a skewed
	distribution is not very useful.  A much better approach is based on
	profiling the objective function." (Douglas Bates May 2012)
\end{quote}


\section{Profile Likelihood}
Normal-based confidence intervals for a parameter of interest are inaccurate when the sampling distribution of the estimate is skewed. The technique known as profile likelihood can produce confidence intervals with better coverage. It may be used when the model includes only the variable of interest or several other variables in addition. Profile-likelihood confidence intervals are particularly useful in nonlinear models.

Profile likelihood confidence intervals are based on the log-likelihood function.  
%For a single parameter, likelihood theory shows that the 2 points 1.92 units down from the maximum of the log-likelihood function provide a $95\%$ confidence interval when there is no extrabinomial variation (i.e. c = 1)..  The value 1.92 is half of the chi-square value of 3.84 with 1 degree of freedom.

%Thus, the same confidence interval can be computed with the deviance by adding 3.84 to the minimum of the deviance function, where the deviance is the log-likelihood multiplied by -2 minus the -2 log likelihood value of the saturated model.

\section{Implementation of PL Confidence Intervals}

The suitable calculation of confidence limits for this variance ratio are to be computed using the profile likelihood approach. The \texttt{R} package \texttt{profilelikelihood} will be assessed for feasibility, particularly the command \texttt{profilelikelihood.lme()}



%http://cran.r-project.org/web/packages/ProfileLikelihood/ProfileLikelihood.pdf

%http://lme4.r-forge.r-project.org/slides/2011-03-16-Amsterdam/3Profiling.pdf

%http://lme4.r-forge.r-project.org/slides/2009-07-21-Seewiesen/4PrecisionD.pdf



%---------------------------------------------------------------------------%
\newpage
\section{Extension of techniques to LME Models} %1.2

Model diagnostic techniques, well established for classical models, have since been adapted for use with linear mixed effects models.Diagnostic techniques for LME models are inevitably more difficult to implement, due to the increased complexity.

Beckman, Nachtsheim and Cook (1987) \citet{Beckman} applied the \index{local influence}local influence method of Cook (1986) to the analysis of the linear mixed model.

While the concept of influence analysis is straightforward, implementation in mixed models is more complex. Update formulae for fixed effects models are available only when the covariance parameters are assumed to be known.

If the global measure suggests that the points in $U$ are influential, the nature of that influence should be determined. In particular, the points in $U$ can affect the following

\begin{itemize}
	\item the estimates of fixed effects,
	\item the estimates of the precision of the fixed effects,
	\item the estimates of the covariance parameters,
	\item the estimates of the precision of the covariance parameters,
	\item fitted and predicted values.
\end{itemize}






\section{Covariance Parameters} %1.5
The unknown variance elements are referred to as the covariance parameters and collected in the vector $\theta$.
% - where is this coming from?
% - where is it used again?
% - Has this got anything to do with CovTrace etc?
%---------------------------------------------------------------------------%




\section{Carstensen's Mixed Models}

\citet{BXC2004} proposes linear mixed effects models for deriving
conversion calculations similar to Deming's regression, and for
estimating variance components for measurements by different
methods. The following model ( in the authors own notation) is
formulated as follows, where $y_{mir}$ is the $r$th replicate
measurement on subject $i$ with method $m$.

\begin{equation}
y_{mir}  = \alpha_{m} + \beta_{m}\mu_{i} + c_{mi} + e_{mir} \qquad
( e_{mi} \sim N(0,\sigma^{2}_{m}), c_{mi} \sim N(0,\tau^{2}_{m}))
\end{equation}
The intercept term $\alpha$ and the $\beta_{m}\mu_{i}$ term follow
from \citet{DunnSEME}, expressing constant and proportional bias
respectively , in the presence of a real value $\mu_{i}.$
$c_{mi}$ is a interaction term to account for replicate, and
$e_{mir}$ is the residual associated with each observation.
Since variances are specific to each method, this model can be
fitted separately for each method.

The above formulation doesn't require the data set to be balanced.
However, it does require a sufficient large number of replicates
and measurements to overcome the problem of identifiability. The
import of which is that more than two methods of measurement may
be required to carry out the analysis. There is also the
assumptions that observations of measurements by particular
methods are exchangeable within subjects. (Exchangeability means
that future samples from a population behaves like earlier
samples).

%\citet{BXC2004} describes the above model as a `functional model',
%similar to models described by \citet{Kimura}, but without any
%assumptions on variance ratios. A functional model is . An
%alternative to functional models is structural modelling

\citet{BXC2004} uses the above formula to predict observations for
a specific individual $i$ by method $m$;

\begin{equation}BLUP_{mir} = \hat{\alpha_{m}} + \hat{\beta_{m}}\mu_{i} +
c_{mi} \end{equation}. Under the assumption that the $\mu$s are
the true item values, this would be sufficient to estimate
parameters. When that assumption doesn't hold, regression
techniques (known as updating techniques) can be used additionally
to determine the estimates. The assumption of exchangeability can
be unrealistic in certain situations. \citet{BXC2004} provides an
amended formulation which includes an extra interaction term ($
d_{mr} \sim N(0,\omega^{2}_{m}$)to account for this.


\newpage
\citet{BXC2008} sets out a methodology of computing the limits of
agreement based upon variance component estimates derived using
linear mixed effects models. Measures of repeatability, a
characteristic of individual methods of measurements, are also
derived using this method.

\subsection{Using LME models to create Prediction Intervals}
\citet{BXC2004} also advocates the use of linear mixed models in
the study of method comparisons. The model is constructed to
describe the relationship between a value of measurement and its
real value. The non-replicate case is considered first, as it is
the context of the Bland-Altman plots. This model assumes that
inter-method bias is the only difference between the two methods.
A measurement $y_{mi}$ by method $m$ on individual $i$ is
formulated as follows;
\begin{equation}
y_{mi}  = \alpha_{m} + \mu_{i} + e_{mi} \qquad ( e_{mi} \sim
N(0,\sigma^{2}_{m}))
\end{equation}
The differences are expressed as $d_{i} = y_{1i} - y_{2i}$ For the
replicate case, an interaction term $c$ is added to the model,
with an associated variance component. All the random effects are
assumed independent, and that all replicate measurements are
assumed to be exchangeable within each method.

\begin{equation}
y_{mir}  = \alpha_{m} + \mu_{i} + c_{mi} + e_{mir} \qquad ( e_{mi}
\sim N(0,\sigma^{2}_{m}), c_{mi} \sim N(0,\tau^{2}_{m}))
\end{equation}





%-------------------------------------------------------------------------------------------------------%

\chapter{Model Diagnostics}
%---------------------------------------------------------------------------%
%1.1 Introduction to Influence Analysis
%1.2 Extension of techniques to LME Models
%1.3 Residual Diagnostics
%1.4 Standardized and studentized residuals
%1.5 Covariance Parameters
%1.6 Case Deletion Diagnostics
%1.7 Influence Analysis
%1.8 Terminology for Case Deletion
%1.9 Cook's Distance (Classical Case)
%1.10 Cook's Distance (LME Case)
%1.11 Likelihood Distance
%1.12 Other Measures
%1.13 CPJ Paper
%1.14 Matrix Notation of Case Deletion
%1.15 CPJ's Three Propositions
%1.16 Other measures of Influence
\tableofcontents
%===========================================================================%
\newpage

\subsection*{Abstract}
This chapter is broken into two parts. The first part is a review of diagnostics methods for linear models, intended to acquaint the reader with the subject, and also to provide a basis for material covered in the second part. Particular attention is drawn to graphical methods.

The second part of the chapter looks at diagnostics techniques for LME models, firsly covering the theory, then proceeding to a discussion on 
implementing these using \texttt{R} code.

While a substantial body of work has been developed in this area, there is still areas worth exploring. 
In particular the development of graphical techniques pertinent to LME models should be looked at.




%\section{Introduction (Page 1)}
%
%Linear models for uncorrelated data have well established measures to gauge the influence of one or more
%observations on the analysis. For such models, closed-form update expressions allow efficient computations
%without refitting the model. 
%
%
%When similar notions of statistical influence are applied to mixed models,
%things are more complicated. Removing data points affects fixed effects and covariance parameter estimates.
%Update formulas for “\textit{leave-one-out}” estimates typically fail to account for changes in covariance
%parameters. 
%
%Moreover, in repeated measures or longitudinal studies, one is often interested in multivariate
%influence, rather than the impact of isolated points. 

% This paper examines extensions of influence measures
% in linear mixed models and their implementation in the MIXED procedure.









\newpage
%=========================================================================%
\section{Model Validation Framework}
%\section{Model Validation using Residual Diagnostics}
In statistical modelling, the process of model validation is a critical step of model fitting process, but also a step that is too often overlooked. A very simple procedure is to examine commonly-used
metrics, such as the $R^2$ value. However, using a small handful of simple measures and methods is insufficient to properly assess the quality of a fitted model. To do so properly, a full and comprehensive
analysis that tests of all of the assumptions, as far as possible, must be carried out.

%=========================================================================%
%\subsection{Model Validation Framework}
%In classical linear models, this examination of model-data agreement has traditionally revolved around
\citet{schab} describes the model validatin framework as comprised of the following tasks
\begin{itemize}
	\item  overall measures of goodness-of-fit
	\item the informal, graphical examination of estimates of model errors to assess the quality of distributional
	assumptions: residual analysis
	
	
	\item the quantitative assessment of the inter-relationship of model components; for example, collinearity 	diagnostics
	\item the qualitative and quantitative assessment of influence of cases on the analysis, i.e. influence analysis.
\end{itemize}
%The sensitivity of a model is studied through measures that express its stability under perturbations. You
%are not interested in a model that is either overly stable or overly sensitive. Changes in the data or model
%components should produce commensurate changes in the model output. The difficulty is to determine
%when the changes are substantive enough to warrant further investigation, possibly leading to a reformulation
%of the model or changes in the data (such as dropping outliers).

% This paper is primarily concerned with stability of linear mixed models to perturbations of the data; that is, with influence analysis.
%========================================================================================================= %
%\subsection{Residual}



%========================================================================================================= %
%\subsection{Residual Analysis}

Residual analysis is a widely used model validation technique. A residual is simply the difference between an observed value and the corresponding fitted value, as predicted by the model. The rationale is that, if the model is properly fitted to the model, then the residuals would approximate the random errors that one should expect.
that is to say, if the residuals behave randomly, with no discernible trend, the model has fitted the data well. If some sort of non-random trend is evident in the model, then the model can be considered to be poorly fitted.

%========================================================================================================= %
%\subsection{Introduction}
%A statistical model, whether of the fixed-effects or mixed-effects variety, represents how you think your data were generated. 
%Following model specification and estimation, it is of interest to explore the model-data
%agreement by raising questions such as

Statistical software environments, such as the \texttt{R} Programming language, provides a suite of tests and graphical procedure sfor appraising a fitted linear model, with several 
of these procedures analysing the model residuals.

For LME models the matter of residual is more complex. \citet{schab} describes two types
of residuals, marginal residuals and conditional residuals. A marginal residual is the difference between the observed data and the estimated marginal mean. A conditional residual is the
difference between the observed data and the predicted value of
the observation. In a model without random effects, both sets of
residuals coincide. We shall revert to this matter in due course.

Further to the analysis of residuals, \citet{schab} recommends the examination of the following questions.
\begin{itemize}
	\item Does the model-data agreement support the model assumptions?
	\item Should model components be refined, and if so, which components? For example, should regressors
	be added or removed, and is the covariation of the observations modeled properly?
	\item Are the results sensitive to model and/or data? Are individual data points or groups of cases particularly
	influential on the analysis?
\end{itemize}



%========================================================================================================= %
\subsection{Outliers and Leverage}


The question of whether or not a point should be considered an outlier must also be addressed. An outlier is an observation whose true value is unusual given its value on the predictor variables. The leverage of an observation is a further consideration. Leverage describes an observation with an extreme value on a predictor variable is a point with high leverage. High leverage points can have a great amount of effect on the estimate of regression coefficients.
% - Leverage is a measure of how far an independent variable deviates from its mean.

Influence can be thought of as the product of leverage and outlierness. An observation is said to be influential if removing the observation substantially changes the estimate of the regression coefficients. The \texttt{R} programming language has a variety of methods used to study each of the aspects for a linear model. While linear models and GLMS can be studied with a wide range of well-established diagnostic technqiues, the choice of methodology is much more restricted for the case of LMEs.

%---------------------------------------------------------------------------%
%\newpage
%\section{Residual diagnostics} %1.3
For classical linear models, residual diagnostics are typically conducted using a plot of the observed residuals and the predicted values. A visual inspection for the presence of trends inform the analyst on the validity of distributional assumptions, and to detect outliers and influential observations.


\section*{Cook's distance}
In the study of Linear model diagnostics, Cook proposed a measure that combines the information of leverage and residual of the observation, now known simply as the Cook's Distance. \citet{CPJ} would later adapt the Cook's distance measure for the analysis of LME models.



%---------------------------------------------------------------------------%


\section{Zewotir Measures of Influence in LME Models}%2.2
%Zewotir page 161
\citet{Zewotir} describes a number of approaches to model diagnostics, investigating each of the following;
\begin{itemize}
	\item Variance components
	\item Fixed effects parameters
	\item Prediction of the response variable and of random effects
	\item likelihood function
\end{itemize}

\citet{Zewotir} lists several established methods of analyzing influence in LME models. These methods include \begin{itemize}
	\item Cook's distance for LME models,
	\item \index{likelihood distance} likelihood distance,
	\item the variance (information) ration,
	\item the \index{Cook-Weisberg statistic} Cook-Weisberg statistic,
	\item the \index{Andrews-Prebigon statistic} Andrews-Prebigon statistic.
\end{itemize}




%---------------------------------------------------------------------------%
\newpage
\section{Matrix Notation for Case Deletion} %1.14

\subsection{Case deletion notation} %1.14.1

For notational simplicity, $\boldsymbol{A}(i)$ denotes an $n \times m$ matrix $\boldsymbol{A}$ with the $i$-th row
removed, $a_i$ denotes the $i$-th row of $\boldsymbol{A}$, and $a_{ij}$ denotes the $(i, j)-$th element of $\boldsymbol{A}$.
%
%\subsection{Partitioning Matrices} %1.14.2
%Without loss of generality, matrices can be partitioned as if the $i-$th omitted observation is the first row; i.e. $i=1$.



\subsection{Further Assumptions of Linear Models}

As with fitted models, the assumption of normality of residuals and homogeneity of variance is applicable to LMEs also. 

%--------------------------------------%


Homoscedascity is the technical term to describe the variance of the
residuals being constant across the range of predicted values.
Heteroscedascity is the converse scenario : the variance differs along
the range of values.

%--Marginal and Conditional Residuals

%\subsection{INFLUENCE DIAGNOSTICS IN THE MIXED PROCEDURE}
%Key to the implementations of influence diagnostics in the MIXED procedure is the attempt to quantify
%influence, where possible, by drawing on the basic definitions of the various statistics in the classical linear
%model. 

On occasion, quantification is not possible. Assume, for example, that a data point is removed
and the new estimate of the G matrix is not positive definite. This may occur if a variance component
estimate now falls on the boundary of the parameter space. Thus, it may not be possible to compute certain
influence statistics comparing the full-data and reduced-data parameter estimates. However, knowing that
a new singularity was encountered is important qualitative information about the data point’s influence on
the analysis.

The basic procedure for quantifying influence is simple:

\begin{enumerate}
	\item Fit the model to the data and obtain estimates of all parameters.
	\item Remove one or more data points from the analysis and compute updated estimates of model parameters.
	\item Based on full- and reduced-data estimates, contrast quantities of interest to determine how the absence
	of the observations changes the analysis.
\end{enumerate}
We use the subscript (U) to denote quantities obtained without the observations in the set U. For example,
%βb
(U) denotes the fixed-effects “\textit{\textbf{leave-U-out}}” estimates. Note that the set U can contain multiple observations.


%===================================================================================
If the global measure suggests that the points in U are influential, you should next determine the nature of
that influence. In particular, the points can affect
\begin{itemize}
	\item the estimates of fixed effects
	\item the estimates of the precision of the fixed effects
	\item the estimates of the covariance parameters
	\item the estimates of the precision of the covariance parameters
	\item fitted and predicted values
\end{itemize}

It is important to further decompose the initial finding to determine whether data points are actually troublesome.
Simply because they are influential “somehow”, should not trigger their removal from the analysis or
a change in the model. For example, if points primarily affect the precision of the covariance parameters
without exerting much influence on the fixed effects, then their presence in the data may not distort hypothesis
tests or confidence intervals about $\beta$.
%They will only do so if your inference depends on an estimate of the
%precision of the covariance parameter estimates, as is the case for the Satterthwaite and Kenward-Roger
%degrees of freedom methods and the standard error adjustment associated with the DDFM=KR option.

%------------------------------------------------------------%
\subsection{Summary of Paper}
%Summary of Schabenberger
Standard residual and influence diagnostics for linear models can be extended to LME models.
The dependence of the fixed effects solutions on the covariance parameters has important ramifications on the perturbation analysis.	
Calculating the studentized residuals-And influence statistics whereas each software procedure can calculate both conditional and marginal raw residuals, only SAs Proc Mixed is currently the only program that provide studentized residuals Which ave preferred for model diagnostics. The conditional Raw residuals ave not well suited to detecting outliers as are the studentized conditional residuals. (schabenbege r)


LME are flexible tools for the analysis of clustered and repeated measurement data. LME extend the capabilities of standard linear models by allowing unbalanced and missing data, as long as the missing data are MAR. Structured covariance matrices for both the random effects G and the residuals R. missing at Random.

A conditional residual is the difference between the observed valve and the predicted valve of a dependent variable- Influence diagnostics are formal techniques that allow the identification observation that heavily influence estimates of parameters.
To alleviate the problems with the interpretation of conditional residuals that may have unequal variances, we consider sealing.
Residuals obtained in this manner ave called studentized residuals.



%---------------------------------------------------------------%
\section{Schabenberger: Summary and Conclusions}
\begin{itemize}
	\item Standard residual and inﬂuence diagnostics for linear models can be extended to linear mixed models. The dependence of ﬁxed-effects solutions on the covariance parameter estimates has important ramiﬁcations in perturbation analysis. 
	\item To gauge the full impact of a set of observations on the analysis, covariance parameters need to be updated, which requires reﬁtting of the model. 
	\item The experimental INFLUENCE option of the MODEL statement in the MIXED procedure (SAS 9.1) enables you to perform iterative and noniterative inﬂuence analysis for individual observations and sets of observations.
	
	\item The conditional (subject-speciﬁc) and marginal (population-averaged) formulations in the linear mixed model enable you to consider conditional residuals that use the estimated BLUPs of the random effects, and marginal residuals which are deviations from the overall mean. 
	\item Residuals using the BLUPs are useful to diagnose whether the random effects components in the model are speciﬁed correctly, marginal residuals are useful to diagnose the ﬁxed-effects components. 
	\item Both types of residuals are available in SAS 9.1 as an experimental option of the MODEL statement in the MIXED procedure.
	
	\item It is important to note that influence analyses are performed under the assumption that the chosen model is correct. Changing the model structure can alter the conclusions. Many other variance models have been ﬁt to the data presented in the repeated measures example. You need to see the conclusions about which model component is affected in light of the model being fit.
	%	\item  For example, modeling these data with a random intercept and random slope for each child or an unstructured covariance matrix will affect your conclusions about which children are inﬂuential on the analysis and how this influence manifests itself.
\end{itemize}











% Diagnostics with nlmeU

\section*{Leave-One-Out Diagnostics with \texttt{lmeU}}
Galecki et al provide a brief the matter of LME influence diagnostics in their book.

The command \texttt{lmeU} fits a model with a particular subject removed. The identifier of the subject to be removed is passed as the only argument

A plot ofthe per-observation diagnostics individual subject log-likelihood contributions can be rendered.

\subsubsection*{The addition of an extra factor}


%=========================================================================%


Interaction terms are featured in ANOVA designs.

%=========================================================================%
My search just now found no mention of Cook's distance or influence measures.  

The closest I found was an unanswered question on this from 
April 2003 (http://finzi.psych.upenn.edu/R/Rhelp02a/archive/4797.html).

Beyond that, there is an excellent discussion of "Examining a Fitted Model" in Sec. 4.3 (pp. 174-197) of Pinheiro and Bates (2000) 
Mixed-Effects Models in S and S-Plus (Springer).  

Pinheiro and Bates decided NOT to include plots of Cook's distance among the many diagnostics they did provide.  
However, 'plot(fit.lme)' plots 'standardized residuals' vs. predicted or 'fitted values'.  
Wouldn't points with large influence stand apart from the crowd in terms of 'fitted value'?

Of course, there are many things other one could do to get at related information, including reading the code for 'influence' and 'lme', and 
figure out from that how to write an 'influence' method for an 'lme' object. 


%============================================================================%

\section{Paired T tests}
This method can be applied to test for statisitcally significant
deviations in bias. This method can be potentially misused for
method comparison studies.
\\It is a poor measure of agreement when the rater's measurements
are perpendicular to the line of equality[Hutson et al]. In this
context, an average difference of zero between the two raters, yet
the scatter plot displays strong negative correlation.

\subsection*{Components in assessing agreement}

\begin{enumerate}
	\item The degree of linear relationship between the two sets \item
	The amount of bias as represented by the difference in the
	means\item The Differences in the two variances.
\end{enumerate}

\section{Methods of assessing agreement}

\begin{enumerate}
	\item Pearson's Correlation Coefficient\item Intraclass
	correlation coefficient \item Bland Altman Plot \item Bartko's
	Ellipse (1994) \item Blackwood Bradley Test \item Lin's
	Reproducibility Index \item Luiz Step function
\end{enumerate}

Bland and Altman attend to the issue of repeated measures in
$1996$.

Repeated measurements on several subjects can be used to quantify
measurement error, the variation between measurements of the same
quantity on the same individual.

Bland and Altman discuss two metrics for measurement error; the
within-subject standard deviation ,and the correlation
coefficient.

The above plot incorporates both the conventional limits of
agreement ( the inner pair of dashed lines), the `t' limits of
agreement ( the outer pair of dashed lines) centred around the
inter-method bias (indicated by the full line). This plot is
intended for expository purposes only, as the sample size is
small.





\subsection{Equivalence and Interchangeability}
Limits of agreement are intended to analyse equivalence. How this
is assessed is the considered judgement of the practitioner. In
\citet{BA86} an example of good agreement is cited. For two
methods of measuring `oxygen saturation', the limits of agreement
are calculated as (-2.0,2.8).A practitioner would ostensibly find
this to be sufficiently narrow.

If the limits of agreement are not clinically important, which is
to say that the differences tend not to be substantial, the two
methods may be used interchangeably. \citet{DunnSEME} takes issue
with the notion of `equivalence', remarking that while agreement
indicated equivalence, equivalence does not reflect agreement.




%---------------------------------------------------------------------------%
\section{Introduction}%1.1
In classical linear models model diagnostics have been become a required part of any statistical analysis, and the methods are commonly available in statistical packages and standard textbooks on applied regression. However it has been noted by several papers that model diagnostics do not often accompany LME model analyses.

\subsection{Checking model assumptions}
In classical linear regression, it is important to carry out model diagnostic techniques to determine whether or not the distributional assumptions are satisfied. Model diagnostics are also used to determine the influence of unusual observations.

\citet{schabenberger} describes the examination of model-data agreement as comprising several elements; residual analysis, goodness of fit, collinearity diagnostics and influence analysis.

\subsection{Influence Diagnostics: Basic Idea and Statistics}
%http://support.sas.com/documentation/cdl/en/statug/63033/HTML/default/viewer.htm#statug_mixed_sect024.htm

The general idea of quantifying the influence of one or more observations relies on computing parameter estimates based on all data points, removing the cases in question from the data, refitting the model, and computing statistics based on the change between full-data and reduced-data estimation. Influence statistics can be coarsely grouped by the aspect of estimation that is their primary target:
\begin{itemize}
	\item overall measures compare changes in objective functions: (restricted) likelihood distance (Cook and Weisberg 1982, Ch. 5.2)
	\item influence on parameter estimates: Cook's  (Cook 1977, 1979), MDFFITS (Belsley, Kuh, and Welsch 1980, p. 32)
	\item influence on precision of estimates: CovRatio and CovTrace
	\item influence on fitted and predicted values: PRESS residual, PRESS statistic (Allen 1974), DFFITS (Belsley, Kuh, and Welsch 1980, p. 15)
	\item outlier properties: internally and externally studentized residuals, leverage
\end{itemize}

\subsection{Introduction }
The linear mixed effects model is a useful methodology for fitting a wide range of models. However, linear mixed effects models are known to be sensitive to outliers. \citet{christensen} advises that identification of outliers is necessary before conclusions may be drawn from the fitted model.

Standard statistical packages concentrate on calculating and testing parameter estimates without considering the diagnostics of the model.

The assessment of the effects of perturbations in data, on the outcome of the analysis, is known as statistical influence analysis. Influence analysis examines the robustness of the model.

Influence analysis methodologies have been used extensively in classical linear models, and provided the basis for methodologies for use with LME models.

Computationally inexpensive diagnostics tools have been developed to examine the issue of influence \citep{tewomir}.
Studentized residuals, error contrast matrices and the inverse of the response variance covariance matrix are regular components of these tools.

\section{Outline of Thesis}
Thus the study of method comparison is introduced. The intention of this thesis is to progress the
study of method comparison studies, using a statistical method known as Linear mixed effects models.
Chapter two shall describe linear mixed effects models, and how the use of the linear mixed
effects models have so far extended to method comparison studies. Implementations of important existing work shall be presented, using the \texttt{R} programming language.

Model diagnostics are an integral component of a complete statistical analysis.
In chapter three model diagnostics shall be described in depth, with particular
emphasis on linear mixed effects models, further to chapter two.

For the fourth chapter, important linear mixed effects model diagnostic methods shall be extended to method comparison studies, and proposed methods shall be demonstrated on data sets that have become well known in literature on method comparison. The purpose is to both calibrate these methods and to demonstrate applications for them.
The last chapter shall focus on robust measures of important parameters such as agreement.



\section{Extension of technique to LME Models} %1.4

Model diagnostic techniques , well established for classical models, have since been adapted for use with linear mixed effects models.Diagnostic techniques for LME models are inevitably more difficult to implement, due to the increased complexity.

Beckman, Nachtsheim and Cook (1987) applied the \index{local influence}local influence method of Cook (1986)
to the analysis of the linear mixed model.


While the concept of influence analysis is straightforward, implementation in mixed models is more complex. Update formulae for fixed effects models are available only when the covariance parameters are assumed to be known.


If the global measure suggests that the points in $U$ are influential, the nature of that influence should be determined. In particular, the points in $U$ can affect
\begin{itemize}
	\item the estimates of fixed effects
	\item the estimates of the precision of the fixed effects
	\item the estimates of the covariance parameters
	\item the estimates of the precision of the covariance parameters
	\item fitted and predicted values
\end{itemize}





\subsection{Methods and Measures}
The key to making deletion diagnostics useable is the development of efficient
computational formulas, allowing one to obtain the \index{case deletion diagnostics} case deletion diagnostics by
making use of basic building blocks, computed only once for the full model.

\citet{Zewotir} lists several established methods of analyzing influence in LME models. These methods include \begin{itemize}
	\item Cook's distance for LME models,
	\item \index{likelihood distance} likelihood distance,
	\item the variance (information) ration,
	\item the \index{Cook-Weisberg statistic} Cook-Weisberg statistic,
	\item the \index{Andrews-Prebigon statistic} Andrews-Prebigon statistic.
\end{itemize}






\section{Haslett's Analysis} %1.12
For fixed effect linear models with correlated error structure Haslett (1999) showed that the effects on
the fixed effects estimate of deleting each observation in turn could be cheaply computed from the fixed effects model predicted residuals.



%---------------------------------------------------------------------------%
\newpage
\section{Augmented GLMs} %1.17


%Augmented Generalized linear models.
% Youngjo et al page 154
Generalized linear models are a generalization of classical linear
models.

The subscript $M$ is a label referring to the mean model.
\begin{equation}
\left(%
\begin{array}{c}
Y \\
\psi_{M} \\
\end{array}%
\right) = \left(
\begin{array}{cc}
X & Z \\
0 & I \\
\end{array}\right) \left(%
\begin{array}{c}
\beta \\
\nu \\
\end{array}%
\right)+ e^{*}
\end{equation}


%Augmented Generalized linear models.


The error term $e^{*}$ is normal with mean zero. The variance matrix of the error term is given by
\begin{equation}
\Sigma_{a} = \left(%
\begin{array}{cc}
\Sigma & 0 \\
0 & D \\
\end{array}%
\right).
\end{equation}

\begin{equation}
X = \left(%
\begin{array}{cc}
T & Z \\
0 & I \\
\end{array}%
\right)
\delta = \left(%
\begin{array}{c}
\beta  \\
\nu  \\
\end{array}%
\right)
\end{equation}



\begin{equation}
y_{a} = T \delta + e^{*}
\end{equation}

Weighted least squares equation


% Youngjo et al page 154

%--------------------------------------------------------------------------%
\newpage
\section{Covariance Parameters} %1.18
The unknown variance elements are referred to as the covariance parameters and collected in the vector $\theta$.




\chapter{Roy2013}

http://business.utsa.edu/wps/MSS/0017MSS-253-2013.pdf


Testing the Equality of Mean Vectors for Paired Doubly Multivariate Observations 


Example 2. (Mineral Data): This data set is taken from Johnson and Wichern (2007, p. 43).
An investigator measured the mineral content of bones (radius, humerus and ulna) by photon
absorptiometry to examine whether dietary supplements would slow bone loss in 25 older women.
Measurements were recorded for three bones on the dominant and nondominant sides. Thus,
the data is doubly multivariate and clearly u = 2 and q = 3.
The bone mineral contents for the ﬁrst 24 women one year after their participation in an
experimental program is given in Johnson and Wichern (2007, p. 353). 



Thus, for our analysis
we take only ﬁrst 24 women in the ﬁrst data set. We test whether there has been a bone loss
considering the data as doubly multivariate and has BCS structure. We rearrange the variables
in the data set by grouping together the mineral content of the dominant sides of radius, humerus
and ulna as the ﬁrst three variables, that is, the variables in the ﬁrst location (u = 1) and then
the mineral contents for the non-dominant side of the same bones (u = 2)



\section{Outlier Testing} 
A new outlier identification test for method comparison studies based on robust regression.

The identification of outliers in method comparison studies (MCS) is an important part of data analysis, as outliers can indicate serious errors in the measurement process. Common outlier tests proposed in the literature usually require a homogeneous sample distribution and homoscedastic random error variances. However, datasets in MCS usually do not meet these assumptions. In this work, a new outlier test based on robust linear regression is proposed to overcome these special problems. The LORELIA (local reliability) residual test is based on a local, robust residual variance estimator, given as a weighted sum of the observed residuals. The new test is compared to a standard test proposed in the literature by a Monte Carlo simulation. Its performance is illustrated in examples.

\section{Lorelia}


Method comparison studies are performed in order to prove equivalence between two measurement methods or instruments. The identification of outliers is an important part of data analysis as outliers can indicate serious errors in the measurement process. Common outlier tests 
proposed in the literature require a homogeneous sample distribution and homoscedastic random error variances. However, datasets in method comparison studies usually do not meet these assumptions. To overcome this problem, different data transformation methods are proposed in the literature. However, they will only be applicable if the random errors can be described by simple additive or multiplicative models. In this work, a new outlier test based on robust linear regression is proposed which provides a general solution to the above problem. The LORELIA (LOcal RELIAbility) residual test is based on a local, robust residual variance estimator, given as a weighted sum of the observed residuals. Outlier limits are estimated from the actual data situation without making assumptions on the underlying error variance model. The performance of the new test is demonstrated in examples and simulations.

\section{Note on Roy's paper}
\begin{enumerate}
	
	
	\item Basic model:
	\begin{center}
		$ \boldsymbol{y_{i}} = \boldsymbol{X_{i}\beta}
		+ \boldsymbol{Z_{i}b_{i}} + \boldsymbol{\epsilon_{i}}, \qquad i=1,\dots,n$ \\
		$\boldsymbol{Z_{i}} \sim \mathcal{N}(\boldsymbol{0,\Sigma}),\quad
		\boldsymbol{\epsilon_{i}} \sim \mathcal{N}(\boldsymbol{0, \sigma^2
			\boldsymbol{I} })$
	\end{center}
	
	Assumptions are made about homoskedasticity.
	
	\item General model:
	\begin{center}
		$ \boldsymbol{y_{i}} = \boldsymbol{X_{i}\beta}
		+ \boldsymbol{Z_{i}b_{i}} + \boldsymbol{\epsilon_{i}}, \qquad i=1,\dots,n$ \\
		$\boldsymbol{Z_{i}} \sim \mathcal{N}(\boldsymbol{0,\Psi}),\quad
		\boldsymbol{\epsilon_{i}} \sim \mathcal{N}(\boldsymbol{0,\sigma^2 \boldsymbol{\Lambda} })$
	\end{center}
	
	Assumptions about homoskedasticity are relaxed \cite[pg.202]{pb}.
	
	
	
	
	
	\item $\sigma^2 \boldsymbol{\Lambda}$ is the general form for the VC structure for residuals.
	
	\item The response vector $\boldsymbol{y}_{i}$ comprises the observations of
	the subject, as measured by two methods, taking three measurements each.
	Hence a $6 \times 1$ random vector corresponding to the $i$th subject.
	\begin{equation}
	\boldsymbol{y}_{i} = (y_{i}^{j1},y_{i}^{Jj2},y_{i}^{j3},y_{i}^{s1},y_{i}^{s2},y_{i}^{s3}) \prime
	\end{equation}
	
	\item The number of replicates is $p$. A subject will have up to
	$2p$ measurements, for the two instrument case, i.e. $Max(n_{i}) = 2p$.
	(Let $k$ denote number of instruments, which is assumed to be $2$
	unless stated otherwise.) For the blood pressure data $p=3$.
	
	
\end{enumerate}




%\section{Introduction (Page 1)}
%
%Linear models for uncorrelated data have well established measures to gauge the influence of one or more
%observations on the analysis. For such models, closed-form update expressions allow efficient computations
%without refitting the model. 
%
%
%When similar notions of statistical influence are applied to mixed models,
%things are more complicated. Removing data points affects fixed effects and covariance parameter estimates.
%Update formulas for “\textit{leave-one-out}” estimates typically fail to account for changes in covariance
%parameters. 
%
%Moreover, in repeated measures or longitudinal studies, one is often interested in multivariate
%influence, rather than the impact of isolated points. 

% This paper examines extensions of influence measures
% in linear mixed models and their implementation in the MIXED procedure.















%========================================================================================================= %
\subsection{Outliers and Leverage}



The question of whether or not a point should be considered an outlier must also be addressed. An outlier is an observation whose true value is unusual given its value on the predictor variables. The leverage of an observation is a further consideration. Leverage describes an observation with an extreme value on a predictor variable is a point with high leverage. High leverage points can have a great amount of effect on the estimate of regression coefficients.
% - Leverage is a measure of how far an independent variable deviates from its mean.

Influence can be thought of as the product of leverage and outlierness. An observation is said to be influential if removing the observation substantially changes the estimate of the regression coefficients. The \texttt{R} programming language has a variety of methods used to study each of the aspects for a linear model. While linear models and GLMS can be studied with a wide range of well-established diagnostic technqiues, the choice of methodology is much more restricted for the case of LMEs.

%---------------------------------------------------------------------------%
%\newpage
%\section{Residual diagnostics} %1.3
For classical linear models, residual diagnostics are typically conducted using a plot of the observed residuals and the predicted values. A visual inspection for the presence of trends inform the analyst on the validity of distributional assumptions, and to detect outliers and influential observations.

%\section{Case Deletion Diagnostics}
%
%
%Linear models for uncorrelated data have well established measures to gauge the influence of one or more
%observations on the analysis. For such models, closed-form update expressions allow efficient computations
%without refitting the model. 
%
%
%Since the pioneering work of Cook in 1977, deletion measures have been applied to many statistical models for identifying influential observations. Case-deletion diagnostics provide a useful tool for identifying influential observations and outliers.
%
%The key to making deletion diagnostics useable is the development of efficient computational formulas, allowing one to obtain the \index{case deletion diagnostics} case deletion diagnostics by making use of basic building blocks, computed only once for the full model.
%
%The computation of case deletion diagnostics in the classical model is made simple by the fact that estimates of $\beta$ and $\sigma^2$, which exclude the $i-$th observation, can be computed without re-fitting the model. %\subsection{Terminology for Case Deletion diagnostics} %1.8
%
%\citet{preisser} describes two type of diagnostics. When the set consists of only one observation, the type is called
%`\textit{observation-diagnostics}'. For multiple observations, Preisser describes the diagnostics as `\textit{cluster-deletion}' diagnostics. When applied to LME models, such update formulas are available only if one assumes that the covariance parameters are not affected by the removal of the observation in question. However, this is rarely a reasonable assumption.
%
%
%
%
%%---------------------------------------------------------------------------%
\subsection{Matrix Notation for Case Deletion} %1.14

%\subsection{Case deletion notation} %1.14.1

For notational simplicity, $\boldsymbol{A}(i)$ denotes an $n \times m$ matrix $\boldsymbol{A}$ with the $i$-th row
removed, $a_i$ denotes the $i$-th row of $\boldsymbol{A}$, and $a_{ij}$ denotes the $(i, j)-$th element of $\boldsymbol{A}$.
%
%\subsection{Partitioning Matrices} %1.14.2
%Without loss of generality, matrices can be partitioned as if the $i-$th omitted observation is the first row; i.e. $i=1$.



%-------------------------------------------------------------------------------------------------------------------------------------%
%--------------------------------------%
\subsection{Extension of Diagnostic Methods to LME models}


When similar notions of statistical influence are applied to mixed models,
things are more complicated. Removing data points affects fixed effects and covariance parameter estimates.
Update formulas for “\textit{leave-one-out}” estimates typically fail to account for changes in covariance
parameters. 
%
%
%In LME models, there are two types of residuals, marginal residuals and conditional residuals. A
%marginal residual is the difference between the observed data and the estimated marginal mean. A conditional residual is the
%difference between the observed data and the predicted value of the observation. In a model without random effects, both sets of residuals coincide \citep{schab}.

\citet{Christiansen} noted the case deletion diagnostics techniques have not been applied to linear mixed effects models and seeks to develop methodologies in that respect. \citet{Christiansen} develops these techniques in the context of REML.

\citet{CPJ} noted the case deletion diagnostics techniques had not been applied to linear mixed effects models and seeks to develop methodologies in that respect. \citet{CPJ} develops these techniques in the context of REML.
>>>>>>> origin/master

%\citet{CPJ} develops \index{case deletion diagnostics} case deletion diagnostics, in particular the equivalent of \index{Cook's distance} Cook's distance, a well-known metric, for diagnosing influential observations when estimating the fixed effect parameters and variance components. Deletion diagnostics provide a means of assessing the influence of an observation (or groups of observations) on inference on the estimated parameters of LME models. We shall provide a fuller discussion of Cook's distance in due course.


\citet{Demi} extends several regression diagnostic techniques commonly used in linear regression, such as leverage, infinitesimal influence, case deletion diagnostics, Cook's distance, and local influence to the linear mixed-effects model. In each case, the proposed new measure has a direct interpretation in terms of the effects on a parameter of interest, and reduces to the familiar linear regression measure when there are no random effects. 

The new measures that are proposed by \citet{Demi} are explicitly defined functions and do not require re-estimation of the model, especially for cluster deletion diagnostics. The basis for both the cluster deletion diagnostics and Cook's distance is a generalization of Miller's simple update formula for case deletion for linear models. Furthermore \citet{Demi} shows how Pregibon's infinitesimal case deletion diagnostics is adapted to the linear mixed-effects model. 
%A simple compact matrix formula is derived to assess the local influence of the fixed-effects regression coefficients. 


%
%
%\section{Case Deletion Diagnostics for LME models} %1.6
%
%Data from single individuals, or a small group of subjects may influence non-linear mixed effects model selection. Diagnostics routinely applied in model building may identify such individuals, but these methods are not specifically designed for that purpose and are, therefore, not optimal. 

\citet{Demi} proposes two likelihood-based diagnostics for identifying individuals that can influence the choice between two competing models.


\newpage




\section{Model Validation Framework}
%\section{Model Validation using Residual Diagnostics}
In statistical modelling, the process of model validation is a critical step of model fitting process, but also a step that is too often overlooked. A very simple procedure is to examine commonly-used
metrics, such as the $R^2$ value. However, using a small handful of simple measures and methods is insufficient to properly assess the quality of a fitted model. To do so properly, a full and comprehensive
analysis that tests of all of the assumptions, as far as possible, must be carried out.

%=========================================================================%
%\subsection{Model Validation Framework}
%In classical linear models, this examination of model-data agreement has traditionally revolved around
\citet{schab} describes the model validatin framework as comprised of the following tasks

\begin{itemize}
	\item  overall measures of goodness-of-fit
	\item the informal, graphical examination of estimates of model errors to assess the quality of distributional
	assumptions: residual analysis
	
	
	\item the quantitative assessment of the inter-relationship of model components; for example, collinearity 	diagnostics
	\item the qualitative and quantitative assessment of influence of cases on the analysis, i.e. influence analysis.
\end{itemize}

The sensitivity of a model is studied through measures that express its stability under perturbations. You
are not interested in a model that is either overly stable or overly sensitive. Changes in the data or model
components should produce commensurate changes in the model output. The difficulty is to determine
when the changes are substantive enough to warrant further investigation, possibly leading to a reformulation
of the model or changes in the data (such as dropping outliers). This paper is primarily concerned
with stability of linear mixed models to perturbations of the data; that is, with influence analysis. 
%========================================================================================================= %
\newpage
\subsection{Residual Analysis}

Residual analysis is a widely used model validation technique. A residual is simply the difference between an observed value and the corresponding fitted value, as predicted by the model. The rationale is that, if the model is properly fitted to the model, then the residuals would approximate the random errors that one should expect.
that is to say, if the residuals behave randomly, with no discernible trend, the model has fitted the data well. If some sort of non-random trend is evident in the model, then the model can be considered to be poorly fitted.

%========================================================================================================= %
%\subsection{Introduction}
%A statistical model, whether of the fixed-effects or mixed-effects variety, represents how you think your data were generated. 
%Following model specification and estimation, it is of interest to explore the model-data
%agreement by raising questions such as

Statistical software environments, such as the \texttt{R} Programming language, provides a suite of tests and graphical procedure sfor appraising a fitted linear model, with several 
of these procedures analysing the model residuals.

%========================================================================================================= %
\subsection{Outliers and Leverage}



The question of whether or not a point should be considered an outlier must also be addressed. An outlier is an observation whose true value is unusual given its value on the predictor variables. The leverage of an observation is a further consideration. Leverage describes an observation with an extreme value on a predictor variable is a point with high leverage. High leverage points can have a great amount of effect on the estimate of regression coefficients.
% - Leverage is a measure of how far an independent variable deviates from its mean.

Influence can be thought of as the product of leverage and outlierness. An observation is said to be influential if removing the observation substantially changes the estimate of the regression coefficients. The \texttt{R} programming language has a variety of methods used to study each of the aspects for a linear model. While linear models and GLMS can be studied with a wide range of well-established diagnostic technqiues, the choice of methodology is much more restricted for the case of LMEs.



\section{Regression Of Differences On Averages}
Further to Carstensen, we can formulate the two measurements
$y_{1}$ and $y_{2}$ as follows:
\\
$y_{1} = \alpha + \beta\mu + \epsilon_{1}$
\\
$y_{2} = \alpha + \beta\mu + \epsilon_{2}$








\subsection{Note 1: Coefficient of Repeatability}
The coefficient of repeatability is a measure of how well a
measurement method agrees with itself over replicate measurements
\citep{BA99}. Once the within-item variability is known, the
computation of the coefficients of repeatability for both methods
is straightforward.



\subsection{Note 2: Carstensen model in the single measurement case}
\citet{BXC2004} presents a model to describe the relationship between a value of measurement and its real value.
The non-replicate case is considered first, as it is the context of the Bland-Altman plots.
This model assumes that inter-method bias is the only difference between the two methods.


\begin{equation}
y_{mi}  = \alpha_{m} + \mu_{i} + e_{mi} \qquad  e_{mi} \sim \mathcal{N}(0,\sigma^{2}_{m})
\end{equation}

The differences are expressed as $d_{i} = y_{1i} - y_{2i}$.

For the replicate case, an interaction term $c$ is added to the model, with an associated variance component.




\subsection{Note 3: Model terms}
It is important to note the following characteristics of this model.
\begin{itemize}
	\item Let the number of replicate measurements on each item $i$ for both methods be $n_i$, hence $2 \times n_i$ responses. However, it is assumed that there may be a different number of replicates made for different items. Let the maximum number of replicates be $p$. An item will have up to $2p$ measurements, i.e. $\max(n_{i}) = 2p$.
	
	% \item $\boldsymbol{y}_i$ is the $2n_i \times 1$ response vector for measurements on the $i-$th item.
	% \item $\boldsymbol{X}_i$ is the $2n_i \times  3$ model matrix for the fixed effects for observations on item $i$.
	% \item $\boldsymbol{\beta}$ is the $3 \times  1$ vector of fixed-effect coefficients, one for the true value for item $i$, and one effect each for both methods.
	
	\item Later on $\boldsymbol{X}_i$ will be reduced to a $2 \times 1$ matrix, to allow estimation of terms. This is due to a shortage of rank. The fixed effects vector can be modified accordingly.
	\item $\boldsymbol{Z}_i$ is the $2n_i \times  2$ model matrix for the random effects for measurement methods on item $i$.
	\item $\boldsymbol{b}_i$ is the $2 \times  1$ vector of random-effect coefficients on item $i$, one for each method.
	\item $\boldsymbol{\epsilon}$  is the $2n_i \times  1$ vector of residuals for measurements on item $i$.
	\item $\boldsymbol{G}$ is the $2 \times  2$ covariance matrix for the random effects.
	\item $\boldsymbol{R}_i$ is the $2n_i \times  2n_i$ covariance matrix for the residuals on item $i$.
	\item The expected value is given as $\mbox{E}(\boldsymbol{y}_i) = \boldsymbol{X}_i\boldsymbol{\beta}.$ \citep{hamlett}
	\item The variance of the response vector is given by $\mbox{Var}(\boldsymbol{y}_i)  = \boldsymbol{Z}_i \boldsymbol{G} \boldsymbol{Z}_i^{\prime} + \boldsymbol{R}_i$ \citep{hamlett}.
\end{itemize}
\newpage

%\chapter{Limits of Agreement}

%\section{Modelling Agreement with LME Models}

% Carstensen pages 22-23


Roys uses and LME model approach to provide a set of formal tests for method comparison studies.\\

Four candidates models are fitted to the data.\\

These models are similar to one another, but for the imposition of equality constraints.\\

These tests are the pairwise comparison of candidate models, one formulated without constraints, the other with a constraint.\\


Roy's model uses fixed effects $\beta_0 + \beta_1$ and $\beta_0 + \beta_1$ to specify the mean of all observationsby \\ methods 1 and 2 respectuively.





Roy adheres to Random Effect ideas in ANOVA

Roy treats items as a sample from a population.\\

Allocation of fixed effects and random effects are very different in each model\\

Carstensen's interest lies in the difference between the population from which they were drawn.\\

Carstensen's model is a mixed effects ANOVA.\\

\[
Y_{mir}  =  \alpha_m + \mu_i + c_{mi} + e_{mir}, \qquad c_{mi} \sim \mathcal{\tau^2_m}, \qquad e_{mir} \sim \mathcal{\sigma^2_m},
\]

This model includes a method by item iteration term.\\

Carstensen presents two models. One for the case where the replicates, and a second for when they are linked.\\

Carstensen's model does not take into account either between-item or within-item covariance between methods.\\


In the presented example, it is shown that Roy's LoAs are lower than those of Carstensen.
Carstensen makes some interesting remarks in this regard.

\begin{quote}
	The only slightly non-standard (meaning "not often used") feature is the differing residual variances between methods.
\end{quote}
\newpage


\subsection{Note 3: Model terms}
It is important to note the following characteristics of this model.
\begin{itemize}
	\item Let the number of replicate measurements on each item $i$ for both methods be $n_i$, hence $2 \times n_i$ responses. However, it is assumed that there may be a different number of replicates made for different items. Let the maximum number of replicates be $p$. An item will have up to $2p$ measurements, i.e. $\max(n_{i}) = 2p$.
	
	% \item $\boldsymbol{y}_i$ is the $2n_i \times 1$ response vector for measurements on the $i-$th item.
	% \item $\boldsymbol{X}_i$ is the $2n_i \times  3$ model matrix for the fixed effects for observations on item $i$.
	% \item $\boldsymbol{\beta}$ is the $3 \times  1$ vector of fixed-effect coefficients, one for the true value for item $i$, and one effect each for both methods.
	
	\item Later on $\boldsymbol{X}_i$ will be reduced to a $2 \times 1$ matrix, to allow estimation of terms. This is due to a shortage of rank. The fixed effects vector can be modified accordingly.
	\item $\boldsymbol{Z}_i$ is the $2n_i \times  2$ model matrix for the random effects for measurement methods on item $i$.
	\item $\boldsymbol{b}_i$ is the $2 \times  1$ vector of random-effect coefficients on item $i$, one for each method.
	\item $\boldsymbol{\epsilon}$  is the $2n_i \times  1$ vector of residuals for measurements on item $i$.
	\item $\boldsymbol{G}$ is the $2 \times  2$ covariance matrix for the random effects.
	\item $\boldsymbol{R}_i$ is the $2n_i \times  2n_i$ covariance matrix for the residuals on item $i$.
	\item The expected value is given as $\mbox{E}(\boldsymbol{y}_i) = \boldsymbol{X}_i\boldsymbol{\beta}.$ \citep{hamlett}
	\item The variance of the response vector is given by $\mbox{Var}(\boldsymbol{y}_i)  = \boldsymbol{Z}_i \boldsymbol{G} \boldsymbol{Z}_i^{\prime} + \boldsymbol{R}_i$ \citep{hamlett}.
\end{itemize}
\newpage
\newpage
\section{Regression Of Differences On Averages}
Further to Carstensen, we can formulate the two measurements
$y_{1}$ and $y_{2}$ as follows:
\\
$y_{1} = \alpha + \beta\mu + \epsilon_{1}$
\\
$y_{2} = \alpha + \beta\mu + \epsilon_{2}$








%---------------------------------------------------------------------------%
%\newpage
%\section{Residual diagnostics} %1.3
For classical linear models, residual diagnostics are typically conducted using a plot of the observed residuals and the predicted values. A visual inspection for the presence of trends inform the analyst on the validity of distributional assumptions, and to detect outliers and influential observations.

%\section{Case Deletion Diagnostics}
%
%
%Linear models for uncorrelated data have well established measures to gauge the influence of one or more
%observations on the analysis. For such models, closed-form update expressions allow efficient computations
%without refitting the model. 
%
%
%Since the pioneering work of Cook in 1977, deletion measures have been applied to many statistical models for identifying influential observations. Case-deletion diagnostics provide a useful tool for identifying influential observations and outliers.
%
%The key to making deletion diagnostics useable is the development of efficient computational formulas, allowing one to obtain the \index{case deletion diagnostics} case deletion diagnostics by making use of basic building blocks, computed only once for the full model.
%
%The computation of case deletion diagnostics in the classical model is made simple by the fact that estimates of $\beta$ and $\sigma^2$, which exclude the $i-$th observation, can be computed without re-fitting the model. %\subsection{Terminology for Case Deletion diagnostics} %1.8
%
%\citet{preisser} describes two type of diagnostics. When the set consists of only one observation, the type is called
%`\textit{observation-diagnostics}'. For multiple observations, Preisser describes the diagnostics as `\textit{cluster-deletion}' diagnostics. When applied to LME models, such update formulas are available only if one assumes that the covariance parameters are not affected by the removal of the observation in question. However, this is rarely a reasonable assumption.
%
\subsection*{Appendix to Section 4}




As an appendix to section 4, an appraisal of the current state of development (or lack thereof) for current implemenations for LME models, particularly for
\texttt{nlme} and \texttt{lme4} fitted models.

Crucially, a review of internet resources indicates that almost all of the progress in this regard has been done for \texttt{lme4} fitted models, specifically the \textit{Influence.ME} \texttt{R} package. (Nieuwenhuis et 2012)

Conversely there is very little for \texttt{nlme} models. To delve into this mor, one would immediately investigate the current development workflow for both packages.

As an aside, Douglas Bates was arguably the most prominent \texttt{R} developer working in the LME area. 
However Bates has now prioritised the development of LME models in another computing environment , i.e Julia. 


\subsubsection*{Important Consideration for MCS}

The key issue is that \texttt{nlme} allows for the particular specification of Roy's Model, speciifically direct spefiication of the VC matrices for within subject and between subject residuals.
The \texttt{lme4} package does not allow for this.
To advance the ideas that eminate from Roys' paper, one is required to use the \texttt{nlme} context. However, to take advantage of the infrastructure already provided for \texttt{lme4} models, one may change the research question away from that of Roy's paper. 
To this end, an exploration of what textit{influence.ME} can accomplished is merited.
As a complement to this, one can also consider how to properly employ the $R^2$ measure, in the context of Methoc Comparison Studies, further to the work by Edwards et al, namely ``An $R^2$ statistic for fixed effects in the linear mixed model".
%================================================= %

\begin{framed}
	
	\begin{quote}
		\textbf{Abstract for ``An $R^2$ statistic for fixed effects in the linear mixed model"}
		Statisticians most often use the linear mixed model to analyze Gaussian longitudinal data. 
		
		The value and familiarity of the R2 statistic in the linear univariate model naturally creates great interest in extending it to the linear mixed model. We define and describe how to compute a model R2 statistic for the linear mixed model by using only a single model. 
		
		The proposed R2 statistic measures multivariate association between the repeated outcomes and the fixed effects in the linear mixed model. The R2 statistic arises as a 1–1 function of an appropriate F statistic for testing all fixed effects (except typically the intercept) in a full model. 
		
		The statistic compares the full model with a null model with all fixed effects deleted (except typically the intercept) while retaining exactly the same covariance structure. 
		
		Furthermore, the R2 statistic leads immediately to a natural definition of a partial R2 statistic. A mixed model in which ethnicity gives a very small p-value as a longitudinal predictor of blood pressure (BP) compellingly illustrates the value of the statistic. 
		
		In sharp contrast to the extreme p-value, a very small $R^2$ , a measure of statistical and scientific importance, indicates that ethnicity has an almost negligible association with the repeated BP outcomes for the study.
	\end{quote}
\end{framed}

%======================%
% nlme
\subsubsection*{The \texttt{nlme} package}

With regards to \texttt{nlme}, the torch has been passed to Galecki Galecki \& Burzykowski (UMich. and Hasselt respecitely).  Galecki \& Burzykowski published \textit{Linear Mixed Effects Models using \texttt{R}}. 
Also, the accompanying \texttt{R} package, nlmeU package is under current development, with a version being released XXXX.





%======================%
% lme4 and influence.ME
\subsubsection*{The \texttt{lme4} package}

The \texttt{lme4} package is also under active development, under the leadership of Ben Bolker (McMaster University). According to CRAN, the LME4 package, fits linear and generalized linear mixed-effects models

\begin{quote}
	The models and their components are represented using S4 classes and methods. The core computational algorithms are implemented using the Eigen C++ library for numerical linear algebra and RcppEigen "glue".
	(CRAN)
\end{quote}


%=====================%
% Important Consideration for MCS

The key issue is that \texttt{nlme} allows for the particular specification of Roy's Model, speciifically direct spefiication of the VC matrices for within subject and between subject residuals.
The \texttt{lme4} package does not allow for this.
To advance the ideas that eminate from Roys' paper, one is required to use the \texttt{nlme} context. However, to take advantage of the infrastructure already provided for \texttt{lme4} models, one may change the research question away from that of Roy's paper. 
To this end, an exploration of what textit{influence.ME} can accomplished is merited.
As a complement to this, one can also consider how to properly employ the $R^2$ measure, in the context of Methoc Comparison Studies, further to the work by Edwards et al, namely ``An $R^2$ statistic for fixed effects in the linear mixed model".
%================================================= %
\newpage
\begin{framed}
	
	\begin{quote}
		\textbf{Abstract for ``An $R^2$ statistic for fixed effects in the linear mixed model"}
		Statisticians most often use the linear mixed model to analyze Gaussian longitudinal data. 
		
		The value and familiarity of the R2 statistic in the linear univariate model naturally creates great interest in extending it to the linear mixed model. We define and describe how to compute a model R2 statistic for the linear mixed model by using only a single model. 
		
		The proposed R2 statistic measures multivariate association between the repeated outcomes and the fixed effects in the linear mixed model. The R2 statistic arises as a 1–1 function of an appropriate F statistic for testing all fixed effects (except typically the intercept) in a full model. 
		
		The statistic compares the full model with a null model with all fixed effects deleted (except typically the intercept) while retaining exactly the same covariance structure. 
		
		Furthermore, the R2 statistic leads immediately to a natural definition of a partial R2 statistic. A mixed model in which ethnicity gives a very small p-value as a longitudinal predictor of blood pressure (BP) compellingly illustrates the value of the statistic. 
		
		In sharp contrast to the extreme p-value, a very small $R^2$ , a measure of statistical and scientific importance, indicates that ethnicity has an almost negligible association with the repeated BP outcomes for the study.
	\end{quote}
\end{framed}



\begin{equation}
r_{mi}=x^{T}_{i}\hat{\beta}
\end{equation}

\subsection{Marginal Residuals}
\begin{eqnarray}
\hat{\beta} &=& (X^{T}R^{-1}X)^{-1}X^{T}R^{-1}Y \nonumber \\
&=& BY \nonumber
\end{eqnarray}


\section{Covariance Parameters} %1.5
The unknown variance elements are referred to as the covariance parameters and collected in the vector $\theta$.
% - where is this coming from?
% - where is it used again?
% - Has this got anything to do with CovTrace etc?


\subsection{Methods and Measures}
The key to making deletion diagnostics useable is the development of efficient computational formulas, allowing one to obtain the \index{case deletion diagnostics} case deletion diagnostics by making use of basic building blocks, computed only once for the full model.

\citet{Zewotir} lists several established methods of analyzing influence in LME models. These methods include \begin{itemize}
	\item Cook's distance for LME models,
	\item \index{likelihood distance} likelihood distance,
	\item the variance (information) ration,
	\item the \index{Cook-Weisberg statistic} Cook-Weisberg statistic,
	\item the \index{Andrews-Prebigon statistic} Andrews-Prebigon statistic.
\end{itemize}


\section{Missing Data in Method Comparison Studies}

The matter of missing data has not been commonly encountered in either Method Comparison Studies or Linear Mixed Effects Modelling. However Roy (2009) deals with the relevant assumptions regrading missing data.

Galecki \& Burzykowski (2013) tackles the subject of missing data in LME Modelling.

Furthermore the nlmeU package includes the \texttt{patMiss} function, which ``allows to compactly present pattern of missing data in a given vector/matrix/data
frame or combination of thereof".


\section{Leave-One-Out Diagnostics with \texttt{lmeU}}
Galecki et al discuss the matter of LME influence diagnostics in their book, although not into great detail.


The command \texttt{lmeU} fits a model with a particular subject removed. The identifier of the subject to be removed is passed as the only argument

A plot ofthe per-observation diagnostics individual subject log-likelihood contributions can be rendered.


\begin{framed} 
	\begin{itemize}
		\item \texttt{R} command and \texttt{R} object - Typewriter Font
		\item \texttt{R} Package name - Italics
		\item Selected Acronyms and Proper Nouns - Italics
	\end{itemize}
\end{framed}
\medskip

\begin{itemize}	
	\item This chapter is broken into two parts. The first part is a review of diagnostics methods for linear models, intended to acquaint the
	reader with the subject, and also to provide a basis for material covered in the second part. Particular attention is drawn to graphical methods.
	
	\item The second part of the chapter looks at diagnostics techniques for LME models, firsly covering the theory, then proceeding to a discussion on 
	implementing these using \texttt{R} code.
	\item While a substantial body of work has been developed in this area, ther are still area worth exploring. 
	In particular the development of graphical techniques pertinent to LME models should be looked at.
\end{itemize}



\section{Introduction}


\chapter{Model Diagnostics}

%---------------------------------------------------------%
\newpage
\section{Lesaffre's paper.} %5.6

Lesaffre considers the case-weight perturbation approach.


%\citep{cook86}
Cook's 86 describes a local approach wherein each case is given a weight $w_{i}$ and the effect on the parameter estimation is measured by perturbing these weights. Choosing weights close to zero or one corresponds to the global case-deletion approach.

Lesaffre  describes the displacement in log-likelihood as a useful metric to evaluate local influence %\citep{cook86}.


%\citet{lesaffre}
Lesaffre describes a framework to detect outlying observations that matter in an LME model. Detection should be carried out by evaluating diagnostics $C_{i}$ , $C_{i}(\alpha)$ and $C_{i}(D,\sigma^2)$.


Lesaffre defines the total local influence of individual $i$ as
\begin{equation}
C_{i} = 2 | \triangle \prime _{i} L^{-1} \triangle_{i}|.
\end{equation}


The influence function of the MLEs evaluated at the $i$th point $IF_{i}$, given by
\begin{equation}
IF_{i} = -L^{-1}\triangle _{i}
\end{equation}
can indicate how $\hat{theta}$ changes as the weight of the $i$th
subject changes.

The manner by which influential observations distort the estimation process can be determined by inspecting the
interpretable components in the decomposition of the above measures of local influence.


Lesaffre comments that there is no clear way of interpreting the information contained in the angles, but that this doesn't mean the information should be ignored.

\newpage





\section{Carstensen}
Let $y_{mir} $ be the $r$th replicate measurement on the $i$th item by the $m$th method, where $m=1,2,$ $i=1,\ldots,N,$ and $r = 1,\ldots,n_i.$ When the design is balanced and there is no ambiguity we can set $n_i=n.$ The LME model underpinning Roy's approach can be written
\begin{equation}
y_{mir} = \beta_{0} + \beta_{m} + b_{mi} + \epsilon_{mir}.
\end{equation}
Here $\beta_0$ and $\beta_m$ are fixed-effect terms representing, respectively, a model intercept and an overall effect for method $m.$
The $\beta$ terms can be gathered together into (fixed effect) intercept terms $\alpha_m=\beta_0+\beta_m.$ The $b_{1i}$ and $b_{2i}$ terms are correlated random effect parameters having $\mathrm{E}(b_{mi})=0$ with $\mathrm{Var}(b_{mi})=g^2_m$ and $\mathrm{Cov}(b_{mi}, b_{m^\prime i})=g_{12}.$ The random error term for each response is denoted $\epsilon_{mir}$ having $\mathrm{E}(\epsilon_{mir})=0$, $\mathrm{Var}(\epsilon_{mir})=\sigma^2_m$, $\mathrm{Cov}(b_{mir}, b_{m^\prime ir})=\sigma_{12}$, $\mathrm{Cov}(\epsilon_{mir}, \epsilon_{mir^\prime})= 0$ and $\mathrm{Cov}(\epsilon_{mir}, \epsilon_{m^\prime ir^\prime})= 0.$ Two methods of measurement are in complete agreement if the null hypotheses $\mathrm{H}_1\colon \beta_1 = \beta_2$ and $\mathrm{H}_2\colon \sigma^2_1 = \sigma^2_2 $ and $\mathrm{H}_3\colon g^2_1= g^2_2$ hold simultaneously. \citet{roy} proposes a Bonferroni correction to control the familywise error rate for tests of $\{\mathrm{H}_1, \mathrm{H}_2, \mathrm{H}_3\}$ and account for difficulties arising due to multiple testing. Let $\omega^2_m = \sigma^2_m + g^2_m$ represent the overall variability of method $m.$  Roy also integrates $\mathrm{H}_2$ and $\mathrm{H}_3$ into a single testable hypothesis $\mathrm{H}_4\colon \omega^2_1=\omega^2_2.$ CONCERNS?

\bigskip

% Complete paragraph by specifying variances and covariances for epsilons.
% I thing that these are your sigmas?
% Also, state equality of the parameters in this model when each of the three hypotheses above are true.
\citet{Roy} demonstrates how to implement a method comparison study further to model (1) using the SAS proc mixed package.
%------------------------------------------------------------------------------------------------%
\citet{BXC2008} demonstrates how to construct limits of agreement using SAS, STATA and R. In the case of SAS, the PROC MIXED procedure is used.
Implementation in R is performed using the nlme package \citep{pb2000}.

\citet{BXC2008} remarks that the implementation using R is quite ``arcane".

As R is freely available, this paper demonstrates an implementation of Roy's model using R.

The R statistical software package is freely available.

%------------------------------------------------------------------------------------------------%
The LME model is very easy to implement using PROC MIXED of SAS and the results are also easy to interpret.
The SAS proc mixed procedure has very simple syntax.

As the required code to fit the models is complex, R code necessary to fit the models is provided. 

A demonstration is provided on how to use the output to perform the tests, and to compute limits of agreement.



We assume the data are formatted as a dataset with four columns named:

meth, method of measurement, the number of methods being M,
item, items (persons, samples) measured by each method, of which there are I,
repl, replicate indicating repeated measurement of the same item by the same method, and
y, the measurement.







%=======================================================================================%

\subsection{Remarks on the Multivariate Normal Distribution}

Diligence is required when considering the models. Carstensen specifies his models in terms of the univariate normal distribution. Roy's model is specified using the bivariate normal distribution.
This gives rises to a key difference between the two model, in that a bivariate model accounts for covariance between the variables of interest.
The multivariate normal distribution of a $k$-dimensional random vector $X = [X_1, X_2, \ldots, X_k]$
can be written in the following notation:
\[
X\ \sim\ \mathcal{N}(\mu,\, \Sigma),
\]
or to make it explicitly known that $X$ is $k$-dimensional,
\[
X\ \sim\ \mathcal{N}_k(\mu,\, \Sigma).
\]
with $k$-dimensional mean vector
\[ \mu = [ \operatorname{E}[X_1], \operatorname{E}[X_2], \ldots, \operatorname{E}[X_k]] \]
and $k \times k$ covariance matrix
\[ \Sigma = [\operatorname{Cov}[X_i, X_j]], \; i=1,2,\ldots,k; \; j=1,2,\ldots,k \]

\bigskip

\begin{enumerate}
	\item Univariate Normal Distribution
	
	\[
	X\ \sim\ \mathcal{N}(\mu,\, \sigma^2),
	\]
	
	\item Bivariate Normal Distribution
	
	\begin{itemize}
		\item[(a)] \[  X\ \sim\ \mathcal{N}_2(\mu,\, \Sigma), \vspace{1cm}\]
		\item[(b)] \[    \mu = \begin{pmatrix} \mu_x \\ \mu_y \end{pmatrix}, \quad
		\Sigma = \begin{pmatrix} \sigma_x^2 & \rho \sigma_x \sigma_y \\
		\rho \sigma_x \sigma_y  & \sigma_y^2 \end{pmatrix}.\]
	\end{itemize}
\end{enumerate}


%\chapter{Limits of Agreement}

\section{Modelling Agreement with LME Models}

% Carstensen pages 22-23


Roys uses and LME model approach to provide a set of formal tests for method comparison studies.\\

Four candidates models are fitted to the data.\\

These models are similar to one another, but for the imposition of equality constraints.\\

These tests are the pairwise comparison of candidate models, one formulated without constraints, the other with a constraint.\\


Roy's model uses fixed effects $\beta_0 + \beta_1$ and $\beta_0 + \beta_1$ to specify the mean of all observationsby \\ methods 1 and 2 respectuively.





Roy adheres to Random Effect ideas in ANOVA

Roy treats items as a sample from a population.\\

Allocation of fixed effects and random effects are very different in each model\\

Carstensen's interest lies in the difference between the population from which they were drawn.\\

Carstensen's model is a mixed effects ANOVA.\\

\[
Y_{mir}  =  \alpha_m + \mu_i + c_{mi} + e_{mir}, \qquad c_{mi} \sim \mathcal{\tau^2_m}, \qquad e_{mir} \sim \mathcal{\sigma^2_m},
\]

This model includes a method by item iteration term.\\

Carstensen presents two models. One for the case where the replicates, and a second for when they are linked.\\

Carstensen's model does not take into account either between-item or within-item covariance between methods.\\


In the presented example, it is shown that Roy's LoAs are lower than those of Carstensen.
Carstensen makes some interesting remarks in this regard.

\begin{quote}
	The only slightly non-standard (meaning "not often used") feature is the differing residual variances between methods.
\end{quote}





It is also desirable to measure the influence of the case deletions on the covariance matrix of $\hat{\beta}$.



%===================================================================%

\begin{itemize}
	\item \textit{
		The previous Section (Section 4) is a literary review of residual diagnostics and influence procedures
		for Linear Mixed Effects Models, drawing heavily on Schabenberger and Zewotir.}
	
	\item \textit{	Section 4 begins with an introduction to key topics in residual diagnostics, such as influence, leverage, outliers
		and Cook's distance. Other concepts such as DFFITS and DFBETAs will be introduced briefly, mostly to explain why the are not particularly useful for
		the Method Comparison context, and therefore are not elaborated upon.}
	
	\item \textit{	In brief, Variable Selection is not applicable to Method Comparison Studies, in the 
		commonly used used context. 
		Testing a rather simplisticy specificied model against one with more random effects terms is tractable, but this research question is of secondary importance.}
\end{itemize}



\subsection{Matrix Notation for Case Deletion} %1.14

%\subsection{Case deletion notation} %1.14.1

For notational simplicity, $\boldsymbol{A}(i)$ denotes an $n \times m$ matrix $\boldsymbol{A}$ with the $i$-th row
removed, $a_i$ denotes the $i$-th row of $\boldsymbol{A}$, and $a_{ij}$ denotes the $(i, j)-$th element of $\boldsymbol{A}$.
%
%\subsection{Partitioning Matrices} %1.14.2
%Without loss of generality, matrices can be partitioned as if the $i-$th omitted observation is the first row; i.e. $i=1$.












\section{Extension of Diagnostic Methods to LME models}

When similar notions of statistical influence are applied to mixed models,
things are more complicated. Removing data points affects fixed effects and covariance parameter estimates.
Update formulas for “\textit{leave-one-out}” estimates typically fail to account for changes in covariance
parameters. 
%
%
%In LME models, there are two types of residuals, marginal residuals and conditional residuals. A
%marginal residual is the difference between the observed data and the estimated marginal mean. A conditional residual is the
%difference between the observed data and the predicted value of the observation. In a model without random effects, both sets of residuals coincide \citep{schab}.

\citet{Christiansen} noted the case deletion diagnostics techniques have not been applied to linear mixed effects models and seeks to develop methodologies in that respect. \citet{Christiansen} develops these techniques in the context of REML.

\citet{CPJ} noted the case deletion diagnostics techniques had not been applied to linear mixed effects models and seeks to develop methodologies in that respect. \citet{CPJ} develops these techniques in the context of REML.

%\citet{CPJ} develops \index{case deletion diagnostics} case deletion diagnostics, in particular the equivalent of \index{Cook's distance} Cook's distance, a well-known metric, for diagnosing influential observations when estimating the fixed effect parameters and variance components. Deletion diagnostics provide a means of assessing the influence of an observation (or groups of observations) on inference on the estimated parameters of LME models. We shall provide a fuller discussion of Cook's distance in due course.


\citet{Demi} extends several regression diagnostic techniques commonly used in linear regression, such as leverage, infinitesimal influence, case deletion diagnostics, Cook's distance, and local influence to the linear mixed-effects model. In each case, the proposed new measure has a direct interpretation in terms of the effects on a parameter of interest, and reduces to the familiar linear regression measure when there are no random effects. 

The new measures that are proposed by \citet{Demi} are explicitly defined functions and do not require re-estimation of the model, especially for cluster deletion diagnostics. The basis for both the cluster deletion diagnostics and Cook's distance is a generalization of Miller's simple update formula for case deletion for linear models. Furthermore \citet{Demi} shows how Pregibon's infinitesimal case deletion diagnostics is adapted to the linear mixed-effects model. 
%A simple compact matrix formula is derived to assess the local influence of the fixed-effects regression coefficients. 


%
%
%\section{Case Deletion Diagnostics for LME models} %1.6
%
%Data from single individuals, or a small group of subjects may influence non-linear mixed effects model selection. Diagnostics routinely applied in model building may identify such individuals, but these methods are not specifically designed for that purpose and are, therefore, not optimal. 

\citet{Demi} proposes two likelihood-based diagnostics for identifying individuals that can influence the choice between two competing models.





\subsection{Remarks on the Multivariate Normal Distribution}

Diligence is required when considering the models. Carstensen specifies his models in terms of the univariate normal distribution. Roy's model is specified using the bivariate normal distribution.
This gives rises to a key difference between the two model, in that a bivariate model accounts for covariance between the variables of interest.
The multivariate normal distribution of a $k$-dimensional random vector $X = [X_1, X_2, \ldots, X_k]$
can be written in the following notation:
\[
X\ \sim\ \mathcal{N}(\mu,\, \Sigma),
\]
or to make it explicitly known that $X$ is $k$-dimensional,
\[
X\ \sim\ \mathcal{N}_k(\mu,\, \Sigma).
\]
with $k$-dimensional mean vector
\[ \mu = [ \operatorname{E}[X_1], \operatorname{E}[X_2], \ldots, \operatorname{E}[X_k]] \]
and $k \times k$ covariance matrix
\[ \Sigma = [\operatorname{Cov}[X_i, X_j]], \; i=1,2,\ldots,k; \; j=1,2,\ldots,k \]

\bigskip

\begin{enumerate}
	\item Univariate Normal Distribution
	
	\[
	X\ \sim\ \mathcal{N}(\mu,\, \sigma^2),
	\]
	
	\item Bivariate Normal Distribution
	
	\begin{itemize}
		\item[(a)] \[  X\ \sim\ \mathcal{N}_2(\mu,\, \Sigma), \vspace{1cm}\]
		\item[(b)] \[    \mu = \begin{pmatrix} \mu_x \\ \mu_y \end{pmatrix}, \quad
		\Sigma = \begin{pmatrix} \sigma_x^2 & \rho \sigma_x \sigma_y \\
		\rho \sigma_x \sigma_y  & \sigma_y^2 \end{pmatrix}.\]
	\end{itemize}
\end{enumerate}
\newpage

\section{Repeated measurements in LME models}

In many statistical analyzes, the need to determine parameter estimates where multiple measurements are available on each of a set of variables often arises. Further to \citet{lam}, \citet{hamlett} performs an analysis of the correlation of replicate measurements, for two variables of interest, using LME models.

Let $y_{Aij}$ and $y_{Bij}$ be the $j$th repeated observations of the variables of interest $A$ and $B$ taken on the $i$th subject. The number of repeated measurements for each variable may differ for each individual.
Both variables are measured on each time points. Let $n_{i}$ be the number of observations for each variable, hence $2\times n_{i}$ observations in total.

It is assumed that the pair $y_{Aij}$ and $y_{Bij}$ follow a bivariate normal distribution.
\begin{eqnarray*}
	\left(
	\begin{array}{c}
		y_{Aij} \\
		y_{Bij} \\
	\end{array}
	\right) \sim \mathcal{N}(
	\boldsymbol{\mu}, \boldsymbol{\Sigma})\mbox{   where } \boldsymbol{\mu} = \left(
	\begin{array}{c}
		\mu_{A} \\
		\mu_{B} \\
	\end{array}
	\right)
\end{eqnarray*}

The matrix $\Sigma$ represents the variance component matrix between response variables at a given time point $j$.

\[
\boldsymbol{\Sigma} = \left( \begin{array}{cc}
\sigma^2_{A} & \sigma_{AB} \\
\sigma_{AB} & \sigma^2_{B}\\
\end{array}   \right)
\]

$\sigma^2_{A}$ is the variance of variable $A$, $\sigma^2_{B}$ is the variance of variable $B$ and $\sigma_{AB}$ is the covariance of the two variable. It is assumed that $\boldsymbol{\Sigma}$ does not depend on a particular time point, and is the same over all time points.

%-------------------------------------------------------------------------------------------------------------------------------------%
%-------------------------------------------------------------------------------------------------------------------------------------%


\chapter{Augmented GLMs} 


%---------------------------------------------------------------------------%
% - 3. Augmented GLMS
%---------------------------------------------------------------------------%


Generalized linear models are a generalization of classical linear  models.

	\section{Augmented GLMs} %3.1
	
	With the use of h-likihood, a random effected model of the form can be viewed as an `augmented GLM' with the response varaibkes $(y^t, \phi^t_m)^t$, (with $\mu = E(y)$,$ u = E(\phi)$, $var(y) = \theta V (\mu)$.
	The augmented linear predictor is \[\eta_{ma}  = (\eta^t, \eta^t_m)^t) = T\omega. \].
	
	
	
	%Augmented Generalized linear models.
	% Youngjo et al page 154
	
	The subscript $M$ is a label referring to the mean model.
	\begin{equation}
	\left(%
	\begin{array}{c}
	Y \\
	\psi_{M} \\
	\end{array}%
	\right) = \left(
	\begin{array}{cc}
	X & Z \\
	0 & I \\
	\end{array}\right) \left(%
	\begin{array}{c}
	\beta \\
	\nu \\
	\end{array}%
	\right)+ e^{*}
	\end{equation}
	
	
	%Augmented Generalized linear models.
	
	
	The error term $e^{*}$ is normal with mean zero. The variance matrix of the error term is given by
	\begin{equation}
	\Sigma_{a} = \left(%
	\begin{array}{cc}
	\Sigma & 0 \\
	0 & D \\
	\end{array}%
	\right).
	\end{equation}
	
	$y_{a} = T \delta + e^{*}$
	
	Weighted least squares equation
	
	
	% Youngjo et al page 154
	
	
	\subsection{The Augmented Model Matrix}  %3.2
	\begin{equation}
	X = \left(%
	\begin{array}{cc}
	T & Z \\
	0 & I \\
	\end{array}%
	\right)
	\delta = \left(%
	\begin{array}{c}
	\beta  \\
	\nu  \\
	\end{array}%
	\right)
	\end{equation}
	
	
	


\section{Augmented GLMs} %3.1

With the use of h-likihood, a random effected model of the form can be viewed as an `augmented GLM' with the response varaibkes $(y^t, \phi^t_m)^t$, (with $\mu = E(y)$,$ u = E(\phi)$, $var(y) = \theta V (\mu)$.
The augmented linear predictor is \[\eta_{ma}  = (\eta^t, \eta^t_m)^t) = T\omega. \].



%Augmented Generalized linear models.
% Youngjo et al page 154

The subscript $M$ is a label referring to the mean model.
\begin{equation}
\left(%
\begin{array}{c}
Y \\
\psi_{M} \\
\end{array}%
\right) = \left(
\begin{array}{cc}
X & Z \\
0 & I \\
\end{array}\right) \left(%
\begin{array}{c}
\beta \\
\nu \\
\end{array}%
\right)+ e^{*}
\end{equation}


%Augmented Generalized linear models.


The error term $e^{*}$ is normal with mean zero. The variance matrix of the error term is given by
\begin{equation}
\Sigma_{a} = \left(%
\begin{array}{cc}
\Sigma & 0 \\
0 & D \\
\end{array}%
\right).
\end{equation}

$y_{a} = T \delta + e^{*}$

Weighted least squares equation


% Youngjo et al page 154


\subsection{The Augmented Model Matrix}  %3.2
\begin{equation}
X = \left(%
\begin{array}{cc}
T & Z \\
0 & I \\
\end{array}%
\right)
\delta = \left(%
\begin{array}{c}
\beta  \\
\nu  \\
\end{array}%
\right)
\end{equation}



\subsection{Importance-Weighted Least-Squares (IWLS)}  %3.3


\subsection{H-Likelihood}




%-------------------------------------------------------------------------------------------------------------------------------------%
%-------------------------------------------------------------------------------------------------------------------------------------%
%-------------------------------------------------------------------------------------------------Chapter 4------------------------%
%-------------------------------------------------------------------------------------------------------------------------------------%

	
	Generalized linear models are a generalization of classical linear  models.
	

	\section{Algorithms : ML v REML}
	Maximum likelihood estimation is a method of obtaining estimates of unknown parameters by optimizing a likelihood function. The ML
	parameter estimates are the values of the argument that maximise the likelihood function, i.e. the estimates that make the observed
	values of the dependent variable most likely, given the distributional assumptions
	
	The most common iterative algorithms used for the optimization
	problem in the context of LMEs are the EM algoritm, fisher scoring
	algorithm and NR algorithm, which [cite:West] commends as the
	preferred method.
	
	A mixed model is an extension of the general linear models that
	can specify additional random effects terms.
	
	Parameter of the mixed model can be estimated using either ML or
	REML, while the AIC and the BIC can be used as measures of
	"goodness of fit" for particular models, where smaller values are
	considered preferable.
	
	%--------------------------------------------------------------------%
	
	(\textbf{\emph{Wikipedia}})The restricted (or residual, or reduced) maximum likelihood (REML) approach is a particular form of maximum likelihood estimation which does not base estimates on a maximum likelihood fit of all the information, but instead uses a likelihood function calculated from a transformed set of data, so that nuisance parameters have no effect.
	
	In contrast to the earlier maximum likelihood estimation, REML can produce unbiased estimates of variance and covariance parameters.
	
	%-----------------------------------------------------------------------------------------%
	
	\noindent \textbf{ML procedures for LME}
	
	The maximum likelihood procedure of Hartley and Rao yields
	simultaneous estimates for both the fixed effects and the random
	effect, by maximising the likelihood of $\boldsymbol{y}$ with
	respect to each element of $\boldsymbol{\beta}$ and
	$\boldsymbol{b}$.
	
	%-----------------------------------------------------------------------------------------%
	
	\section{Estimation of random effects}
	
	Estimation of random effects for LME models in the NLME package is accomplished through use
	of both EM (Expectation-Maximization) algorithms and Newton-Raphson algorithms.
	\begin{itemize}
		\item EM iterations bring estimates of the parameters into the region of the optimum very quickly, but
		convergence to the optimum is slow when near the optimum.
		\item Newton-Raphson iterations are computationally intensive and can be unstable when far from the
		optimum. However, close to the optimum they converge quickly.
		\item The LME function implements a hybrid approach, using 25 EM iterations to quickly get near the
		optimum, then switching to Newton-Raphson iterations to quickly converge to the optimum. \item If
		convergence problems occur, the ``control�argument in LME can be used to change the way the
		model arrives at the optimum.
	\end{itemize}
	
	
	
	
	%--Marginal and Conditional Residuals
	
	\section{Covariance Parameters} %1.5
	The unknown variance elements are referred to as the covariance parameters and collected in the vector $\theta$.
	% - where is this coming from?
	% - where is it used again?
	% - Has this got anything to do with CovTrace etc?
	%---------------------------------------------------------------------------%
	
	\subsection{Methods and Measures}
	The key to making deletion diagnostics useable is the development of efficient computational formulas, allowing one to obtain the \index{case deletion diagnostics} case deletion diagnostics by making use of basic building blocks, computed only once for the full model.
	
	\citet{Zewotir} lists several established methods of analyzing influence in LME models. These methods include \begin{itemize}
		\item Cook's distance for LME models,
		\item \index{likelihood distance} likelihood distance,
		\item the variance (information) ration,
		\item the \index{Cook-Weisberg statistic} Cook-Weisberg statistic,
		\item the \index{Andrews-Prebigon statistic} Andrews-Prebigon statistic.
	\end{itemize}
	%--------------------------------------------------------------------------------------------%
	
	
	\section{Haslett's Analysis} %2.5
	For fixed effect linear models with correlated error structure Haslett (1999) showed that the effects on
	the fixed effects estimate of deleting each observation in turn could be cheaply computed from the fixed effects model predicted residuals.
	
	
	%---------------------------------------------------------------------------------------------------------%
	
	
	\section{Computation and Notation } %2.3
	with $\boldsymbol{V}$ unknown, a standard practice for estimating $\boldsymbol{X \beta}$ is the estime the variance components $\sigma^2_j$,
	compute an estimate for $\boldsymbol{V}$ and then compute the projector matrix $A$, $\boldsymbol{X \hat{\beta}}  = \boldsymbol{AY}$.
	
	
	\citet{Zewotir} remarks that $\boldsymbol{D}$ is a block diagonal with the $i-$th block being $u \boldsymbol{I}$
	
	
	

\chapter{Application to Method Comparison Studies} % Chapter 4


%---------------------------------------------------------------------------%
% - 1. Application to MCS
% - 2. Grubbs' Data
% - 3. R implementation
% - 4. Influence measures using R
%---------------------------------------------------------------------------%

\section{Application to MCS} %4.1

Let $\hat{\beta}$ denote the least square estimate of $\beta$
based upon the full set of observations, and let
$\hat{\beta}^{(k)}$ denoted the estimate with the $k^{th}$ case
excluded.


\section{Grubbs' Data} %4.2

For the Grubbs data the $\hat{\beta}$ estimated are
$\hat{\beta}_{0}$ and $\hat{\beta}_{1}$ respectively. Leaving the
fourth case out, i.e. $k=4$ the corresponding estimates are
$\hat{\beta}_{0}^{-4}$ and $\hat{\beta}_{1}^{-4}$


\begin{equation}
Y^{-Q} = \hat{\beta}^{-Q}X^{-Q}
\end{equation}

When considering the regression of case-wise differences and averages, we write $D^{-Q} = \hat{\beta}^{-Q}A^{-Q}$


\newpage

\begin{table}[ht]
	\begin{center}
		\begin{tabular}{rrrrr}
			\hline
			& F & C & D & A \\
			\hline
			1 & 793.80 & 794.60 & -0.80 & 794.20 \\
			2 & 793.10 & 793.90 & -0.80 & 793.50 \\
			3 & 792.40 & 793.20 & -0.80 & 792.80 \\
			4 & 794.00 & 794.00 & 0.00 & 794.00 \\
			5 & 791.40 & 792.20 & -0.80 & 791.80 \\
			6 & 792.40 & 793.10 & -0.70 & 792.75 \\
			7 & 791.70 & 792.40 & -0.70 & 792.05 \\
			8 & 792.30 & 792.80 & -0.50 & 792.55 \\
			9 & 789.60 & 790.20 & -0.60 & 789.90 \\
			10 & 794.40 & 795.00 & -0.60 & 794.70 \\
			11 & 790.90 & 791.60 & -0.70 & 791.25 \\
			12 & 793.50 & 793.80 & -0.30 & 793.65 \\
			\hline
		\end{tabular}
	\end{center}
\end{table}


\newpage

\begin{equation}
Y^{(k)} = \hat{\beta}^{(k)}X^{(k)}
\end{equation}

Consider two sets of measurements , in this case F and C , with the vectors of case-wise averages $A$ and case-wise differences $D$ respectively. A regression model of differences on averages can be fitted with the view to exploring some characteristics of the data.

When considering the regression of case-wise differences and averages, we write

\begin{equation}
D^{-Q} = \hat{\beta}^{-Q}A^{-Q}
\end{equation}
Let $\hat{\beta}$ denote the least square estimate of $\beta$ based upon the full set of observations, and let $\hat{\beta}^{(k)}$ denoted the estimate with the $k^{th}$ case excluded.

For the Grubbs data the $\hat{\beta}$ estimated are $\hat{\beta}_{0}$ and $\hat{\beta}_{1}$ respectively. Leaving the
fourth case out, i.e. $k=4$ the corresponding estimates are $\hat{\beta}_{0}^{-4}$ and $\hat{\beta}_{1}^{-4}$

\begin{equation}
Y^{(k)} = \hat{\beta}^{(k)}X^{(k)}
\end{equation}

Consider two sets of measurements , in this case F and C , with the vectors of case-wise averages $A$ and case-wise differences $D$ respectively. A regression model of differences on averages can be fitted with the view to exploring some characteristics of the data.

\begin{verbatim}
Call: lm(formula = D ~ A)

Coefficients: (Intercept)            A
-37.51896      0.04656

\end{verbatim}




When considering the regression of case-wise differences and averages, we write

\begin{equation}
D^{-Q} = \hat{\beta}^{-Q}A^{-Q}
\end{equation}



\subsection{Influence measures using R} %4.4
\texttt{R} provides the following influence measures of each observation.

%Influence measures: This suite of functions can be used to compute
%some of the regression (leave-one-out deletion) diagnostics for
%linear and generalized linear models discussed in Belsley, Kuh and
% Welsch (1980), Cook and Weisberg (1982)



\begin{table}[ht]
	\begin{center}
		\begin{tabular}{|c|c|c|c|c|c|c|}
			\hline
			& dfb.1\_ & dfb.A & dffit & cov.r & cook.d & hat \\
			\hline
			1 & 0.42 & -0.42 & -0.56 & 1.13 & 0.15 & 0.18 \\
			2 & 0.17 & -0.17 & -0.34 & 1.14 & 0.06 & 0.11 \\
			3 & 0.01 & -0.01 & -0.24 & 1.17 & 0.03 & 0.08 \\
			4 & -1.08 & 1.08 & 1.57 & 0.24 & 0.56 & 0.16 \\
			5 & -0.14 & 0.14 & -0.24 & 1.30 & 0.03 & 0.13 \\
			6 & -0.00 & 0.00 & -0.11 & 1.31 & 0.01 & 0.08 \\
			7 & -0.04 & 0.04 & -0.08 & 1.37 & 0.00 & 0.11 \\
			8 & 0.02 & -0.02 & 0.15 & 1.28 & 0.01 & 0.09 \\
			9 & 0.69 & -0.68 & 0.75 & 2.08 & 0.29 & 0.48 \\
			10 & 0.18 & -0.18 & -0.22 & 1.63 & 0.03 & 0.27 \\
			11 & -0.03 & 0.03 & -0.04 & 1.53 & 0.00 & 0.19 \\
			12 & -0.25 & 0.25 & 0.44 & 1.05 & 0.09 & 0.12 \\
			\hline
		\end{tabular}
	\end{center}
\end{table}


\addcontentsline{toc}{section}{Bibliography}

	%--------------------------------------------------------------------------------------%
	
\bibliographystyle{chicago}
\bibliography{DB-txfrbib}
\end{document}


