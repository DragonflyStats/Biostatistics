\documentclass[12pt, a4paper]{report}
\usepackage{natbib}
\usepackage{vmargin}
\usepackage{graphicx}
\usepackage{epsfig}
\usepackage{subfigure}
%\usepackage{amscd}
\usepackage{amssymb}
\usepackage{framed}
\usepackage{amsbsy}
\usepackage{amsthm, amsmath}
%\usepackage[dvips]{graphicx}
\bibliographystyle{chicago}
\renewcommand{\baselinestretch}{1.8}

% left top textwidth textheight headheight % headsep footheight footskip
\setmargins{3.0cm}{2.5cm}{15.5 cm}{23.5cm}{0.5cm}{0cm}{1cm}{1cm}

\pagenumbering{arabic}


\begin{document}
	\author{Kevin O'Brien}
	\title{SCRATCH}
	\date{\today}
	\maketitle
	
	\tableofcontents \setcounter{tocdepth}{2}
	%==============================================================================%

\chapter{Introduction}
\section{Methods of assessing agreement}

\begin{enumerate}
	\item Pearson's Correlation Coefficient\item Intraclass
	correlation coefficient \item Bland Altman Plot \item Bartko's
	Ellipse (1994) \item Blackwood Bradley Test \item Lin's
	Reproducibility Index \item Luiz Step function
\end{enumerate}

Bland and Altman attend to the issue of repeated measures in
$1996$.

Repeated measurements on several subjects can be used to quantify
measurement error, the variation between measurements of the same
quantity on the same individual.

Bland and Altman discuss two metrics for measurement error; the
within-subject standard deviation ,and the correlation
coefficient.

The above plot incorporates both the conventional limits of
agreement ( the inner pair of dashed lines), the `t' limits of
agreement ( the outer pair of dashed lines) centred around the
inter-method bias (indicated by the full line). This plot is
intended for expository purposes only, as the sample size is
small.





\subsection{Equivalence and Interchangeability}
Limits of agreement are intended to analyse equivalence. How this
is assessed is the considered judgement of the practitioner. In
\citet{BA86} an example of good agreement is cited. For two
methods of measuring `oxygen saturation', the limits of agreement
are calculated as (-2.0,2.8).A practitioner would ostensibly find
this to be sufficiently narrow.

If the limits of agreement are not clinically important, which is
to say that the differences tend not to be substantial, the two
methods may be used interchangeably. \citet{DunnSEME} takes issue
with the notion of `equivalence', remarking that while agreement
indicated equivalence, equivalence does not reflect agreement.




%---------------------------------------------------------------------------%

		\section{Introduction}
		The problem of assessing the agreement between two or more methods
		of measurement is ubiquitous in scientific research, and is
		commonly referred to as a `method comparison study'. Published
		examples of method comparison studies can be found in disciplines
		as diverse as pharmacology \citep{ludbrook97}, anaesthesia
		\citep{Myles}, and cardiac imaging methods \citep{Krumm}.
		\smallskip
		
		To illustrate the characteristics of a typical method comparison
		study consider the data in Table I \citep{Grubbs73}. In each of
		twelve experimental trials, a single round of ammunition was fired
		from a 155mm gun and its velocity was measured simultaneously (and
		independently) by three chronographs devices, identified here by
		the labels `Fotobalk', `Counter' and `Terma'.
		\smallskip
		

		
		\begin{table}[ht]
			\begin{center}
				\begin{tabular}{rrrr}
					\hline
					Round& Fotobalk [F] & Counter [C]& Terma [T]\\
					\hline
					1 & 793.8 & 794.6 & 793.2 \\
					2 & 793.1 & 793.9 & 793.3 \\
					3 & 792.4 & 793.2 & 792.6 \\
					4 & 794.0 & 794.0 & 793.8 \\
					5 & 791.4 & 792.2 & 791.6 \\
					6 & 792.4 & 793.1 & 791.6 \\
					7 & 791.7 & 792.4 & 791.6 \\
					8 & 792.3 & 792.8 & 792.4 \\
					9 & 789.6 & 790.2 & 788.5 \\
					10 & 794.4 & 795.0 & 794.7 \\
					11 & 790.9 & 791.6 & 791.3 \\
					12 & 793.5 & 793.8 & 793.5 \\
					\hline
				\end{tabular}
				\caption{Velocity measurement from the three chronographs (Grubbs
					1973).}
			\end{center}
		\end{table}
		
		An important aspect of the these data is that all three methods of
		measurement are assumed to have an attended measurement error, and
		the velocities reported in Table 1.1 can not be assumed to be
		`true values' in any absolute sense.
		
		%While lack of
		%agreement between two methods is inevitable, the question , as
		%posed by \citet{BA83}, is 'do the two methods of measurement agree
		%sufficiently closely?'
		
		A method of measurement should ideally be both accurate and precise. \citet{Barnhart} describes agreement as being a broader term that contains both of those qualities. An accurate measurement method will give results close to the unknown `true value'. The precision of a method is indicated by how tightly measurements obtained under identical conditions are distributed around their mean measurement value. A precise and accurate method
		will yield results consistently close to the true value. Of course 	a method may be accurate, but not precise, if the average of its measurements is close to the true value, but those measurements
		are highly dispersed. Conversely a method that is not accurate may be quite precise, as it consistently indicates the same level of inaccuracy. The tendency of a method of measurement to consistently give results above or below the true value is a source of systematic bias. The smaller the systematic bias, the
		greater the accuracy of the method.
		
		% The FDA define precision as the closeness of agreement (degree of
		% scatter) between a series of measurements obtained from multiple
		% sampling of the same homogeneous sample under prescribed
		% conditions. \citet{Barnhart} describes precision as being further
		% subdivided as either within-run, intra-batch precision or
		% repeatability (which assesses precision during a single analytical
		% run), or between-run, inter-batch precision or repeatability
		%(which measures precision over time).
		
		In the context of the agreement of two methods, there is also a tendency of one measurement method to consistently give results above or below the other method. Lack of agreement is a consequence of the existence of `inter-method bias'. For two methods to be considered in good agreement, the inter-method bias should be in the region of zero. A simple estimation of the inter-method bias can be calculated using the differences of the
		paired measurements. The data in Table 1.2 are a good example of
		possible inter-method bias; the `Fotobalk' consistently recording
		smaller velocities than the `Counter' method. Consequently one
		would conclude that there is lack of agreement between the two
		methods.
		
		The absence of inter-method bias by itself is not sufficient to
		establish whether two measurement methods agree. The two methods
		must also have equivalent levels of precision. Should one method
		yield results considerably more variable than those of the other,
		they can not be considered to be in agreement. With this in mind a
		methodology is required that allows an analyst to estimate the
		inter-method bias, and to compare the precision of both methods of
		measurement.
		\newpage
		% latex table generated in R 2.6.0 by xtable 1.5-5 package
		% Wed Aug 26 15:22:41 2009
		\begin{table}[h!]
			
			\begin{center}
				
				\begin{tabular}{rrrr}
					\hline
					Round& Fotobalk (F) & Counter (C) & F-C \\
					\hline
					1 & 793.8& 794.6 & -0.8 \\
					2 & 793.1 & 793.9 & -0.8 \\
					3 & 792.4 & 793.2 & -0.8 \\
					4 & 794.0 & 794.0 & 0.0 \\
					5 & 791.4 & 792.2 & -0.8 \\
					6 & 792.4 & 793.1 & -0.7 \\
					7 & 791.7 & 792.4 & -0.7 \\
					8 & 792.3 & 792.8 & -0.5 \\
					9 & 789.6 & 790.2 & -0.6 \\
					10 & 794.4 & 795.0 & -0.6 \\
					11 & 790.9 & 791.6 & -0.7 \\
					12 & 793.5 & 793.8 & -0.3 \\
					\hline
				\end{tabular}
				\caption{Difference between Fotobalk and Counter measurements.}
			\end{center}
		\end{table}
		
		\bigskip
		
		\newpage

	\section{Method Comparison Studies}
	
	Agreement between two methods of clinical measurement can be quantified using the differences between observations made using the two methods on the same subjects. The 95\% limits of agreement, estimated by mean difference +/- 1.96 standard deviation of the differences, provide an interval within which 95\% of differences between measurements by the two methods are expected to lie.
	


\section{Discussion on Method Comparison Studies}

The need to compare the results of two different measurement
techniques is common in medical statistics.

In particular, in medicine, new methods or devices that are
cheaper, easier to use, or less invasive, are routinely developed.
Agreement between a new method and a traditional reference or gold
standard must be evaluated before the new one is put into
practice. Various methodologies have been proposed for this
purpose in recent years.

Indications on how to deal with outliers in Bland Altman plots
\\
We wish to determine how outliers should be treated in a Bland
Altman Plot
\\
In their 1983 paper they merely state that the plot can be used to
'spot outliers'.
\\
In  their 1986 paper, Bland and Altman give an example of an
outlier. They state that it could be omitted in practice, but make
no further comments on the matter.
\\
In Bland and Altmans 1999 paper, we get the clearest indication of
what Bland and Altman suggest on how to react to the presence of
outliers. Their recommendation is to recalculate the limits
without them, in order to test the difference with the calculation
where outliers are retained.\\

The span has reduced from 77 to 59 mmHg, a noticeable but not
particularly large reduction.
\\
However, they do not recommend removing outliers. Furthermore,
they say:
\\
We usually find that this method of analysis is not too sensitive
to one or two large outlying differences.
\\
We ask if this would be so in all cases. Given that the limits of
agreement may or may not be disregarded, depending on their
perceived suitability, we examine whether it would possible that
the deletion of an outlier may lead to a calculation of limits of
agreement that are usable in all cases?
\\
Should an Outlying Observation be omitted from a data set? In
general, this is not considered prudent.
\\
Also, it may be required that the outliers are worthy of
particular attention themselves.
\\
Classifying outliers and recalculating We opted to examine this
matter in more detail. The following points have to be considered
\\how to suitably identify an outlier (in a generalized sense)
\\Would a recalculation of the limits of agreement generally
results in  a compacted range between the upper and lower limits
of agreement?
\subsection{Agreement} Bland and Altman (1986) define Perfect
agreement as 'The case where all of the pairs of rater data lie
along the line of equality'. The Line of Equality is defined as
the 45 degree line passing through the origin, or X=Y on a XY
plane.

\subsection{Lack Of Agreement}
\begin{enumerate}
	\item Constant Bias\item Proportional Bias
\end{enumerate}

\subsubsection*{Constant Bias} This is a form of systematic
deviations estimated as the average difference between the test
and the reference method


\subsubsection*{Proportional Bias} Two methods may agree on
average, but they may exhibit differences over a range of
	\section{Methods of assessing agreement}
	
	\begin{enumerate}
		\item Pearson's Correlation Coefficient\item Intraclass
		correlation coefficient \item Bland Altman Plot \item Bartko's
		Ellipse (1994) \item Blackwood Bradley Test \item Lin's
		Reproducibility Index \item Luiz Step function
	\end{enumerate}
	
	Bland and Altman attend to the issue of repeated measures in
	$1996$.
	\\
	Repeated measurements on several subjects can be used to quantify
	measurement error, the variation between measurements of the same
	quantity on the same individual.
	\\
	Bland and Altman discuss two metrics for measurement error; the
	within-subject standard deviation ,and the correlation
	coefficient.
	
	The above plot incorporates both the conventional limits of
	agreement ( the inner pair of dashed lines), the `t' limits of
	agreement ( the outer pair of dashed lines) centred around the
	inter-method bias (indicated by the full line). This plot is
	intended for expository purposes only, as the sample size is
	small.
	
	
	
	
	
	\subsection{Equivalence and Interchangeability}
	Limits of agreement are intended to analyse equivalence. How this
	is assessed is the considered judgement of the practitioner. In
	\citet{BA86} an example of good agreement is cited. For two
	methods of measuring `oxygen saturation', the limits of agreement
	are calculated as (-2.0,2.8).A practitioner would ostensibly find
	this to be sufficiently narrow.
	
	If the limits of agreement are not clinically important, which is
	to say that the differences tend not to be substantial, the two
	methods may be used interchangeably. \citet{DunnSEME} takes issue
	with the notion of `equivalence', remarking that while agreement
	indicated equivalence, equivalence does not reflect agreement.
	
	
	
	
	\section{Introductory Definitions}
	
	
	
	
	
	To illustrate the characteristics of a typical method comparison study consider the data in Table I, taken from \citet{Grubbs73}.
	\smallskip
	In each of twelve experimental trials a single round of ammunition was fired from a 155mm gun, and its velocity was measured
	simultaneously (and independently) by three chronographs devices, referred to here as `Fotobalk', `Counter' and `Terma'.
	\smallskip
	
	
	\newpage
	
	\begin{table}[ht]
		\begin{center}
			\begin{tabular}{rrrr}
				\hline
				Round& Fotobalk [F] & Counter [C]& Terma [T]\\
				\hline
				1 & 793.8 & 794.6 & 793.2 \\
				2 & 793.1 & 793.9 & 793.3 \\
				3 & 792.4 & 793.2 & 792.6 \\
				4 & 794.0 & 794.0 & 793.8 \\
				5 & 791.4 & 792.2 & 791.6 \\
				6 & 792.4 & 793.1 & 791.6 \\
				7 & 791.7 & 792.4 & 791.6 \\
				8 & 792.3 & 792.8 & 792.4 \\
				9 & 789.6 & 790.2 & 788.5 \\
				10 & 794.4 & 795.0 & 794.7 \\
				11 & 790.9 & 791.6 & 791.3 \\
				12 & 793.5 & 793.8 & 793.5 \\
				\hline
			\end{tabular}
			\caption{Measurement of the three chronographs (Grubbs 1973)}
		\end{center}
	\end{table}
	
	An important aspect of the these data is that all three methods of
	measurement are assumed to have an attended measurement error, and
	the velocities reported in Table I can not be assumed to be `true
	values' in any absolute sense. For expository purposes only the
	first two methods `Fotobalk' and `Counter' will enter in the
	immediate discussion.
	
	While lack of agreement between two methods is inevitable, the question , as
	posed by \citet{BA83}, is 'do the two methods of measurement agree
	sufficiently closely?'
	
	A method of measurement should ideally be both accurate and
	precise.An accurate measurement methods shall give a result close
	to the `true value'. Precision of a method is indicated by how
	tightly clustered its measurements are around their mean
	measurement value.
	
	
	
	A precise and accurate method should yield results consistently
	close to the true value. However a method may be accurate, but not
	precise. The average of its measurements is close to the true
	value, but those measurements are highly dispersed. Conversely an
	inaccurate method may be quite precise , as it consistently
	indicates the same level of inaccuracy.
	
	The tendency of a method of measurement to consistently give
	results above or below the true value is a source of systematic
	bias. The lesser the systematic bias, the greater the accuracy of
	the method.
	
	In the context of the agreement of two methods, there is also a
	tendency of one measurement method to consistently give results
	above or below the other method. Lack of agreement is a
	consequence of the existence of `inter-method bias'. For two
	methods to be considered in good agreement, the inter-method bias
	should be in the region of zero.
	
	A simple estimation of the inter-method bias can be calculated
	using the differences of the paired measurements. The data in
	Table 1.2 are a good example of possible inter-method bias; the
	`Fotobalk' consistently recording smaller velocities than the
	`Counter' method. Consequently there is lack of agreement between
	the two methods.
	\newpage
	% latex table generated in R 2.6.0 by xtable 1.5-5 package
	% Wed Aug 26 15:22:41 2009
	\begin{table}[h!]
		\begin{center}
			
			\begin{tabular}{rrrr}
				\hline
				Round& Fotobalk (F) & Counter (C) & F-C \\
				\hline
				1 & 793.80 & 794.60 & -0.80 \\
				2 & 793.10 & 793.90 & -0.80 \\
				3 & 792.40 & 793.20 & -0.80 \\
				4 & 794.00 & 794.00 & 0.00 \\
				5 & 791.40 & 792.20 & -0.80 \\
				6 & 792.40 & 793.10 & -0.70 \\
				7 & 791.70 & 792.40 & -0.70 \\
				8 & 792.30 & 792.80 & -0.50 \\
				9 & 789.60 & 790.20 & -0.60 \\
				10 & 794.40 & 795.00 & -0.60 \\
				11 & 790.90 & 791.60 & -0.70 \\
				12 & 793.50 & 793.80 & -0.30 \\
				\hline
			\end{tabular}
			\caption{Difference between Fotobalk and Counter measurements}
		\end{center}
	\end{table}
	
	\bigskip
	
	\noindent The absence of inter-method bias by itself is not
	sufficient to establish whether two measurement methods agree or
	not. These methods must also have equivalent levels of precision.
	Should one method yield results considerably more variable than
	that of the other, they can not be considered to be in agreement.
	
	Therefore a methodology must be introduced that allows an analyst
	to estimate the inter-method bias, and to compare the precision of
	both methods of measurement.
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	
	
	\subsection{Agreement Criteria}	
	Roy's method considers two methods to be in agreement if three: no significant bias, i.e. the difference between the two mean readings is not "statistically significant", high overall correlation coefficient, the agreement between the two methods by testing their
	repeatability coefficients. Two methods of measurement can be said to be in agreement if there is no significant difference between in three key respects. 
	
	Roy additionally uses the overall correlation coefficient to provide extra information about the comparison, with a minimum of 0.82 being required. Firstly, there is no inter-method bias between the two methods, i.e. there is no persistent tendency for one method to give higher values than the other. Secondly, both methods of measurement have the same  within-subject variability. In such a case the variance of the replicate measurements would consistent for both methods. Lastly, the methods have equal between-subject variability.  Put simply, for the mean measurements for each case, the variances of the mean measurements from both methods are equal. Lack of agreement can arise if there is a disagreement in overall variabilities. This may be due to due to the disagreement in either between-item variabilities or within-item variabilities, or both. \citet{ARoy2009} allows for a formal test of each.
	

\begin{table}[ht]
	\begin{center}
		\begin{tabular}{|r|r|r|r|}
			\hline
			Round& Fotobalk [F] & Counter [C]& Terma [T]\\
			\hline
			1 & 793.8 & 794.6 & 793.2 \\
			2 & 793.1 & 793.9 & 793.3 \\
			3 & 792.4 & 793.2 & 792.6 \\
			4 & 794.0 & 794.0 & 793.8 \\
			5 & 791.4 & 792.2 & 791.6 \\
			6 & 792.4 & 793.1 & 791.6 \\
			7 & 791.7 & 792.4 & 791.6 \\
			8 & 792.3 & 792.8 & 792.4 \\
			9 & 789.6 & 790.2 & 788.5 \\
			10 & 794.4 & 795.0 & 794.7 \\
			11 & 790.9 & 791.6 & 791.3 \\
			12 & 793.5 & 793.8 & 793.5 \\
			\hline
		\end{tabular}
		\caption{Velocity measurement from the three chronographs (Grubbs
			1973).}
	\end{center}
\end{table}

An important aspect of the these data is that all three methods of
measurement are assumed to have an attended measurement error, and
the velocities reported in Table 1.1 can not be assumed to be
`true values' in any absolute sense.

%While lack of
%agreement between two methods is inevitable, the question , as
%posed by \citet{BA83}, is 'do the two methods of measurement agree
%sufficiently closely?'

A method of measurement should ideally be both accurate and
precise. \citet{Barnhart} describes agreement as being a broader
term that contains both of those qualities. An accurate
measurement method will give results close to the unknown `true
value'. The precision of a method is indicated by how tightly
measurements obtained under identical conditions are distributed
around their mean measurement value. A precise and accurate method
will yield results consistently close to the true value. Of course
a method may be accurate, but not precise. If the average of its
measurements is close to the true value, but those measurements
are highly dispersed. Conversely a method that is not accurate may
be quite precise, as it consistently indicates the same level of
inaccuracy. The tendency of a method of measurement to
consistently give results above or below the true value is a
source of systematic bias. The smaller the systematic bias, the
greater the accuracy of the method.


The FDA define precision as the closeness of agreement (degree of
scatter) between a series of measurements obtained from multiple
sampling of the same homogeneous sample under prescribed
conditions. \citet{Barnhart} describes precision as being further
subdivided as either within-run, intra-batch precision or
repeatability (which assesses precision during a single analytical
run), or between-run, inter-batch precision or repeatability
(which measures precision over time)

In the context of the agreement of two methods, there is also a
tendency of one measurement method to consistently give results
above or below the other method. Lack of agreement is a
consequence of the existence of `inter-method bias'. For two
methods to be considered in good agreement, the inter-method bias
should be in the region of zero. A simple estimation of the
inter-method bias can be calculated using the differences of the
paired measurements. The data in Table 1.2 are a good example of
possible inter-method bias; the `Fotobalk' consistently recording
smaller velocities than the `Counter' method. Consequently one
would conclude that there is lack of agreement between the two
methods.

The absence of inter-method bias by itself is not sufficient to
establish whether two measurement methods agree. The two
methods must also have equivalent levels of precision. Should one
method yield results considerably more variable than that of the
other, they can not be considered to be in agreement. With this in
mind a methodology is required that allows an analyst to estimate
the inter-method bias, and to compare the precision of both
methods of measurement.
\newpage
% latex table generated in R 2.6.0 by xtable 1.5-5 package
% Wed Aug 26 15:22:41 2009
\begin{table}[h!]
	
	\begin{center}
		
		\begin{tabular}{rrrr}
			\hline
			Round& Fotobalk (F) & Counter (C) & F-C \\
			\hline
			1 & 793.8& 794.6 & -0.8 \\
			2 & 793.1 & 793.9 & -0.8 \\
			3 & 792.4 & 793.2 & -0.8 \\
			4 & 794.0 & 794.0 & 0.0 \\
			5 & 791.4 & 792.2 & -0.8 \\
			6 & 792.4 & 793.1 & -0.7 \\
			7 & 791.7 & 792.4 & -0.7 \\
			8 & 792.3 & 792.8 & -0.5 \\
			9 & 789.6 & 790.2 & -0.6 \\
			10 & 794.4 & 795.0 & -0.6 \\
			11 & 790.9 & 791.6 & -0.7 \\
			12 & 793.5 & 793.8 & -0.3 \\
			\hline
		\end{tabular}
		\caption{Difference between Fotobalk and Counter measurements.}
	\end{center}
\end{table}

\bigskip


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\newpage
\section{Introduction}
The problem of assessing the agreement between two or more methods
of measurement is ubiquitous in scientific research, and is
commonly referred to as a `method comparison study'. Published
examples of method comparison studies can be found in disciplines
as diverse as Pharmacology \citep{ludbrook97}, Anaesthesia
\citep{Myles}, and cardiac imaging methods \citep{Krumm}.
\smallskip

To illustrate the characteristics of a typical method comparison
study consider the data in Table I \citep{Grubbs73}. In each of
twelve experimental trials a single round of ammunition was fired
from a 155mm gun, and its velocity was measured simultaneously
(and independently) by three chronographs devices, identified here
by the labels `Fotobalk', `Counter' and `Terma'.
\smallskip


\newpage

\begin{table}[ht]
	\begin{center}
		\begin{tabular}{rrrr}
			\hline
			Round& Fotobalk [F] & Counter [C]& Terma [T]\\
			\hline
			1 & 793.8 & 794.6 & 793.2 \\
			2 & 793.1 & 793.9 & 793.3 \\
			3 & 792.4 & 793.2 & 792.6 \\
			4 & 794.0 & 794.0 & 793.8 \\
			5 & 791.4 & 792.2 & 791.6 \\
			6 & 792.4 & 793.1 & 791.6 \\
			7 & 791.7 & 792.4 & 791.6 \\
			8 & 792.3 & 792.8 & 792.4 \\
			9 & 789.6 & 790.2 & 788.5 \\
			10 & 794.4 & 795.0 & 794.7 \\
			11 & 790.9 & 791.6 & 791.3 \\
			12 & 793.5 & 793.8 & 793.5 \\
			\hline
		\end{tabular}
		\caption{Velocity measurement from the three chronographs (Grubbs
			1973).}
	\end{center}
\end{table}

An important aspect of the these data is that all three methods of
measurement are assumed to have an attended measurement error, and
the velocities reported in Table 1.1 can not be assumed to be
`true values' in any absolute sense.

%While lack of
%agreement between two methods is inevitable, the question , as
%posed by \citet{BA83}, is 'do the two methods of measurement agree
%sufficiently closely?'

A method of measurement should ideally be both accurate and
precise. \citet{Barnhart} describes agreement as being a broader
term that contains both of those qualities. An accurate
measurement method will give results close to the unknown `true
value'. The precision of a method is indicated by how tightly
measurements obtained under identical conditions are distributed
around their mean measurement value. A precise and accurate method
will yield results consistently close to the true value. Of course
a method may be accurate, but not precise. If the average of its
measurements is close to the true value, but those measurements
are highly dispersed. Conversely a method that is not accurate may
be quite precise, as it consistently indicates the same level of
inaccuracy. The tendency of a method of measurement to
consistently give results above or below the true value is a
source of systematic bias. The smaller the systematic bias, the
greater the accuracy of the method.


The FDA define precision as the closeness of agreement (degree of
scatter) between a series of measurements obtained from multiple
sampling of the same homogeneous sample under prescribed
conditions. \citet{Barnhart} describes precision as being further
subdivided as either within-run, intra-batch precision or
repeatability (which assesses precision during a single analytical
run), or between-run, inter-batch precision or repeatability
(which measures precision over time)

In the context of the agreement of two methods, there is also a
tendency of one measurement method to consistently give results
above or below the other method. Lack of agreement is a
consequence of the existence of `inter-method bias'. For two
methods to be considered in good agreement, the inter-method bias
should be in the region of zero. A simple estimation of the
inter-method bias can be calculated using the differences of the
paired measurements. The data in Table 1.2 are a good example of
possible inter-method bias; the `Fotobalk' consistently recording
smaller velocities than the `Counter' method. Consequently one
would conclude that there is lack of agreement between the two
methods.

The absence of inter-method bias by itself is not sufficient to
establish whether two measurement methods agree. The two
methods must also have equivalent levels of precision. Should one
method yield results considerably more variable than that of the
other, they can not be considered to be in agreement. With this in
mind a methodology is required that allows an analyst to estimate
the inter-method bias, and to compare the precision of both
methods of measurement.
\newpage
% latex table generated in R 2.6.0 by xtable 1.5-5 package
% Wed Aug 26 15:22:41 2009
\begin{table}[h!]
	
	\begin{center}
		
		\begin{tabular}{rrrr}
			\hline
			Round& Fotobalk (F) & Counter (C) & F-C \\
			\hline
			1 & 793.8& 794.6 & -0.8 \\
			2 & 793.1 & 793.9 & -0.8 \\
			3 & 792.4 & 793.2 & -0.8 \\
			4 & 794.0 & 794.0 & 0.0 \\
			5 & 791.4 & 792.2 & -0.8 \\
			6 & 792.4 & 793.1 & -0.7 \\
			7 & 791.7 & 792.4 & -0.7 \\
			8 & 792.3 & 792.8 & -0.5 \\
			9 & 789.6 & 790.2 & -0.6 \\
			10 & 794.4 & 795.0 & -0.6 \\
			11 & 790.9 & 791.6 & -0.7 \\
			12 & 793.5 & 793.8 & -0.3 \\
			\hline
		\end{tabular}
		\caption{Difference between Fotobalk and Counter measurements.}
	\end{center}
\end{table}

\bigskip


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\newpage

\section{Method Comparison Stduies with \texttt{R}}

\subsection{Accuracy and Precision}

An important consideration in discussing methods of measurement are the issues of accuracy and precision.

\subsection{What is Agreement}

Agreement between two methods of clinical measurement can be quantified using the differences between observations made using the two methods on the same subjects. (Bland and Altman 1999)




\subsection{Bias}
Bland and Altman define bias a \emph{a consistent tendency for one
method to exceed the other} [$3$] and propose estimating its value
by determining the mean of the differences. The variation about
this mean shall be estimated by the  standard deviation of the
differences. Bland and Altman remark that these estimates are based on the
assumption that bias and variability are constant throughout the
range of measurements.



\bibliographystyle{chicago}
\bibliography{DB-txfrbib}




\end{document} 
