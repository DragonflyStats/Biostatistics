
\documentclass[12pt, a4paper]{article}
\usepackage{epsfig}
\usepackage{subfigure}
%\usepackage{amscd}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{amsthm, amsmath}
%\usepackage[dvips]{graphicx}
\usepackage{natbib}
\bibliographystyle{chicago}
\usepackage{vmargin}
% left top textwidth textheight headheight
% headsep footheight footskip
\setmargins{3.0cm}{2.5cm}{15.5 cm}{22cm}{0.5cm}{0cm}{1cm}{1cm}
\renewcommand{\baselinestretch}{1.5}
\pagenumbering{arabic}
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{ill}[theorem]{Example}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{axiom}{Axiom}
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\newtheorem{notation}{Notation}
\theoremstyle{remark}
\newtheorem{remark}{Remark}[section]
\newtheorem{example}{Example}[section]
\renewcommand{\thenotation}{}
\renewcommand{\thetable}{\thesection.\arabic{table}}
\renewcommand{\thefigure}{\thesection.\arabic{figure}}
\title{Research notes: linear mixed effects models}
\author{ } \date{ }


\begin{document}
\author{Kevin O'Brien}
\title{Updating techniques for LME models}

\addcontentsline{toc}{section}{Bibliography}

%----------------------------------------------------------------------------------------%


\newpage
\section{Introduction}

\citet{roy} uses an approach based on linear mixed effects (LME) models for the purpose of comparing the agreement between two methods of measurement, where replicate measurements on items, typically individuals, by both methods are available. She provides three tests of hypothesis appropriate for evaluating the agreement between the two methods of measurement under this sampling scheme. These tests consider null hypotheses that assume: absence of inter-method bias; equality of between-subject variabilities of the two methods; equality of within-subject variabilities of the two methods. By inter-method bias we mean that a systematic difference exists between observations recorded by the two methods. Differences in between-subject variabilities of the two methods arise when one method is yielding average response levels for individuals than are more variable than the average response levels for the same sample of individuals taken by the other method.  Differences in within-subject variabilities of the two methods arise when one method is yielding responses for an individual than are more variable than the responses for this same individual taken by the other method. The two methods of measurement can be considered to agree, and subsequently can be used interchangeably, if all three null hypotheses are true.

\bigskip

Let $y_{mir} $ be the $r$th replicate measurement on the $i$th item by the $m$th method, where $m=1,2,$ $i=1,\ldots,N,$ and $r = 1,\ldots,n_i.$ When the design is balanced and there is no ambiguity we can set $n_i=n.$ The LME model can be written

\begin{equation}
y_{mir} = \beta_{0} + \beta_{m} + b_{mi} + \epsilon_{mir}.
\end{equation}

Here $\beta_0$ and $\beta_m$ are fixed-effect terms representing, respectively, a model intercept and an overall effect for method $m.$ The $b_{1i}$ and $b_{2i}$ terms represent random effect parameters corresponding to the two methods, having $\mathrm{E}(b_{mi})=0$ with $\mathrm{Var}(b_{mi})=g^2_m$ and $\mathrm{Cov}(b_{mi}, b_{m^\prime i})=g_{12}.$ The random error term for each response is denoted $\epsilon_{mir}$ having $\mathrm{E}(\epsilon_{mir})=0$, $\mathrm{Var}(\epsilon_{mir})=\sigma^2_m$, $\mathrm{Cov}(b_{mir}, b_{m^\prime ir})=\sigma_{12}$, $\mathrm{Cov}(\epsilon_{mir}, \epsilon_{mir^\prime})= 0$ and $\mathrm{Cov}(\epsilon_{mir}, \epsilon_{m^\prime ir^\prime})= 0.$
When two methods of measurement are in agreement, there is no significant differences between $ \beta_1$ and $ \beta_2 $ , between $g^2_1 $ and $ g^2_2 $, and between
$ \sigma^2_1 $ and $ \sigma^2_2 $.

\bigskip

% Complete paragraph by specifying variances and covariances for epsilons.
% I thing that these are your sigmas?
% Also, state equality of the parameters in this model when each of the three hypotheses above are true.

\section{Roy's Hypotheses Tests}

In order to express Roy's LME model in matrix notation we gather all $2n_i$ observations specific to item $i$ into a single vector  $\boldsymbol{y}_{i} = (y_{1i1},y_{2i1},y_{1i2},\ldots,y_{mir},\ldots,y_{1in_{i}},y_{2in_{i}})^\prime.$ The LME model can be written
\[
\boldsymbol{y_{i}} = \boldsymbol{X_{i}\beta} + \boldsymbol{Z_{i}b_{i}} + \boldsymbol{\epsilon_{i}},
\]
where $\boldsymbol{\beta}=(\beta_0,\beta_1,\beta_2)^\prime$ is a vector of fixed effects, and $\boldsymbol{X}_i$ is a corresponding $2n_i\times 3$ design matrix for the fixed effects. The random effects are expressed in the vector $\boldsymbol{b}=(b_1,b_2)^\prime$, with $\boldsymbol{Z}_i$ the corresponding $2n_i\times 2$ design matrix. The vector $\boldsymbol{\epsilon}_i$ is a $2n_i\times 1$ vector of residual terms. Random effects and residuals are assumed to be independent of each other.

The random effects are assumed to be distributed as $\boldsymbol{b}_i \sim \mathcal{N}_2(0,\boldsymbol{G})$. The between-item variance covariance matrix $\boldsymbol{G}$ is constructed as follows:
\[ \boldsymbol{G} =\left(
            \begin{array}{cc}
              g^2_1  & g_{12} \\
              g_{12} & g^2_2 \\
            \end{array}
          \right) \]

% This is probably a good place to discuss how R_i can  be interpreted as a Kroneckor product

The matrix of random errors $\boldsymbol{\epsilon}_i$ is distributed as $\mathcal{N}_2(0,\boldsymbol{R}_i)$.
\citet{hamlett} shows that the variance covariance matrix for the residuals(i.e. the within-item sources of variation between both methods) can be expressed as the Kroneckor product of an $n_i \times n_i$ identity matrix and the partial within-item variance covariance matrix $\boldsymbol{\Sigma}$, i.e. $\boldsymbol{R}_{i} = \boldsymbol{I}_{n_{i}} \otimes \boldsymbol{\Sigma}$.
\[
\boldsymbol{\Sigma} = \left( \begin{array}{cc}
  \sigma^2_{1} & \sigma_{12} \\
  \sigma_{12} & \sigma^2_{2} \\
\end{array}\right),
\]
where $\sigma^2_{1}$ and $\sigma^2_{2}$ are the within-subject variances of the respective methods, and $\sigma_{12}$ is the within-item covariance between the two methods. The within-item variance covariance matrix $\boldsymbol{\Sigma}$ is assumed to be the same for all replications.Computational analysis of linear mixed effects models allow for the explicit analysis of both $\boldsymbol{G}$ and $\boldsymbol{R_i}$.

For expository purposes consider the case where each item provides three replicate measurements by each method. In matrix form the model has the structure
\[
\boldsymbol{y}_{i} =
%---Design Matrix X ----%
\left(\begin{array}{ccc}
 1 & 1 & 0 \\ 1 & 0 & 1 \\ 1 & 1 & 0 \\
 1 & 0 & 1 \\ 1 & 1 & 0 \\ 1 & 0 & 1 \\
\end{array}\right)
%---FE Matrix----%
\left(\begin{array}{c}
 \beta_0 \\ \beta_1 \\ \beta_2 \\
\end{array}\right)
+
%---Design Matrix Z----%
\left(\begin{array}{cc}
1 & 0 \\0 & 1 \\1 & 0 \\0 & 1 \\0 & 1 \\\end{array}
\right)
%---RE Matrix----%
\left(\begin{array}{c}
b_{1i} \\   b_{2i} \\
\end{array}\right)
+
%------Errors Vector---%
\left( \begin{array}{c}
\epsilon_{1i1} \\\epsilon_{2i1} \\\epsilon_{1i2} \\ \epsilon_{2i2} \\\epsilon_{1i3} \\\epsilon_{2i3} \\
\end{array}\right).
\]
The between item variance covariance $\boldsymbol{G}$ is as before, while the within item variance covariance is given as
%------Specification of within item VC matrix R---%
\[
\boldsymbol{R}_i = \left(
\begin{array}{cccccc}
  \sigma^2_{1} & \sigma_{12} & 0 & 0 & 0 & 0 \\
  \sigma_{12} & \sigma^2_{2} & 0 & 0 & 0 & 0 \\
  0 & 0 & \sigma^2_{1} & \sigma_{12} & 0 & 0 \\
  0 & 0 & \sigma_{12} & \sigma^2_{2} & 0 & 0 \\
  0 & 0 & 0 & 0 & \sigma^2_{1} & \sigma_{12} \\
  0 & 0 & 0 & 0 & \sigma_{12} & \sigma^2_{2} \\
\end{array} \right)
\]

The overall variability between the two methods is the sum of between-item variability
$\boldsymbol{G}$ and partial within-item variability $\boldsymbol{\Sigma}$. \citet{roy} denotes the overall variability as ${\mbox{Block - }\boldsymbol \Omega_{i}}$. The overall variation for methods $1$ and $2$ are given by

%------Overall variability in terms of G and R ----%
\begin{equation}
\left(\begin{array}{cc}
              \omega^2_1  & \omega_{12} \\
              \omega_{12} & \omega^2_2 \\
       \end{array}  \right)
 =
\left(\begin{array}{cc}
              g^2_1  & g_{12} \\
              g_{12} & g^2_2 \\
\end{array} \right)
+
\left( \begin{array}{cc}
              \sigma^2_1  & \sigma_{12} \\
              \sigma_{12} & \sigma^2_2 \\
\end{array}\right)
\end{equation}
%------------------------------------------------------------------------%
\newpage
\subsection{Roy's hypothesis tests for variability}
% Three hypothesis tests follow from this equation.
Lack of agreement can arise if there is a disagreement in overall variabilities. This may be due to due to the disagreement in either between-item variabilities or within-item variabilities, or both. The formulation presented above usefully facilitates a series of significance tests that advise as to how well the two methods agree. \citet{roy} allows for a formal test of each. These tests are comprised of a formal test for the equality of between-item variances,
\begin{eqnarray*}
\operatorname{H_0} : g^2_1 = g^2_2 \\
\operatorname{H_1} : g^2_1 \neq g^2_2
\end{eqnarray*}
a formal test for the equality of within-item variances,
\begin{eqnarray*}
\operatorname{H_0} : \sigma^2_1 = \sigma^2_2 \\
\operatorname{H_1} : \sigma^2_1 \neq \sigma^2_2
\end{eqnarray*}
and finally, a formal test for the equality of overall variances.
\begin{eqnarray*}
\operatorname{H_0} : \omega^2_1 = \omega^2_2 \\
\operatorname{H_1} : \omega^2_1 \neq \omega^2_2
\end{eqnarray*}

These tests are complemented by the ability to consider the inter-method bias and the overall correlation coefficient.
Two methods can be considered to be in agreement if criteria based upon these methodologies are met. Additionally Roy makes reference to the overall correlation coefficient of the two methods, which is determinable from variance estimates.

\subsection{Computation of limits of agreement under Roy's model}
The limits of agreement \citep{BA86} are ubiquitous in method comparison studies.
The computation thereof require that the variance of the difference of measurements. This variance is easily computable from the  variance estimates in the ${\mbox{Block - }\boldsymbol \Omega_{i}}$ matrix, i.e.
\[
% Check this
\operatorname{Var}(y_1 - y_2) = \sqrt{ \omega^2_1 + \omega^2_2 - 2\omega_{12}}.
\]

\newpage
\section{Carstensen's Model}
\citet{BXC2008} uses an approach based on linear mixed effects (LME) models for the purpose of computing the limits of agreement for two methods of measurement, where replicate measurements are taken on items. As the emphasis of this methodology lies on the inter-method bias and the limits of agreement, the two key elements of the Bland-Altman methodology, other formal tests are not described.

Using Carstensen's notation, a measurement $y_{mi}$ by method $m$ on individual $i$ the measurement $y_{mir} $ is the $r$th replicate measurement on the $i$th item by the $m$th method, where $m=1,2,$ $i=1,\ldots,N,$ and $r = 1,\ldots,n_i$ is formulated as follows;

\begin{equation}
y_{mir}  = \alpha_{m} + \mu_{i} + c_{mi} + \epsilon_{mir}, \qquad  e_{mi}
\sim \mathcal{N}(0,\sigma^{2}_{m}), \quad c_{mi} \sim \mathcal{N}(0,\tau^{2}_{m}).
\end{equation}

Here the terms $\alpha_{m}$ and $\mu_{i}$ represent the fixed effect for method $m$ and a true value for item $i$ respectively. The random effect terms comprise an interaction term $c_{mi}$ and the residuals $\epsilon_{mir}$.
%---Key difference 1---The True Value
%---Colollary -- Difference in model types
The presence of the true value term $\mu_i$ gives rise to an important difference between Carstensen's and Roy's models. The fixed effect of Roy's model comprise of an intercept term and fixed effect terms for both methods, with no reference to the true value of any individual item. In other words, Roy considers the group of items being measured as a sample taken from a population. A distinction can be made between the two models: Roy's model is a standard LME model, whereas Carstensen's model is a more complex additive model.
%---Key Difference 2 --- Need for balanced design
%---Key Difference 3 --- Univariate normal distribution

\newpage



As the difference between methods is of interest, the item term can be disregarded.

We assume that that the variance of the measurements is different for both methods, but it does not mean that the separate variances can be estimated with the data available.\\
% Carstensen also uses a LME model for examining MCS with replicates.\\


% Carstensen allocates a fixed, but unknown, mean for each individual. [Grubbs(1948) model.]\\

% His interest lies in calculating the LoA as opposed to formalized testing.

\citet{BXC2004} presents a model to describe the relationship between a value of measurement and its real value.
The non-replicate case is considered first, as it is the context of the Bland-Altman plots.
This model assumes that inter-method bias is the only difference between the two methods.


\begin{equation}
y_{mi}  = \alpha_{m} + \mu_{i} + e_{mi} \qquad  e_{mi} \sim \mathcal{N}(0,\sigma^{2}_{m})
\end{equation}

The differences are expressed as $d_{i} = y_{1i} - y_{2i}$.
For the replicate case, an interaction term $c$ is added to the model, with an associated variance component.
All the random effects are assumed independent, and that all replicate measurements are assumed to be exchangeable within each method.


%----



\section{Carstensen's Limits of agreement}
\citet{bxc2008} presents a methodology to compute the limits of agreement based on LME models.
Importantly, Carstensen's underlying model differs from Roy's model in some key respects, and therefore a prior discussion of Carstensen's model is required.


\subsection{Assumptions on Variability}

Aside from the fixed effects, another important difference is that Carstensen's model requires that particular assumptions be applied, specifically that the off-diagonal elements of the between-item
and within-item variability matrices are zero. By extension the overall variability off diagonal elements are also zero. Also, implementation requires that the between-item variances are
estimated as the same value: $g^2_1 = g^2_2 = g^2$. Necessarily Carstensen's method does not allow for a formal test of the between-item variability.

\[\left(\begin{array}{cc}
                \omega^1_2  & 0 \\
              0 & \omega^2_2 \\
            \end{array}  \right)
            =  \left(
            \begin{array}{cc}
              g^2  & 0 \\
              0 & g^2 \\
            \end{array} \right)+
            \left(
            \begin{array}{cc}
              \sigma^2_1  & 0 \\
              0 & \sigma^2_2 \\
            \end{array}\right)
\]

In cases where the off-diagonal terms in the overall variability
matrix are close to zero, the limits of agreement due to
\citet{bxc2008} are very similar to the limits of agreement that
follow from the general model.

\newpage
\newpage
\subsection{Remarks on the Multivariate Normal Distribution}

Diligence is required when considering the models. Carstensen specifies his models in terms of the univariate normal distribution. Roy's model is specified using the bivariate normal distribution.
This gives rises to a key difference between the two model, in that a bivariate model accounts for covariance between the variables of interest.
The multivariate normal distribution of a $k$-dimensional random vector $X = [X_1, X_2, \ldots, X_k]$
can be written in the following notation:
\[
    X\ \sim\ \mathcal{N}(\mu,\, \Sigma),
\]
or to make it explicitly known that $X$ is $k$-dimensional,
\[
    X\ \sim\ \mathcal{N}_k(\mu,\, \Sigma).
\]
with $k$-dimensional mean vector
\[ \mu = [ \operatorname{E}[X_1], \operatorname{E}[X_2], \ldots, \operatorname{E}[X_k]] \]
and $k \times k$ covariance matrix
\[ \Sigma = [\operatorname{Cov}[X_i, X_j]], \; i=1,2,\ldots,k; \; j=1,2,\ldots,k \]

\bigskip

\begin{enumerate}
\item Univariate Normal Distribution

\[
    X\ \sim\ \mathcal{N}(\mu,\, \sigma^2),
\]

\item Bivariate Normal Distribution

\begin{itemize}
\item[(a)] \[  X\ \sim\ \mathcal{N}_2(\mu,\, \Sigma), \vspace{1cm}\]
\item[(b)] \[    \mu = \begin{pmatrix} \mu_x \\ \mu_y \end{pmatrix}, \quad
    \Sigma = \begin{pmatrix} \sigma_x^2 & \rho \sigma_x \sigma_y \\
                             \rho \sigma_x \sigma_y  & \sigma_y^2 \end{pmatrix}.\]
\end{itemize}
\end{enumerate}
\newpage

\section{Note 1: Coefficient of Repeatability}
The coefficient of repeatability is a measure of how well a
measurement method agrees with itself over replicate measurements
\citep{BA99}. Once the within-item variability is known, the
computation of the coefficients of repeatability for both methods
is straightforward.


\section{Note 2: Model terms}
It is important to note the following characteristics of this model.
\begin{itemize}
\item Let the number of replicate measurements on each item $i$ for both methods be $n_i$, hence $2 \times n_i$ responses. However, it is assumed that there may be a different number of replicates made for different items. Let the maximum number of replicates be $p$. An item will have up to $2p$ measurements, i.e. $\max(n_{i}) = 2p$.

% \item $\boldsymbol{y}_i$ is the $2n_i \times 1$ response vector for measurements on the $i-$th item.
% \item $\boldsymbol{X}_i$ is the $2n_i \times  3$ model matrix for the fixed effects for observations on item $i$.
% \item $\boldsymbol{\beta}$ is the $3 \times  1$ vector of fixed-effect coefficients, one for the true value for item $i$, and one effect each for both methods.

\item Later on $\boldsymbol{X}_i$ will be reduced to a $2 \times 1$ matrix, to allow estimation of terms. This is due to a shortage of rank. The fixed effects vector can be modified accordingly.
\item $\boldsymbol{Z}_i$ is the $2n_i \times  2$ model matrix for the random effects for measurement methods on item $i$.
\item $\boldsymbol{b}_i$ is the $2 \times  1$ vector of random-effect coefficients on item $i$, one for each method.
\item $\boldsymbol{\epsilon}$  is the $2n_i \times  1$ vector of residuals for measurements on item $i$.
\item $\boldsymbol{G}$ is the $2 \times  2$ covariance matrix for the random effects.
\item $\boldsymbol{R}_i$ is the $2n_i \times  2n_i$ covariance matrix for the residuals on item $i$.
\item The expected value is given as $\mbox{E}(\boldsymbol{y}_i) = \boldsymbol{X}_i\boldsymbol{\beta}.$ \citep{hamlett}
\item The variance of the response vector is given by $\mbox{Var}(\boldsymbol{y}_i)  = \boldsymbol{Z}_i \boldsymbol{G} \boldsymbol{Z}_i^{\prime} + \boldsymbol{R}_i$ \citep{hamlett}.
\end{itemize}
\newpage

%\chapter{Limits of Agreement}

%\section{Modelling Agreement with LME Models}

% Carstensen pages 22-23


\bigskip
Roys uses and LME model approach to provide a set of formal tests for method comparison studies.\\

Four candidates models are fitted to the data.\\

These models are similar to one another, but for the imposition of equality constraints.\\

These tests are the pairwise comparison of candidate models, one formulated without constraints, the other with a constraint.\\


Roy's model uses fixed effects $\beta_0 + \beta_1$ and $\beta_0 + \beta_1$ to specify the mean of all observationsby \\ methods 1 and 2 respectuively.


Roy adheres to Random Effect ideas in ANOVA

Roy treats items as a sample from a population.\\

Allocation of fixed effects and random effects are very different in each model\\

Carstensen's interest lies in the difference between the population from which they were drawn.\\

Carstensen's model is a mixed effects ANOVA.\\

\[
Y_{mir}  =  \alpha_m + \mu_i + c_{mi} + e_{mir}, \qquad c_{mi} \sim \mathcal{\tau^2_m}, \qquad e_{mir} \sim \mathcal{\sigma^2_m},
\]

This model includes a method by item iteration term.\\

Carstensen presents two models. One for the case where the replicates, and a second for when they are linked.\\

Carstensen's model does not take into account either between-item or within-item covariance between methods.\\

Importantly, estimates required to calculate the limits of agreement are not extractable, and therefore the calculation must be done by hand.

In cases where there is negligible covariance between methods, the limits of agreement computed using Roy's model accord with those computed using Carstensen's model.
In cases where some degree of covariance is present between the two methods, the limits of agreement computed using models will differ.

In the presented example, it is shown that Roy's LoAs are lower than those of Carstensen.
Carstensen makes some interesting remarks in this regard.

\begin{quote}
The only slightly non-standard (meaning "not often used") feature is the differing residual variances between methods.
\end{quote}



\newpage
\bibliography{DB-txfrbib}
\end{document}
