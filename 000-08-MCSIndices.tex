\documentclass[Chap3bmain.tex]{subfiles}
\begin{document}
\section{Probability-based Measures of Agreement}
There are two measures of agreement based on the probability criteria. The first is the
$p_0$-th percentile of jDj, say Q($p_0$), where $p_0$ (> 0.5) is a specified large probability (usually
Â¸ 0:80). 
It was introduced by Lin (2000) who called it the total deviation index (TDI). Its
small value indicates a good agreement between (X; Y ). The TDI can be expressed as,

! EQUATION HERE
-distribution with a single degree of freedom
and non-centrality parameter $\Del$.

%-----------------------------------------------------------------------------------------%
%Coverarge Probability

The second measure, introduced by Lin et al. (2002), is the \textbf{coverage probability} (CP) of
the interval [Â¡Â±0; Â±0], where a difference under Â§Â±0 is considered practically equivalent to
zero. There is no loss of generality in taking this interval to be symmetric around zero as it
can be achieved by a location shift. 

Letting,
dl = (Â¡Â±0 Â¡ Â¹)=Â¾; du = (Â±0 Â¡ Â¹)=Â¾; (2)


the CP can be expressed as
F(Â±0) = Â©(du) Â¡ Â©(dl): (3)

A high value of F(Â±0) implies a good agreement between the methods.

\newpage
\subsection*{Coverage Probability and Total Deviation Index}
% Barnhart

As elaborated by Lin and colleagues (Lin, 2000; Lin et al., 2002), an intuitive measure of
agreement is a measure that captures a large proportion of data within a boundary for allowed
observersâ€™ differences. The proportion and boundary are two quantities that correspond to
each other. If we set d0 as the predetermined boundary; i.e., the maximum acceptable
absolute difference between two observersâ€™ readings, we can compute the probability of absolute
difference between any two observersâ€™ readings less than d0. 

This probability is called
coverage probability (CP). On the other hand, if we set 0 as the predetermined coverage
probability, we can find the boundary so that the probability of absolute difference less than
this boundary is 0. This boundary is called total deviation index (TDI) and is the 1000
percentile of the absolute difference of paired observations. A satisfactory agreement may
require a large CP or, equivalently, a small TDI.

For J = 2 observers, let Yi1 and Yi2 be the
readings of these two observers, the CP and TDI are defined as
\[
CPd0 = Prob(|Yi1 âˆ’ Yi2| < d0), TDI0 = fâˆ’1(0)
\]
where fâˆ’1(0) is the solution of d by setting $f(d) = Prob(|Yi1 âˆ’ Yi2| < d) = 0$.
Estimation and inference on CPd0 and TDI0 often requires a normality assumption on
Di = Yi1 âˆ’ Yi2.Assume that Di is normally distributed with mean Î¼D and variance 2
D .


	
	\subsection*{Coverage probability (CP)}
	Another user friendly measure of agreement which is related to the computation of the TDI is the so called coverage probability (CP) [11,12]. 
	The CP describes the proportion captured within a pre-specified boundary of the absolute paired-measurement differences from two devices, i.e., the value of p$\kappa$ such that $P(|D| < \kappa$) = $p_\kappa$. Therefore one can find p$\kappa$ for a specified boundary $\kappa$ using standard methods for computing probability quantities under normal assumptions [11]:
	
	(13)
	and to obtain a CP estimate, p$\kappa$ can be computed by replacing $\mu_D$ and $\sigma_D$ by their REML estimate counterparts derived from model (1).
	
	As with the TDI, the CP criterion can also be translated into a hypothesis test specification. 
	In this case the interest is to ensure that a specified boundary of the absolute paired-measurement differences captures at least a predetermined proportion, p0:
	
	
	The proposed TI method for inference about the TDI can be utilized to perform inferences about the CP estimates. From the TI in (10) it follows that
	
	(14)
	Now $\kappa$ is a fixed known boundary, and our interest lies in finding a lower confidence bound for the CP estimate. 
	Thus, one can find a lower confidence bound for a non-central Student-t proportion with confidence level 1 - $\alpha$ by searching the non-centrality parameter, 
	that depends on  and hence on p$\kappa$, that satisfies
	
	(15)
	and once the non-centrality parameter  is achieved, a lower bound about the proportion p$\kappa$ is found using equation (5), 
	
	% p$\kappa$ = Î¦() - Î¦(-2Î¼D/ÏƒD - ).
	
	However, the non-centrality parameter cannot be found in a closed form, so one may use again a modified version of the binary search algorithm as follows:
	
	\begin{enumerate}
		\item begin with the interval [low = 0; high = 1], as p$\kappa$ is bounded by the interval (0,1);
		
		\item calculate the midpoint of the interval \textit{mid = (low + high)/2} and compute the difference ;
		
		\item if d is greater than 0 up to a tolerance bound $\delta$ (i.e., ), then recalculate the interval [low = mid + $\delta$; high = 1]; if it is 
		lower than 0 up to a tolerance bound $\delta$ (i.e. ), then recalculate the interval [low = 0; high = mid - $\delta$];
		
		\item repeat steps 2-3 until convergence, i.e. until d satisfies .
	\end{enumerate}
\newpage
\section{Probability-based Measures of Agreement}
There are two measures of agreement based on the probability criteria. The first is the
$p_0$-th percentile of jDj, say Q($p_0$), where $p_0$ (> 0.5) is a specified large probability (usually
Â¸ 0:80). 
It was introduced by Lin (2000) who called it the total deviation index (TDI). Its
small value indicates a good agreement between (X; Y ). The TDI can be expressed as,

! EQUATION HERE
-distribution with a single degree of freedom
and non-centrality parameter $\Del$.

%-----------------------------------------------------------------------------------------%
%Coverarge Probability

The second measure, introduced by Lin et al. (2002), is the \textbf{coverage probability} (CP) of
the interval [Â¡Â±0; Â±0], where a difference under Â§Â±0 is considered practically equivalent to
zero. There is no loss of generality in taking this interval to be symmetric around zero as it
can be achieved by a location shift. 

Letting,
dl = (Â¡Â±0 Â¡ Â¹)=Â¾; du = (Â±0 Â¡ Â¹)=Â¾; (2)


the CP can be expressed as
F(Â±0) = Â©(du) Â¡ Â©(dl): (3)

A high value of F(Â±0) implies a good agreement between the methods.


%-----------------------------------------------------------------------------------------%
\section{Coverage Probability and Tolerance Deviation Index}

Individual agreement between two measurement methods may be
assessed using the the coverage probability (CP) criteria or the
total deviation index (TDI) as proposed by \citet{lin2000} and
\citet{lin2002}.

If $d_{0}$ is predetermined as the maximum acceptable absolute
difference between two methods of measurement, the probability
that the absolute difference of two measures being less than
$d_{0}$ can be computed. This is known as the coverage probability
(CP).

\begin{equation}
CP = P(|x_{i} - y_{i}| \leq d_{0})
\end{equation}

If $\pi_{0}$ is set as the predetermined coverage probability, the
boundary under which the proportion of absolute differences is
$\pi_{0}$ may be determined. his boundary is known as the `total
deviation index' (TDI). Hence the TDI is the $100\pi_{0}$
percentile of the absolute difference of paired observations.


The CP is the most intuitively clear approach; it mirrors the information provided by the TDI. 
Both TDI and CP depend on the normality assumption and offer better power
for inference than the CCC. The CP would have difÂŽficulty discriminating among instruments or 
assays that have excellent agreement, all because the CP values would be very close to
1. In this case, the TDI can be used to discriminate among these. When a meaningful clinical range is known and the study is conducted over that range, the CCC offers a meaningful geo- metric interpretation and is unit free. Furthermore, the accuracy and precision components of the CCC offer more insight. Therefore, the CCC, accuracy, and precision remain very useful tools. Note that when Y and X are not linearly related, the CCC will capture the total deviation. However, it will treat the nonlinear deviation as imprecision rather than inaccuracy. The CCC, ICC, and Pearson correlation coefÂŽ cient depend
largely on the analytical range and the intrasample variation.

%-------------------------------------------------------------------------------------------%
\section{Mean Square Deviation}
Mean Square deviation is defined as the expectation of the squared difference of two readings.
The MSD is usually used for the case of two methods, each making a single reading.


\newpage
Total Deviation Index
================================================================

Total deviation index for measuring individual agreement with applications in laboratory performance and bioequivalence.
Lin LI.
*Stat Med. 2000 Jan 30;19(2):255-70*
*http://www.ncbi.nlm.nih.gov/pubmed/10641028*
<hr>
- In areas of inter-laboratory quality control, method comparisons, assay validation and individual bioequivalence, etc., 
the agreement between observations and target (reference) values is of interest. 

- The mean of the squared difference between observations and target values (MSD) is a good measure of the total deviation. 
A new user-friendly statistic, the total deviation index (TDI(1-p)), is introduced that translates the MSD into an index
that can be directly compared to a predetermined criterion. 

- The TDI(1-p) describes a boundary such that a majority, 100(1-p) per cent, of the observations are within the boundary
(measurement unit and/or per cent) from their target values. Statistical inference using the sample counter part
(estimate) is presented. 

- A Monte Carlo experiment with 5000 runs was performed to confirm the estimate's validity.
Applications in laboratory performance and validation, as well as individual bioequivalence, are presented.




\end{document}
