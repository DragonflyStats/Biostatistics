
\documentclass[12pt, a4paper]{article}
\usepackage{natbib}
\usepackage{vmargin}
\usepackage{graphicx}
\usepackage{epsfig}
\usepackage{subfigure}
%\usepackage{amscd}
\usepackage{amssymb}
\usepackage{subfigure}
\usepackage{amsbsy}
\usepackage{amsthm, amsmath}
%\usepackage[dvips]{graphicx}
\bibliographystyle{chicago}
\renewcommand{\baselinestretch}{1.4}

% left top textwidth textheight headheight % headsep footheight footskip
\setmargins{3.0cm}{2.5cm}{15.5 cm}{23.5cm}{0.5cm}{0cm}{1cm}{1cm}

\pagenumbering{arabic}


\begin{document}
	\chapter{Zewotir's Paper}
	
	% 2.1 Efficient Updating Theorem
	% 2.2 Zewotir Measures of Influence in LME Models (section 4 of paper)
	% 2.3 Computation and Notation 
	% 2.4 Measures 2
	
	
	\section{Efficient Updating Theorem}
	\citet{Zewotir} describes the basic theorem of efficient updating.
	\begin{itemize}
		\item \[ m_i = {1 \over c_{ii}}\]
		%\item
		%item
		%\item
	\end{itemize}
	%-------------------------------------------------------------------------------------------------------------------------------------%
	\section{Zewotir Measures of Influence in LME Models}
	%Zewotir page 161
	\citet{Zewotir} describes a number of approaches to model diagnostics, investigating each of the following;
	\begin{itemize}
		\item Variance components
		\item Fixed effects parameters
		\item Prediction of the response variable and of random effects
		\item likelihood function
	\end{itemize}
	
	\subsection{Cook's Distance}
	\begin{itemize}
		\item For variance components $\gamma$: $CD(\gamma)_i$,
		\item For fixed effect parameters $\beta$: $CD(\beta)_i$,
		\item For random effect parameters $\boldsymbol{u}$: $CD(u)_i$,
		\item For linear functions of $\hat{beta}$: $CD(\psi)_i$
	\end{itemize}
	
	\newpage
	\subsubsection{Random Effects}
	
	A large value for $CD(u)_i$ indicates that the $i-$th observation is influential in predicting random effects.
	
	\subsubsection{linear functions}
	
	$CD(\psi)_i$ does not have to be calculated unless $CD(\beta)_i$ is large.
	
	
	\subsection{Information Ratio}
	
	
	%--------------------------------------------------------------%
	\newpage
	\section{Computation and Notation } %2.3
	with $\boldsymbol{V}$ unknown, a standard practice for estimating $\boldsymbol{X \beta}$ is the estime the variance components $\sigma^2_j$,
	compute an estimate for $\boldsymbol{V}$ and then compute the projector matrix $A$, $\boldsymbol{X \hat{\beta}}  = \boldsymbol{AY}$.
	
	
	\citet{Zewotir} remarks that $\boldsymbol{D}$ is a block diagonal with the $i-$th block being $u \boldsymbol{I}$
	%--------------------------------------------------------------%
	\newpage
	\section{Measures 2} %2.4
	
	\subsection{Cook's Distance} %2.4.1
	\begin{itemize}
		\item For variance components $\gamma$
	\end{itemize}
	
	Diagnostic tool for variance components
	\[ C_{\theta i} =(\hat(\theta)_{[i]} - \hat(\theta))^{T}\mbox{cov}( \hat(\theta))^{-1}(\hat(\theta)_{[i]} - \hat(\theta))\]
	
	\subsection{Variance Ratio} %2.4.2
	\begin{itemize}
		\item For fixed effect parameters $\beta$.
	\end{itemize}
	
	\subsection{Cook-Weisberg statistic} %2.4.3
	\begin{itemize}
		\item For fixed effect parameters $\beta$.
	\end{itemize}
	
	\subsection{Andrews-Pregibon statistic} %2.4.4
	\begin{itemize}
		\item For fixed effect parameters $\beta$.
	\end{itemize}
	The Andrews-Pregibon statistic $AP_{i}$ is a measure of influence based on the volume of the confidence ellipsoid.
	The larger this statistic is for observation $i$, the stronger the influence that observation will have on the model fit.
	
	
	
	
	%---------------------------------------------------------------------------------------------------------%
	%--------------------------------------------------------------------------------------Sort Line ---------%
	%---------------------------------------------------------------------------------------------------------%
	
	
	
	\chapter{Zewotir}

%-------------------------------------------------------------------------------------------------------------------------------------%
\section{Efficient Updating Theorem} %2.1
\citet{Zewotir} describes the basic theorem of efficient updating.
\begin{itemize}
	\item \[ m_i = {1 \over c_{ii}}\]
	%\item
	%item
	%\item
\end{itemize}




\subsubsection{Random Effects}


A large value for $CD(u)_i$ indicates that the $i-$th observation is influential in predicting random effects.


\subsubsection{linear functions}


$CD(\psi)_i$ does not have to be calculated unless $CD(\beta)_i$ is large.






\section{Zewotir Measures of Influence in LME Models}%2.2
%Zewotir page 161
\citet{Zewotir} describes a number of approaches to model diagnostics, investigating each of the following;
\begin{itemize}
	\item Variance components
	\item Fixed effects parameters
	\item Prediction of the response variable and of random effects
	\item likelihood function
\end{itemize}






\section{Haslett's Analysis} %2.5
For fixed effect linear models with correlated error structure Haslett (1999) showed that the effects on
the fixed effects estimate of deleting each observation in turn could be cheaply computed from the fixed effects model predicted residuals.


A general theory is presented for residuals from the general linear model with correlated errors.
It is demonstrated that there are two fundamental types of residual associated with this model,
referred to here as the marginal and the conditional residual.


These measure respectively the distance to the global aspects of the model as represented by the expected value
and the local aspects as represented by the conditional expected value.


These residuals may be multivariate.


\citet{HaslettHayes} developes some important dualities which have simple implications for diagnostics.


%The results are illustrated by reference to model diagnostics in time series and in classical multivariate analysis with independent cases.



\section{Demidenko's I Influence} %2.6
The concept of I Influence is generalized  to the non linea regression model.



\bibliography{DB-txfrbib}
%---------------------------------------------------------------------------%
%1.1 Introduction to Influence Analysis
%1.2 Extension of techniques to LME Models
%1.3 Residual Diagnostics
%1.4 Standardized and studentized residuals
%1.5 Covariance Parameters
%1.6 Case Deletion Diagnostics
%1.7 Influence Analysis
%1.8 Terminology for Case Deletion
%1.9 Cook's Distance (Classical Case)
%1.10 Cook's Distance (LME Case)
%1.11 Likelihood Distance
%1.12 Other Measures
%1.13 CPJ Paper
%1.14 Matrix Notation of Case Deletion
%1.15 CPJ's Three Propositions
%1.16 Other measures of Influence





\newpage
\subsection{Extension of techniques to LME Models} %1.2

Model diagnostic techniques, well established for classical models, have since been adapted for use with linear mixed effects models. Diagnostic techniques for LME models are inevitably more difficult to implement, due to the increased complexity.

Beckman, Nachtsheim and Cook (1987) \citet{Beckman} applied the \index{local influence}local influence method of Cook (1986) to the analysis of the linear mixed model.

While the concept of influence analysis is straightforward, implementation in mixed models is more complex. Update formulae for fixed effects models are available only when the covariance parameters are assumed to be known.

If the global measure suggests that the points in $U$ are influential, the nature of that influence should be determined. In particular, the points in $U$ can affect the following

\begin{itemize}
	\item the estimates of fixed effects,
	\item the estimates of the precision of the fixed effects,
	\item the estimates of the covariance parameters,
	\item the estimates of the precision of the covariance parameters,
	\item fitted and predicted values.
\end{itemize}






%---------------------------------------------------------------------------%
\newpage
\subsection{Influence Statistics for LME models} %1.1.4
Influence statistics can be coarsely grouped by the aspect of estimation that is their primary target:
\begin{itemize}
	\item overall measures compare changes in objective functions: (restricted) likelihood distance (Cook and Weisberg 1982, Ch. 5.2)
	\item influence on parameter estimates: Cook's  (Cook 1977, 1979), MDFFITS (Belsley, Kuh, and Welsch 1980, p. 32)
	\item influence on precision of estimates: CovRatio and CovTrace
	\item influence on fitted and predicted values: PRESS residual, PRESS statistic (Allen 1974), DFFITS (Belsley, Kuh, and Welsch 1980, p. 15)
	\item outlier properties: internally and externally studentized residuals, leverage
\end{itemize}
%---------------------------------------------------------------------------%




\newpage
\subsection{Extension of techniques to LME Models} %1.2


Model diagnostic techniques, well established for classical models, have since been adapted for use with linear mixed effects models.Diagnostic techniques for LME models are inevitably more difficult to implement, due to the increased complexity.


Beckman, Nachtsheim and Cook (1987) \citet{Beckman} applied the \index{local influence}local influence method of Cook (1986) to the analysis of the linear mixed model.


While the concept of influence analysis is straightforward, implementation in mixed models is more complex. Update formulae for fixed effects models are available only when the covariance parameters are assumed to be known.


If the global measure suggests that the points in $U$ are influential, the nature of that influence should be determined. In particular, the points in $U$ can affect the following


\begin{itemize}
	\item the estimates of fixed effects,
	\item the estimates of the precision of the fixed effects,
	\item the estimates of the covariance parameters,
	\item the estimates of the precision of the covariance parameters,
	\item fitted and predicted values.
\end{itemize}








\newpage
\subsection{Standardized and studentized residuals} %1.4
%--Studentized and Standardized Residuals

To alleviate the problem caused by inconstant variance, the residuals are scaled (i.e. divided) by their standard deviations. This results in a \index{standardized residual}`standardized residual'. Because true standard deviations are frequently unknown, one can instead divide a residual by the estimated standard deviation to obtain the \index{studentized residual}`studentized residual. 



%--------------------------------------------------%
\subsection{Residual Analysis for Linear Models, LME models and GLMs}

\textbf{Keywords:}

\begin{itemize}
	\item Residuals (\emph{Beginners}), 
	\item Testing the Assumption of Normality (\emph{Beginners})
	\item Diagnostic Plots with the \texttt{plot} function
	\item Cook's Distance
	\item DFFits and DFBeta
	\item Standardized and Studentized Residuals
	\item Influence Leverage and Outlierness
\end{itemize}
%=================================================================================================== %
\newpage

%http://www.artifex.org/~meiercl/R_statistics_guide.pdf
\subsection{Identifying outliers with a LME model object}

The process is slightly different than with standard LME model objects, since the \textbf{\emph{influence}}
function does not work on lme model objects. Given \textbf{\emph{mod.lme}}, we can use the plot function to
identify outliers.
%----------------------%
\subsection{Diagnostics for Random Effects}
Empirical best linear unbiased predictors EBLUPS provide the a useful way of diagnosing random effects.

EBLUPs are also known as ``shrinkage estimators" because they tend to be smaller than the estimated effects would be if they were computed by treating a random factor as if it was fixed (West et al )




\newpage


\subsection{Influence Diagnostics: Basic Idea and Statistics} %1.1.2
%http://support.sas.com/documentation/cdl/en/statug/63033/HTML/default/viewer.htm#statug_mixed_sect024.htm

The general idea of quantifying the influence of one or more observations relies on computing parameter estimates based on all data points, removing the cases in question from the data, refitting the model, and computing statistics based on the change between full-data and reduced-data estimation. 




\subsection{Case Deletion Diagnostics for Mixed Models}

\citet{Christiansen} notes the case deletion diagnostics techniques have not been applied to linear mixed effects models and seeks to develop methodologies in that respect.

\citet{Christiansen} develops these techniques in the context of REML

\subsection{Methods and Measures}
The key to making deletion diagnostics useable is the development of efficient computational formulas, allowing one to obtain the \index{case deletion diagnostics} case deletion diagnostics by making use of basic building blocks, computed only once for the full model.

\citet{Zewotir} lists several established methods of analyzing influence in LME models. These methods include \begin{itemize}
	\item Cook's distance for LME models,
	\item \index{likelihood distance} likelihood distance,
	\item the variance (information) ration,
	\item the \index{Cook-Weisberg statistic} Cook-Weisberg statistic,
	\item the \index{Andrews-Prebigon statistic} Andrews-Prebigon statistic.
\end{itemize}

%===================================================================================== %


\section{Demidenko's I Influence} %2.6
The concept of I Influence is generalized  to the non linea regression model.
%-------------------------------------------------------------------------------------------------------------------------------------%



\section{Computation and Notation } %2.3
with $\boldsymbol{V}$ unknown, a standard practice for estimating $\boldsymbol{X \beta}$ is the estime the variance components $\sigma^2_j$,
compute an estimate for $\boldsymbol{V}$ and then compute the projector matrix $A$, $\boldsymbol{X \hat{\beta}}  = \boldsymbol{AY}$.




\citet{zewotir} remarks that $\boldsymbol{D}$ is a block diagonal with the $i-$th block being $u \boldsymbol{I}$






\section{The Hat Matrix} %5.1

The projection matrix $H$ (also known as the hat matrix), is a
well known identity that maps the fitted values $\hat{Y}$ to the
observed values $Y$, i.e. $\hat{Y} = HY$.

\begin{equation}
H =\quad X(X^{T}X)^{-1}X^{T}
\end{equation}

$H$ describes the influence each observed value has on each fitted
value. The diagonal elements of the $H$ are the `leverages', which
describe the influence each observed value has on the fitted value
for that same observation. The residuals ($R$) are related to the
observed values by the following formula:
\begin{equation}
R = (I-H)Y
\end{equation}

The variances of $Y$ and $R$ can be expressed as:
\begin{eqnarray}
\mbox{var}(Y) = H\sigma^{2} \nonumber\\
\mbox{var}(R) = (I-H)\sigma^{2}
\end{eqnarray}

Updating techniques allow an economic approach to recalculating
the projection matrix, $H$, by removing the necessity to refit the
model each time it is updated. However this approach is known for
numerical instability in the case of down-dating.




% 2.1 Efficient Updating Theorem
% 2.2 Zewotir Measures of Influence in LME Models (section 4 of paper)
% 2.3 Computation and Notation 
% 2.4 Measures 2
%2.5 Haslett Analysis
\chapter{Zewotir's Paper}

% 2.1 Efficient Updating Theorem
% 2.2 Zewotir Measures of Influence in LME Models (section 4 of paper)
% 2.3 Computation and Notation 
% 2.4 Measures 2
%2.5 Haslett Analysis

\section{Efficient Updating Theorem} %2.1
\citet{Zewotir} describes the basic theorem of efficient updating.
\begin{itemize}
	\item \[ m_i = {1 \over c_{ii}}\]
	%\item
	%item
	%\item
\end{itemize}
%-------------------------------------------------------------------------------------------------------------------------------------%
\section{Zewotir Measures of Influence in LME Models}%2.2
%Zewotir page 161
\citet{Zewotir} describes a number of approaches to model diagnostics, investigating each of the following;
\begin{itemize}
	\item Variance components
	\item Fixed effects parameters
	\item Prediction of the response variable and of random effects
	\item likelihood function
\end{itemize}

\subsection{Cook's Distance}
\begin{itemize}
	\item For variance components $\gamma$: $CD(\gamma)_i$,
	\item For fixed effect parameters $\beta$: $CD(\beta)_i$,
	\item For random effect parameters $\boldsymbol{u}$: $CD(u)_i$,
	\item For linear functions of $\hat{beta}$: $CD(\psi)_i$
\end{itemize}

\newpage
\subsubsection{Random Effects}

A large value for $CD(u)_i$ indicates that the $i-$th observation is influential in predicting random effects.

\subsubsection{linear functions}

$CD(\psi)_i$ does not have to be calculated unless $CD(\beta)_i$ is large.


\subsection{Information Ratio}


%--------------------------------------------------------------%
\newpage
\section{Computation and Notation } %2.3
with $\boldsymbol{V}$ unknown, a standard practice for estimating $\boldsymbol{X \beta}$ is the estime the variance components $\sigma^2_j$,
compute an estimate for $\boldsymbol{V}$ and then compute the projector matrix $A$, $\boldsymbol{X \hat{\beta}}  = \boldsymbol{AY}$.


\citet{zewotir} remarks that $\boldsymbol{D}$ is a block diagonal with the $i-$th block being $u \boldsymbol{I}$
%--------------------------------------------------------------%
\newpage
\section{Measures 2} %2.4

\subsection{Cook's Distance} %2.4.1
\begin{itemize}
	\item For variance components $\gamma$
\end{itemize}

Diagnostic tool for variance components
\[ C_{\theta i} =(\hat(\theta)_{[i]} - \hat(\theta))^{T}\mbox{cov}( \hat(\theta))^{-1}(\hat(\theta)_{[i]} - \hat(\theta))\]

\subsection{Variance Ratio} %2.4.2
\begin{itemize}
	\item For fixed effect parameters $\beta$.
\end{itemize}

\subsection{Cook-Weisberg statistic} %2.4.3
\begin{itemize}
	\item For fixed effect parameters $\beta$.
\end{itemize}

\subsection{Andrews-Pregibon statistic} %2.4.4
\begin{itemize}
	\item For fixed effect parameters $\beta$.
\end{itemize}
The Andrews-Pregibon statistic $AP_{i}$ is a measure of influence based on the volume of the confidence ellipsoid.
The larger this statistic is for observation $i$, the stronger the influence that observation will have on the model fit.


%-------------------------------------------------------------------------------------------------Chapter 3------------------------%
%-------------------------------------------------------------------------------------------------------------------------------------%
%-------------------------------------------------------------------------------------------------------------------------------------%


\section{Efficient Updating Theorem} %2.1
\citet{Zewotir} describes the basic theorem of efficient updating.
\begin{itemize}
	\item \[ m_i = {1 \over c_{ii}}\]
	%\item
	%item
	%\item
\end{itemize}
%-------------------------------------------------------------------------------------------------------------------------------------%
\section{Zewotir Measures of Influence in LME Models}%2.2
%Zewotir page 161
\citet{Zewotir} describes a number of approaches to model diagnostics, investigating each of the following;
\begin{itemize}
	\item Variance components
	\item Fixed effects parameters
	\item Prediction of the response variable and of random effects
	\item likelihood function
\end{itemize}
%---------------------------------------------------------------------------%
\newpage

\chapter{Zewotir's Paper}


% 2.1 Efficient Updating Theorem
% 2.2 Zewotir Measures of Influence in LME Models (section 4 of paper)
% 2.3 Computation and Notation
% 2.4 Measures 2
% 2.5 Haslett Hayes Paper
% 2.6 Demidenko I Influence


\section{Efficient Updating Theorem} %2.1
\citet{Zewotir} describes the basic theorem of efficient updating.
\begin{itemize}
	\item \[ m_i = {1 \over c_{ii}}\]
	%\item
	%item
	%\item
\end{itemize}
%-------------------------------------------------------------------------------------------------------------------------------------%
\section{Zewotir Measures of Influence in LME Models}%2.2
%Zewotir page 161
\citet{Zewotir} describes a number of approaches to model diagnostics, investigating each of the following;
\begin{itemize}
	\item Variance components
	\item Fixed effects parameters
	\item Prediction of the response variable and of random effects
	\item likelihood function
\end{itemize}

\subsection{Cook's Distance}
\begin{itemize}
	\item For variance components $\gamma$: $CD(\gamma)_i$,
	\item For fixed effect parameters $\beta$: $CD(\beta)_i$,
	\item For random effect parameters $\boldsymbol{u}$: $CD(u)_i$,
	\item For linear functions of $\hat{beta}$: $CD(\psi)_i$
\end{itemize}



\newpage
\subsubsection{Random Effects}


A large value for $CD(u)_i$ indicates that the $i-$th observation is influential in predicting random effects.


\subsubsection{linear functions}


$CD(\psi)_i$ does not have to be calculated unless $CD(\beta)_i$ is large.




\subsection{Information Ratio}




%--------------------------------------------------------------%
\newpage
\section{Computation and Notation } %2.3
with $\boldsymbol{V}$ unknown, a standard practice for estimating $\boldsymbol{X \beta}$ is the estime the variance components $\sigma^2_j$,
compute an estimate for $\boldsymbol{V}$ and then compute the projector matrix $A$, $\boldsymbol{X \hat{\beta}}  = \boldsymbol{AY}$.




\citet{zewotir} remarks that $\boldsymbol{D}$ is a block diagonal with the $i-$th block being $u \boldsymbol{I}$




\section{Demidenko's I Influence} %2.6
The concept of I Influence is generalized  to the non linea regression model.
%-------------------------------------------------------------------------------------------------------------------------------------%
%-------------------------------------------------------------------------------------------------------------------------------------%
\chapter{Zewotir's Paper}

% 2.1 Efficient Updating Theorem
% 2.2 Zewotir Measures of Influence in LME Models (section 4 of paper)
% 2.3 Computation and Notation 
% 2.4 Measures 2
%2.5 Haslett Analysis

\section{Efficient Updating Theorem} %2.1
\citet{Zewotir} describes the basic theorem of efficient updating.
\begin{itemize}
	\item \[ m_i = {1 \over c_{ii}}\]
	%\item
	%item
	%\item
\end{itemize}

\newpage
\subsubsection{Random Effects}

A large value for $CD(u)_i$ indicates that the $i-$th observation is influential in predicting random effects.

\subsubsection{linear functions}

$CD(\psi)_i$ does not have to be calculated unless $CD(\beta)_i$ is large.


\subsection{Information Ratio}


%--------------------------------------------------------------%
\newpage
\section{Computation and Notation } %2.3
with $\boldsymbol{V}$ unknown, a standard practice for estimating $\boldsymbol{X \beta}$ is the estime the variance components $\sigma^2_j$,
compute an estimate for $\boldsymbol{V}$ and then compute the projector matrix $A$, $\boldsymbol{X \hat{\beta}}  = \boldsymbol{AY}$.


\citet{Zewotir} remarks that $\boldsymbol{D}$ is a block diagonal with the $i-$th block being $u \boldsymbol{I}$
%--------------------------------------------------------------%
\newpage
\section{Measures 2} %2.4

\subsection{Cook's Distance} %2.4.1
\begin{itemize}
	\item For variance components $\gamma$
\end{itemize}

Diagnostic tool for variance components
\[ C_{\theta i} =(\hat(\theta)_{[i]} - \hat(\theta))^{T}\mbox{cov}( \hat(\theta))^{-1}(\hat(\theta)_{[i]} - \hat(\theta))\]

\subsection{Variance Ratio} %2.4.2
\begin{itemize}
	\item For fixed effect parameters $\beta$.
\end{itemize}

\subsection{Cook-Weisberg statistic} %2.4.3
\begin{itemize}
	\item For fixed effect parameters $\beta$.
\end{itemize}

\subsection{Andrews-Pregibon statistic} %2.4.4
\begin{itemize}
	\item For fixed effect parameters $\beta$.
\end{itemize}
The Andrews-Pregibon statistic $AP_{i}$ is a measure of influence based on the volume of the confidence ellipsoid.
The larger this statistic is for observation $i$, the stronger the influence that observation will have on the model fit.


%---------------------------------------------------------------------------%
\newpage
\section{Haslett's Analysis} %2.5
For fixed effect linear models with correlated error structure Haslett (1999) showed that the effects on
the fixed effects estimate of deleting each observation in turn could be cheaply computed from the fixed effects model predicted residuals.

%-------------------------------------------------------------------------------------------------------------------------------------%
%-------------------------------------------------------------------------------------------------------------------------------------%
\newpage
\chapter{Zewotir's Paper}


% 2.1 Efficient Updating Theorem
% 2.2 Zewotir Measures of Influence in LME Models (section 4 of paper)
% 2.3 Computation and Notation
% 2.4 Measures 2
% 2.5 Haslett Hayes Paper
% 2.6 Demidenko I Influence


\section{Efficient Updating Theorem} %2.1
\citet{Zewotir} describes the basic theorem of efficient updating.
\begin{itemize}
	\item \[ m_i = {1 \over c_{ii}}\]
	%\item
	%item
	%\item
\end{itemize}



\newpage
\subsubsection{Random Effects}


A large value for $CD(u)_i$ indicates that the $i-$th observation is influential in predicting random effects.


\subsubsection{linear functions}


$CD(\psi)_i$ does not have to be calculated unless $CD(\beta)_i$ is large.




\subsection{Information Ratio}




%--------------------------------------------------------------%
\newpage
\section{Computation and Notation } %2.3
with $\boldsymbol{V}$ unknown, a standard practice for estimating $\boldsymbol{X \beta}$ is the estime the variance components $\sigma^2_j$,
compute an estimate for $\boldsymbol{V}$ and then compute the projector matrix $A$, $\boldsymbol{X \hat{\beta}}  = \boldsymbol{AY}$.




\citet{zewotir} remarks that $\boldsymbol{D}$ is a block diagonal with the $i-$th block being $u \boldsymbol{I}$

\newpage
\section{Haslett's Analysis} %2.5
For fixed effect linear models with correlated error structure Haslett (1999) showed that the effects on
the fixed effects estimate of deleting each observation in turn could be cheaply computed from the fixed effects model predicted residuals.


A general theory is presented for residuals from the general linear model with correlated errors.
It is demonstrated that there are two fundamental types of residual associated with this model,
referred to here as the marginal and the conditional residual.


These measure respectively the distance to the global aspects of the model as represented by the expected value
and the local aspects as represented by the conditional expected value.


These residuals may be multivariate.


\citet{HaslettHayes} developes some important dualities which have simple implications for diagnostics.


%The results are illustrated by reference to model diagnostics in time series and in classical multivariate analysis with independent cases.
\subsection{Methods and Measures}
The key to making deletion diagnostics useable is the development of efficient computational formulas, allowing one to obtain the \index{case deletion diagnostics} case deletion diagnostics by making use of basic building blocks, computed only once for the full model.

\citet{Zewotir} lists several established methods of analyzing influence in LME models. These methods include \begin{itemize}
	\item Cook's distance for LME models,
	\item \index{likelihood distance} likelihood distance,
	\item the variance (information) ration,
	\item the \index{Cook-Weisberg statistic} Cook-Weisberg statistic,
	\item the \index{Andrews-Prebigon statistic} Andrews-Prebigon statistic.
\end{itemize}


%-------------------------------------------------------------------------------------------------Chapter 2	------------------------%
%-------------------------------------------------------------------------------------------------------------------------------------%
%-------------------------------------------------------------------------------------------------------------------------------------%

\section{Computation and Notation } %2.3
with $\boldsymbol{V}$ unknown, a standard practice for estimating $\boldsymbol{X \beta}$ is the estime the variance components $\sigma^2_j$,
compute an estimate for $\boldsymbol{V}$ and then compute the projector matrix $A$, $\boldsymbol{X \hat{\beta}}  = \boldsymbol{AY}$.


\citet{Zewotir} remarks that $\boldsymbol{D}$ is a block diagonal with the $i-$th block being $u \boldsymbol{I}$
%--------------------------------------------------------------%

\section{Measures 2} %2.4

\subsection{Cook's Distance} %2.4.1
\begin{itemize}
	\item For variance components $\gamma$
\end{itemize}

Diagnostic tool for variance components
\[ C_{\theta i} =(\hat(\theta)_{[i]} - \hat(\theta))^{T}\mbox{cov}( \hat(\theta))^{-1}(\hat(\theta)_{[i]} - \hat(\theta))\]




\section{Zewotir: Computation and Notation } %2.3
with $\boldsymbol{V}$ unknown, a standard practice for estimating $\boldsymbol{X \beta}$ is the estime the variance components $\sigma^2_j$,
compute an estimate for $\boldsymbol{V}$ and then compute the projector matrix $A$, $\boldsymbol{X \hat{\beta}}  = \boldsymbol{AY}$.


Zewotir remarks that $\boldsymbol{D}$ is a block diagonal with the $i-$th block being $u \boldsymbol{I}$
%===============================================================================================================%

\section{Demidenko's I Influence} %2.6
The concept of I Influence is generalized  to the non linea regression model.




Zewotir Notepad

\begin{quote}
	Abstract: Linear mixed models are extremely sensitive to outlying responses and extreme points in the fixed and random effect design spaces. Few diagnostics are available in standard computing packages. We provide routine diagnostic tools, which are computationally inexpensive. The diagnostics
	are functions of basic building blocks: studentized residuals, error contrast matrix, and the inverse of the response variable covariance matrix. The basic building blocks are computed only once from the complete data analysis and provide information on the influence of the data on different aspects
	of the model fit. Numerical examples provide analysts with the complete pictures of the diagnostics.
\end{quote}
Key words: Case deletion, influential observations, randomeffects, statistical
diagnostics, variance components ratios.

%-------------------------------------------------------------------------------------------------------%

Description: The influence of observations on statistical inference is of importance in statistical data analysis. 
A practical and well-established approach to influence analysis is based on case deletion. 
We provide computationally inexpensive diagnostic tools for linear mixed models. 
The diagnostics are a function of basic building blocks, computed only once from the complete data analysis, 
and provide information on the influence of the data on different aspects of the model fit.


%-------------------------------------------------------------------------------------------------------%
Residual standard deviation.
Roy Subject effects, replicate in subject,
Cardiac data PEFR data from BLand
Royal Melbourne Hospital.
Roy demonstrates that correlation can be described under the model formulation.

\[Y_i = x.\beta + Z.u + epsilon]\
Laird Ware form (litte et al)

%-------------------------------------------%
Multivariariate normal distribubtion

Between subject variability G
Within subject variability R


%-------------------------------------------------------------------------------------------------------%

For the purpose of comparison of both approaches, we compute the limits of agreement for two methods described in 
well known data sets.
%Examples Done On Other Notepad

%-------------------------------------------------------------------------------------------------------%

% Zewotir
\epsilon is an $n times 1$ vector of error terms
Zewotir provides routine diagnostics tools that are computationally inexpensive.
\boldsymbol{u}_i is a q_i \times 1  vector of random variables from \mathcal{N}(0 \sigma^2.I)


Christensen Petersen and Johnson studied case deletion diagnostics. 
%-------------------------------------------------------------------------------------------------------% 

% 2. Model Definiton and Estimation 

%-------------------------------------------------------------------------------------------------------%  
% 3. Background, Notation and Update Formulae

\section{Section 3}

\[  \boldsymbol{X} = \left[  \begin{array}{c} x^{\prime} \\ \boldsymbol{X} \end{array} \right]   \]

\[  \boldsymbol{Z} = \left[  \begin{array}{c} z^{\prime} \\ \boldsymbol{Z} \end{array} \right]   \] 

$\boldsymbol{A}_{(i)}$ denote an $n\times m$ matrix $\boldsymbol{A}$ with the $i-$th row removed.

\[ X= \left[ \begin{array} x_i \\ X(i) \end{array} \right] \]
%-------------------------------------------------------------------------------------------------------%
%Page 158 Top Half

CPJ used certain statistics as the basic building blocks of case deletion diagnostics.


%-------------------------------------------------------------------------------------------------------%
%Page 158 Lower Half

\textbf{Theorem 2 :} Basic Theorem of efficient updating (Zewotir)

%-------------------------------------------------------------------------------------------------------%
%Zewotir section 4
\section{Measures of Influence}
% 4.1 influence on variance component rations
%     4.1.1 Analogue of Cook’s Distance
%     4.1.2 Analogue of Information Ratio

%Page  161
Cook's Distance
\[  CD_{i}(\gamma) = \boldsymbol{g}^{\prime}_{(i)} ( \boldsymbol{I} + var(\hat{\gamma}) \boldsymbol{G} + \boldsymbol{g}\]

Large values of $CD$ highlights observations for special attention$.

Information Ratio
\[ IR(\gamma) = det( \boldsymbol{I}_r + var(\hat{\gamma})\boldsymbol{G} \]

\begin{itemize}
\item $det(A)$ denotes the determinant of the square matrix $\boldsymbol{A}$.
\item
\end{itemize}
%-------------------------------------------------------------------------------------------------------%

4.2. Influence on fixed effects parameter estimates
4.2.1 Analogue of Cook’s Distance
The Cook’s distance can be extended to measure influence on the fixed effects in the mixed models.
Large values of CD_i(\beta) indicates points for further consideration
%------------------------------------%
4.2.2. Analogue of the variance ratio

The variance ratio measures the change of the determinant of the variance of the fixed effects parameter estimates when the i-th case is deleted.

%------------------------------------%
%Page 163
4.2.3 Analogue of the Cook-Weisberg statistic

This statistic is used to measure the change of the confidence ellipsoid value of $\beta$.
\[ \boldsymbol{y} \sim N ( boldsymbol{X}\beta , \sigma^2_epsilon boldsymbol{H})\]

The $100(1-\alpha)\%$ confidence ellipsoid for $\beta$ is....

Cook and Weisberg proposed the logarithm of the ratio $E_{(i)}$ to E as a measure of influence.


%-------------------------------------------------------------------------------------------------------%


4.2.4 Analogue of the Andrews Pregibons statistic
This is another measure based on the volume of the confidence ellipsoid. AP_i
%-------------------------------------------------------------------------------------------------------%

4.3 Influence on random effects prediction.
Analogue of Cook’s Distance
A large CD_i(u) indicates that the i-th observation is influential in predicting random effects.
%-------------------------------------------------------------------------------------------------------%

4.4 Influence on the likelihood function
Likelihood Distance ($LD_i$)
%-------------------------------------------------------------------------------------------------------%

4.5 influence on the linear functions of the fixed effect parameters.
All the diagnostics are a function of the following basic building blocks
1)  	Studentized residuals
2)  	Error contrast matrix
3)  	The inverse of the response variable covariance matrix.
The basic building blocks are computed once from the complete data set.
Zewotir assumes that D is block diagonal with the i-th block being $\gamma. I$.
%-------------------------------------------------------------------------------------------------------% 
Applications in other notepad
Studentized Residuals
\[ e^s_i = \frac{e_i}{s^2_{(i)}(1-h_i)} \]
where
$e^s_i $ - studentized residual
$s^2_{(i)}$ - standard deviation where $i$th obs is deleted
$h_i$ - leverage statistic
Belsley et al (1980) recommend the use of studentized Residuals to determine whether there is an outlier.
%-------------------------------------------------------------------------------%
Data set 1: Beckmans' aerosol data ( Zewotir)
high efficiency particulate air filter.
toxic dust, radionuclides, and mists/
Both Beckman and CPJ rank the 14th observation as the most influential.
%-------------------------------------------------------------------------------%
Data set 2: Metal oxide analysis data ( Zewotir)
Process and measurement variation on the properties of lots of metal oxides.
type 1 and 2
chemist 1 and 2
Sample 1 and 2
Maximum likelihood variance component ratios.
Full data and with cases removed.
%-------------------------------------------------------------------------------%
http://www.tandfonline.com/doi/abs/10.1080/03610910600716795
http://www.ingentaconnect.com/content/routledg/cjas/2011/00000038/00000005/art00016
http://www.sciencedirect.com/science/article/pii/S0047259X09001213



Margina Means ( population averaged)
$E[Y_{ij}]$

Conditional means ( Cluster specific)
$E[Y_{ij}|\gamma_{i}]$





\bibliography{DB-txfrbib}
\end{document}
