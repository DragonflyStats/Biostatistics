

\chapter{REGRESSION}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Regression
\section{Model II Regression}
\subsection{Simple Linear Regression} Simple Linear Regression is  well
known statistical technique , wherein estimates for slope and
intercept of the line of best fit are derived according to the
Ordinary Least Square (OLS) principle.This method is known to
Cornbleet and Cochrane as Model I regression.
\\
\\
In Model I regression, the independent variable is assumed to be
measured without error. For method comparison studies, both sets
of measurement must be assumed to be measured with imprecision and
neither case can be taken to be a reference method. Arbitrarily
selecting either method as the reference will yield two
conflicting outcomes. A fitting based on '$X$ on $Y$' will give
inconsistent results with a fitting based on '$Y$ on $X$'.
Consequently model I regression is inappropriate for such cases.
\\
\\
Conversely, Cornbleet Cochrane state that when the independent
variable $X$ is a precisely measured reference method, Model I
regression may be considered suitable. They qualify this statement
by referring the $X$ as \emph{the 'correct' value}, tacitly
implying that there must still be some measurement error present.
The validity of this approach has been disputed elsewhere.




\subsection{Model II regression}
Cochrane and Cornbleet argue for the use of methods that based on
the assumption that both methods are imprecisely measured ,and
that yield a fitting that is consistent with both '$X$ on $Y$' and
'$Y$ on $X$' formulations. These methods uses alternatives to the
OLS approach to determine the slope and intercept.
\\
They describe three such alternative methods of regression; Deming
, Mandel, and Bartlett regression. Collectively the authors refer
to these approaches as Model II regression techniques.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\subsection{Contention }
Several papers have commented that this approach is undermined
when the basic assumptions underlying linear regression are not
met, the regression equation, and consequently the estimations of
bias are undermined. Outliers are a source of error in regression
estimates.In method comparison studies, the X variable is a
precisely measured reference method. Cornbleet Gochman (1979)
argued that criterion may be regarded as the correct value. Other
papers dispute this.
\subsection{Least Product Regression}
Least Product Regression , also known as 'Model II regression'
caters for cases in which random error is attached to both
dependent and independent variables. Ludbrook cites this
methodology as being pertinent to Method comparison studies.
\\
\\
The sum of the products of the vertical and horizontal deviations
of the x,y values from the line is minimized.
\\
\\
Least products regression analysis is considered suitable for
calibrating one method against another.Ludbrook comments that it
is also a sensitive technique for detecting and distinguishing
fixed and proportional bias between methods.
\\
\\
Proposed as an alternative to Bland \& Altman methodology ,this
method is also known as 'Geometric Mean Regression' and 'Reduced
Major Axis Regression'.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Difference with Least Squares Regression}
Least-products regression can lead to inflated SEEs and estimates
that do not tend to their true values an N approaches infinity
(Draper and Smith, 1998).
